# 4.3.4 Cross-Session Retrieval

**Layer**: 4 - Memory & State  
**Sublayer**: 4.3 - Episodic Memory (Long-Term)  
**Audience**: Intermediate to Advanced  
**Updated**: 2025-11-18

---

## Table of Contents

- [Overview](#overview)
- [Why Cross-Session Memory Matters](#why-cross-session-memory-matters)
- [Architecture Patterns](#architecture-patterns)
- [Session Management](#session-management)
- [Memory Retrieval Strategies](#memory-retrieval-strategies)
- [Implementation Examples](#implementation-examples)
- [Production Patterns](#production-patterns)
- [Performance Optimization](#performance-optimization)
- [Best Practices](#best-practices)
- [Common Pitfalls](#common-pitfalls)
- [Related Topics](#related-topics)
- [References](#references)

---

## Overview

**Cross-session retrieval** is the ability of an AI agent to recall and utilize information from previous interactions across multiple conversation sessions[^1]. This transforms stateless AI systems into **persistent, context-aware agents** that can:

- Remember user preferences from weeks/months ago
- Continue tasks across sessions without re-explanation
- Build long-term relationships with users
- Provide personalized responses based on history[^2]

**Key Difference**:
- **Single-Session Memory**: Remembers only current conversation (conversation history in context window)
- **Cross-Session Memory**: Remembers across all past conversations (persistent storage + retrieval)

**Example**:
```
Session 1 (Monday):
User: "I prefer dark mode and I'm allergic to peanuts."
Agent: "Got it! Saved your preferences."

Session 50 (Friday, 2 weeks later):
User: "Recommend a lunch spot nearby."
Agent: "Based on your peanut allergy, here are safe options..."
// ✅ Agent remembers from Session 1!
```

---

## Why Cross-Session Memory Matters

### Problem: Stateless AI

**Without Cross-Session Memory**:
```typescript
// Session 1
User: "I love TypeScript and prefer dark mode"
Agent: "Great! I'll remember that."

// Session 2 (new conversation)
User: "Show me some code examples"
Agent: "Sure! Here's a JavaScript example..." // ❌ Forgot TypeScript preference!
```

### Solution: Persistent Memory

**With Cross-Session Memory**:
```typescript
// Session 1
User: "I love TypeScript and prefer dark mode"
Agent: storeFact("user_123", "language", "TypeScript")
Agent: storeFact("user_123", "theme", "dark mode")

// Session 2
User: "Show me some code examples"
Agent: getUserFacts("user_123") // Retrieves: { language: "TypeScript", theme: "dark mode" }
Agent: "Here's a TypeScript example in dark mode syntax highlighting!"
// ✅ Remembers and applies preferences!
```

### Real-World Impact[^3]

**LongMemEval Benchmark** (2025):
- **30% accuracy drop** for commercial AI assistants without cross-session memory
- **18.5% improvement** with proper memory management (A-MEM, Zep)
- **91% latency reduction** compared to passing full conversation history

**Use Cases**:
1. **Healthcare**: Remember patient medical history, medications, allergies
2. **Customer Support**: Track past issues, solutions, account details
3. **Education**: Personalized learning paths based on student progress
4. **E-commerce**: Product preferences, shopping history, wishlists
5. **Personal AI Assistants**: Habits, schedules, relationships, preferences

---

## Architecture Patterns

### 1. Hybrid Memory Architecture

**Three-Tier System**[^4]:

```
┌────────────────────────────────────────────────────────┐
│  TIER 1: WORKING MEMORY (Short-Term)                   │
│  - Current session only                                │
│  - Conversation history (last 10-20 messages)          │
│  - Storage: In-memory (Redis, local state)             │
│  - TTL: 30 minutes to 24 hours                         │
└────────────────────────────────────────────────────────┘
              ↓ (Compress & Extract Facts)
┌────────────────────────────────────────────────────────┐
│  TIER 2: EPISODIC MEMORY (Medium-Term)                 │
│  - Recent sessions (last 7-30 days)                    │
│  - Key facts, entities, events                         │
│  - Storage: Vector DB + Key-Value Store                │
│  - TTL: 30-90 days                                     │
└────────────────────────────────────────────────────────┘
              ↓ (Consolidate & Index)
┌────────────────────────────────────────────────────────┐
│  TIER 3: SEMANTIC MEMORY (Long-Term)                   │
│  - All historical sessions (months to years)           │
│  - Core preferences, relationships, facts              │
│  - Storage: Vector DB + Graph DB                       │
│  - TTL: Indefinite (or manual deletion)                │
└────────────────────────────────────────────────────────┘
```

**Benefits**:
- ✅ **Fast Retrieval**: Recent memories in Tier 2 (50ms latency)
- ✅ **Cost-Effective**: Only index important information in Tier 3
- ✅ **Scalable**: Older memories compressed, less frequently accessed

---

### 2. Session-Aware Namespaces

**Problem**: Prevent data leakage between users and sessions

**Solution**: Isolate memory by user + session[^5]

```typescript
interface SessionIdentifier {
  user_id: string;
  session_id: string;
  timestamp: string;
}

// Store memory with session metadata
await memory.add(fact, {
  user_id: "user_123",
  session_id: "sess_2025-11-18_001",
  timestamp: "2025-11-18T10:00:00Z",
});

// Retrieve only user's memories (across all sessions)
const memories = await memory.search(query, {
  user_id: "user_123", // Filter by user
  // session_id: omitted → search ALL sessions
});
```

---

### 3. Temporal Memory (Timeline-Based)[^6]

**Approach**: Organize memories by time and causality

```typescript
// Timeline structure
interface TemporalMemory {
  id: string;
  user_id: string;
  timestamp: string;
  event_type: "conversation" | "action" | "preference_change";
  content: string;
  linked_memories: string[]; // References to related memories
}

// Example: Track preference evolution
const timeline = [
  {
    id: "mem_001",
    timestamp: "2025-01-15",
    event_type: "preference_change",
    content: "User prefers light mode",
  },
  {
    id: "mem_050",
    timestamp: "2025-11-18",
    event_type: "preference_change",
    content: "User prefers dark mode",
    linked_memories: ["mem_001"], // Links to previous preference
  },
];

// Query: "What was user's theme preference in January?"
const janPrefs = timeline.filter(
  (m) => m.timestamp.startsWith("2025-01") && m.content.includes("theme")
);
```

---

## Session Management

### Session Lifecycle

```typescript
import { v4 as uuidv4 } from "uuid";

interface Session {
  id: string;
  user_id: string;
  started_at: string;
  ended_at?: string;
  message_count: number;
  status: "active" | "inactive" | "archived";
}

class SessionManager {
  async createSession(userId: string): Promise<Session> {
    const session: Session = {
      id: uuidv4(),
      user_id: userId,
      started_at: new Date().toISOString(),
      message_count: 0,
      status: "active",
    };

    await db.sessions.insert(session);
    return session;
  }

  async endSession(sessionId: string) {
    await db.sessions.update(sessionId, {
      ended_at: new Date().toISOString(),
      status: "inactive",
    });

    // Trigger memory consolidation
    await this.consolidateSession(sessionId);
  }

  async consolidateSession(sessionId: string) {
    // Extract facts from session
    const messages = await db.messages.find({ session_id: sessionId });
    const facts = await extractFacts(messages);

    // Store in long-term memory
    await memory.addBatch(facts);

    // Archive session
    await db.sessions.update(sessionId, { status: "archived" });
  }
}

// Usage
const sessionMgr = new SessionManager();

// Start new session
const session = await sessionMgr.createSession("user_123");

// ... conversation happens ...

// End session (30 min timeout or explicit close)
setTimeout(() => sessionMgr.endSession(session.id), 30 * 60 * 1000);
```

---

## Memory Retrieval Strategies

### 1. Recency-Weighted Retrieval

**Prioritize recent memories** (more likely to be relevant)

```typescript
async function recencyWeightedSearch(
  query: string,
  userId: string,
  topK = 10
) {
  // Semantic search
  const results = await vectorDB.search(query, {
    filter: { user_id: userId },
    limit: topK * 2, // Get more candidates
  });

  // Re-rank by recency
  const now = Date.now();
  const rankedResults = results.map((r) => {
    const ageInDays = (now - new Date(r.timestamp).getTime()) / (1000 * 60 * 60 * 24);
    const recencyScore = 1 / (1 + ageInDays); // Decays over time
    const hybridScore = r.similarity * 0.7 + recencyScore * 0.3;

    return { ...r, hybridScore };
  });

  // Return top K by hybrid score
  rankedResults.sort((a, b) => b.hybridScore - a.hybridScore);
  return rankedResults.slice(0, topK);
}

// Example
const results = await recencyWeightedSearch("What are my preferences?", "user_123");
// Prioritizes recent preferences over old ones
```

---

### 2. Multi-Hop Retrieval[^7]

**Follow relationships** across memories (knowledge graph traversal)

```typescript
async function multiHopRetrieval(
  startEntity: string,
  relationship: string,
  hops = 2
) {
  const session = neo4jDriver.session();

  // Multi-hop graph query
  const result = await session.run(
    `
    MATCH path = (start:Entity {name: $startEntity})-[:${relationship}*1..${hops}]->(end:Entity)
    RETURN end.name AS entity, length(path) AS distance
    ORDER BY distance
    `,
    { startEntity }
  );

  await session.close();
  return result.records.map((r) => ({
    entity: r.get("entity"),
    distance: r.get("distance"),
  }));
}

// Example: "Who are Alice's colleagues?"
// 1-hop: Alice → WORKS_WITH → Bob
// 2-hop: Alice → WORKS_WITH → Bob → WORKS_WITH → Carol
const colleagues = await multiHopRetrieval("Alice", "WORKS_WITH", 2);
// Returns: [{ entity: "Bob", distance: 1 }, { entity: "Carol", distance: 2 }]
```

---

### 3. Context-Aware Retrieval

**Retrieve memories relevant to current context**

```typescript
async function contextAwareRetrieval(
  query: string,
  userId: string,
  context: {
    current_task?: string;
    location?: string;
    time_of_day?: string;
  }
) {
  // Build context-enhanced query
  const enhancedQuery = `
    ${query}
    Context: ${context.current_task || "general"}
    Location: ${context.location || "unknown"}
    Time: ${context.time_of_day || "unknown"}
  `;

  // Metadata filters
  const filters = {
    user_id: userId,
    ...(context.current_task && { category: context.current_task }),
  };

  return await vectorDB.search(enhancedQuery, { filter: filters, limit: 5 });
}

// Example
const memories = await contextAwareRetrieval("What should I eat?", "user_123", {
  current_task: "meal_planning",
  time_of_day: "lunch",
  location: "San Francisco",
});
// Retrieves: lunch preferences, dietary restrictions, nearby restaurants
```

---

## Implementation Examples

### Complete Cross-Session System

```typescript
import { OpenAI } from "openai";
import lancedb from "lancedb";
import Redis from "ioredis";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const vectorDB = await lancedb.connect("./lancedb");
const redis = new Redis();

interface Memory {
  id: string;
  user_id: string;
  session_id: string;
  content: string;
  timestamp: string;
  category: string;
  vector: number[];
}

class CrossSessionMemory {
  // Store memory from current session
  async add(userId: string, sessionId: string, content: string, category: string) {
    // Generate embedding
    const embedding = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: content,
    });

    const memory: Memory = {
      id: crypto.randomUUID(),
      user_id: userId,
      session_id: sessionId,
      content,
      timestamp: new Date().toISOString(),
      category,
      vector: embedding.data[0].embedding,
    };

    // Store in vector DB (long-term)
    const table = await vectorDB.openTable("memories");
    await table.add([memory]);

    // Cache recent memories in Redis (short-term)
    await redis.lpush(
      `user:${userId}:recent`,
      JSON.stringify(memory)
    );
    await redis.ltrim(`user:${userId}:recent`, 0, 19); // Keep last 20
    await redis.expire(`user:${userId}:recent`, 3600); // 1 hour TTL
  }

  // Retrieve memories across all sessions
  async search(
    query: string,
    userId: string,
    options: {
      session_id?: string;
      category?: string;
      topK?: number;
      include_recent?: boolean;
    } = {}
  ) {
    const { session_id, category, topK = 5, include_recent = true } = options;

    // Step 1: Check recent cache (fast path)
    let recentMemories: Memory[] = [];
    if (include_recent) {
      const cached = await redis.lrange(`user:${userId}:recent`, 0, -1);
      recentMemories = cached.map((m) => JSON.parse(m));
    }

    // Step 2: Vector search (all sessions or specific session)
    const embedding = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: query,
    });

    const table = await vectorDB.openTable("memories");
    let filters = `user_id = '${userId}'`;
    if (session_id) filters += ` AND session_id = '${session_id}'`;
    if (category) filters += ` AND category = '${category}'`;

    const vectorResults = await table
      .search(embedding.data[0].embedding)
      .where(filters)
      .limit(topK * 2)
      .execute();

    // Step 3: Merge and deduplicate
    const allResults = [...recentMemories, ...vectorResults];
    const uniqueResults = Array.from(
      new Map(allResults.map((m) => [m.id, m])).values()
    );

    // Step 4: Re-rank by recency + similarity
    const rankedResults = this.rerank(uniqueResults, query);

    return rankedResults.slice(0, topK);
  }

  private rerank(memories: Memory[], query: string) {
    const now = Date.now();
    return memories
      .map((m) => {
        const ageInDays =
          (now - new Date(m.timestamp).getTime()) / (1000 * 60 * 60 * 24);
        const recencyScore = 1 / (1 + ageInDays);
        const similarityScore = m._distance ? 1 - m._distance : 0.5;
        const score = similarityScore * 0.7 + recencyScore * 0.3;

        return { ...m, score };
      })
      .sort((a, b) => b.score - a.score);
  }

  // Get all sessions for a user
  async getSessions(userId: string, limit = 10) {
    const table = await vectorDB.openTable("memories");
    const results = await table
      .search([]) // Empty search = return all
      .where(`user_id = '${userId}'`)
      .select(["session_id", "timestamp"])
      .limit(1000)
      .execute();

    // Group by session_id
    const sessions = new Map<string, { first: string; last: string; count: number }>();
    for (const r of results) {
      const existing = sessions.get(r.session_id);
      if (!existing) {
        sessions.set(r.session_id, {
          first: r.timestamp,
          last: r.timestamp,
          count: 1,
        });
      } else {
        existing.last = r.timestamp;
        existing.count++;
      }
    }

    return Array.from(sessions.entries())
      .map(([id, data]) => ({ session_id: id, ...data }))
      .sort((a, b) => b.last.localeCompare(a.last))
      .slice(0, limit);
  }
}

// Usage
const memory = new CrossSessionMemory();

// Session 1
await memory.add("user_123", "sess_001", "I prefer TypeScript", "preference");
await memory.add("user_123", "sess_001", "I'm allergic to peanuts", "medical");

// Session 2 (later)
const results = await memory.search("programming preferences", "user_123");
// Returns: "I prefer TypeScript" (from Session 1)

const sessions = await memory.getSessions("user_123");
console.log(sessions);
// [
//   { session_id: "sess_002", first: "2025-11-18", last: "2025-11-18", count: 5 },
//   { session_id: "sess_001", first: "2025-11-15", last: "2025-11-15", count: 2 }
// ]
```

---

## Production Patterns

### 1. Lazy Memory Loading

**Don't load all memories upfront** (reduces latency)

```typescript
async function lazyMemoryRetrieval(query: string, userId: string) {
  // Step 1: Fast check - any memories exist?
  const hasMemories = await redis.exists(`user:${userId}:has_memories`);
  if (!hasMemories) return [];

  // Step 2: Quick semantic search (top 3)
  const initialResults = await memory.search(query, userId, { topK: 3 });

  // Step 3: Only fetch more if needed
  if (initialResults.length === 0 || initialResults[0].score < 0.7) {
    // Low confidence → expand search
    return await memory.search(query, userId, { topK: 10 });
  }

  return initialResults;
}
```

### 2. Memory Decay

**Gradually forget low-value memories**

```typescript
async function decayOldMemories(userId: string) {
  const SIX_MONTHS_AGO = new Date();
  SIX_MONTHS_AGO.setMonth(SIX_MONTHS_AGO.getMonth() - 6);

  const table = await vectorDB.openTable("memories");

  // Get old, low-importance memories
  const oldMemories = await table
    .search([])
    .where(
      `user_id = '${userId}' AND timestamp < '${SIX_MONTHS_AGO.toISOString()}' AND category != 'medical'`
    )
    .select(["id", "access_count"]) // Assume we track access_count
    .execute();

  // Delete rarely accessed memories
  const toDelete = oldMemories.filter((m) => m.access_count < 2);
  for (const m of toDelete) {
    await table.delete(`id = '${m.id}'`);
  }

  console.log(`Deleted ${toDelete.length} old, unused memories`);
}

// Run periodically (e.g., daily)
setInterval(() => decayOldMemories("user_123"), 24 * 60 * 60 * 1000);
```

### 3. Memory Conflict Resolution

**Handle contradictory memories**[^8]

```typescript
async function resolveConflicts(userId: string, category: string) {
  // Find all memories in category
  const memories = await memory.search("", userId, { category, topK: 100 });

  // Group by subject (e.g., "theme preference")
  const grouped = new Map<string, Memory[]>();
  for (const m of memories) {
    const subject = extractSubject(m.content); // e.g., "theme"
    if (!grouped.has(subject)) grouped.set(subject, []);
    grouped.get(subject)!.push(m);
  }

  // For each subject, keep only most recent
  for (const [subject, mems] of grouped.entries()) {
    if (mems.length <= 1) continue;

    mems.sort((a, b) => b.timestamp.localeCompare(a.timestamp));
    const latest = mems[0];
    const outdated = mems.slice(1);

    console.log(`Resolving ${subject}: Keeping "${latest.content}", deleting ${outdated.length} old entries`);

    for (const old of outdated) {
      await memory.delete(old.id);
    }
  }
}
```

---

## Performance Optimization

### Benchmarks (100k Users, 1M Memories)[^9]

| Strategy                  | Latency (p95) | Cost/Query | Accuracy |
|---------------------------|---------------|------------|----------|
| **No Memory**             | 10ms          | $0.001     | 60%      |
| **Redis Cache Only**      | 20ms          | $0.001     | 75%      |
| **Vector DB Only**        | 80ms          | $0.02      | 85%      |
| **Hybrid (Cache + Vector)**| 30ms         | $0.01      | 92%      |

**Recommendation**: Use hybrid approach (Redis cache + Vector DB)

### Caching Strategy

```typescript
// 1. Cache query embeddings (30% speedup)
const queryCache = new Map<string, number[]>();

async function getCachedEmbedding(query: string) {
  if (queryCache.has(query)) return queryCache.get(query)!;

  const embedding = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: query,
  });
  const vector = embedding.data[0].embedding;

  queryCache.set(query, vector);
  return vector;
}

// 2. Cache frequent queries (50% cost reduction)
await redis.set(`query_result:${userId}:${query}`, JSON.stringify(results), "EX", 3600);
```

---

## Best Practices

### 1. Session Isolation

```typescript
// ✅ Good: Isolate by user + session
await memory.search(query, userId, { session_id: "sess_001" });

// ❌ Bad: Mix sessions (data leakage risk)
await memory.search(query); // Returns memories from all users/sessions!
```

### 2. Metadata Tagging

```typescript
// ✅ Good: Rich metadata for filtering
await memory.add(userId, sessionId, "I prefer dark mode", "preference", {
  subcategory: "ui_theme",
  importance: "high",
  mutable: true, // Can be changed later
});

// ❌ Bad: No metadata (hard to query)
await memory.add(userId, sessionId, "I prefer dark mode", "general");
```

### 3. Progressive Disclosure

```typescript
// ✅ Good: Load memories on-demand
if (query.includes("preference")) {
  const prefs = await memory.search(query, userId, { category: "preference" });
}

// ❌ Bad: Always load all memories (slow + expensive)
const allMemories = await memory.getAll(userId); // 10,000+ memories!
```

---

## Common Pitfalls

### 1. ❌ No Memory Cleanup

```typescript
// ❌ Bad: Never delete old memories (cost accumulates)
// Year 1: 1000 memories → $10/month
// Year 5: 50,000 memories → $500/month

// ✅ Good: Periodic cleanup
await decayOldMemories(userId);
```

### 2. ❌ Ignoring Session Boundaries

```typescript
// ❌ Bad: Treating all sessions as one continuous conversation
Agent: "As we discussed earlier..." // User: "We never discussed that!"

// ✅ Good: Explicitly reference past sessions
Agent: "In our conversation on November 15, you mentioned..."
```

### 3. ❌ Over-Reliance on Memory

```typescript
// ❌ Bad: Always using memory (even when not needed)
User: "What's 2+2?"
Agent: *searches memory* "Based on your math preferences..." // Overkill!

// ✅ Good: Use memory only when relevant
if (requiresPersonalization(query)) {
  const memories = await memory.search(query, userId);
}
```

---

## Related Topics

- **[4.3.1 Vector Databases](./4.3.1-vector-databases.md)** - Storage backends for cross-session memory
- **[4.3.2 Semantic Search](./4.3.2-semantic-search.md)** - Retrieving relevant memories using embeddings
- **[4.3.3 Fact Extraction & Storage](./4.3.3-fact-extraction.md)** - Extracting structured facts for long-term storage
- **[4.3.5 When to Use vs Working Memory](./4.3.5-when-to-use.md)** - Choosing memory types
- **[4.4 State Persistence & Checkpointing](./4.4.1-why-checkpoint.md)** - Saving agent state across sessions

---

## References

[^1]: "AI-Native Memory and the Rise of Context-Aware AI Agents" - Ajith Vallath Prabhakar (2025): https://ajithp.com/2025/06/30/ai-native-memory-persistent-agents-second-me/
[^2]: "Persistent Memory in LLM Agents" - Emergent Mind (2025): https://www.emergentmind.com/topics/persistent-memory-for-llm-agents
[^3]: "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory" - arXiv (2024): https://arxiv.org/abs/2410.10813
[^4]: "Beyond the Bubble: How Context-Aware Memory Systems Are Changing the Game in 2025" - Tribe.ai (2025): https://www.tribe.ai/applied-ai/beyond-the-bubble-how-context-aware-memory-systems-are-changing-the-game-in-2025
[^5]: "AI Agents with LangGraph + cognee: Persistent Semantic Memory" - Cognee.ai (2025): https://www.cognee.ai/blog/integrations/langgraph-cognee-integration-build-langraph-ai-agents-with-persistent-memory
[^6]: "Towards Lifelong Dialogue Agents via Timeline-based Memory Management" - arXiv (2024): https://arxiv.org/abs/2406.10996
[^7]: "A-MEM: Agentic Memory for LLM Agents" - arXiv (2025): https://arxiv.org/abs/2502.12110
[^8]: "Zep: A Temporal Knowledge Graph Architecture for Agent Memory" - arXiv (2025): https://arxiv.org/abs/2501.13956
[^9]: "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory" - arXiv (2025): https://arxiv.org/html/2504.19413v1

---

**Next**: [4.3.5 When to Use vs Working Memory](./4.3.5-when-to-use.md) - Decision framework for choosing memory types.

**Previous**: [4.3.3 Fact Extraction & Storage](./4.3.3-fact-extraction.md) - Extracting structured facts from conversations.
