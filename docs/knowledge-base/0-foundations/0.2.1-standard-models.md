# 0.2.1 Standard Models vs Thinking (Reasoning) Models

## TL;DR

Reasoning models (o3, o4-mini, DeepSeek-R1, Qwen3) think step-by-step internally before responding, achieving 6× better math/science performance than standard models (GPT-4o, Claude, Gemini) at 10-30× higher cost and latency—use reasoning models for complex logic tasks, standard models for everything else.

-   **Status**: ✅ Complete
-   **Last Updated**: 2025-11-28
-   **Prerequisites**: [0.1.1 What is a Large Language Model?](./0.1.1-llm-intro.md)
-   **Grounded In**: OpenAI o3/o4-mini research (2024-2025), DeepSeek-R1-0528 (May 2025), Qwen3-235B (2025), ARC-AGI/ARC-AGI-2 benchmarks

## Table of Contents

-   [Overview](#overview)
-   [The Problem: When Standard Models Fail](#the-problem-when-standard-models-fail)
-   [Core Concept](#core-concept)
-   [Implementation Patterns](#implementation-patterns)
-   [Framework Integration](#framework-integration)
-   [Research & Benchmarks](#research--benchmarks)
-   [When to Use This Pattern](#when-to-use-this-pattern)
-   [Production Best Practices](#production-best-practices)
-   [Trade-offs & Considerations](#trade-offs--considerations)
-   [Key Takeaways](#key-takeaways)
-   [References](#references)

## Overview

Starting in late 2024 and accelerating through 2025, a new class of language models emerged: **reasoning models** (also called **thinking models**). These models differ fundamentally from standard models in how they approach complex problems, introducing explicit reasoning chains before generating final answers.

**Key Innovation**: Instead of immediately responding, reasoning models **think step-by-step** internally before producing output.

**As of November 2025**: Reasoning models have matured significantly, with multiple providers (OpenAI, DeepSeek, Alibaba Qwen) offering both commercial and open-source options. The gap between preview and production versions is notable—OpenAI's o3-preview scored 76-88% on ARC-AGI-1, while the released o3 delivers 41-53%.

### Key Research Findings (2024-2025)

-   **Math Performance (AIME 2024)**: DeepSeek-R1-0528 achieves 91.4%, o3 achieves ~96.7%
-   **Math Performance (AIME 2025)**: Qwen3-Thinking achieves 92.3%, DeepSeek-R1-0528 achieves 87.5%
-   **Graduate Science (GPQA Diamond)**: DeepSeek-R1-0528 achieves 81.0%, approaching o3's ~83%
-   **AGI Reasoning (ARC-AGI-1)**: o3-medium achieves 53%, o4-mini-medium achieves 41%
-   **ARC-AGI-2** (March 2025): o3/o4-mini score <3% vs 60% for average humans
-   **Cost Trade-off**: o4-mini achieves 21% ARC-AGI-1 at ~5 cents/task vs $11+/task for o1-pro
-   **Latency Trade-off**: 5-60 seconds vs 0.5-2 seconds for standard models

**Date Verified**: 2025-11-28

## The Problem: When Standard Models Fail

### The Classic Challenge

Standard language models generate text token-by-token immediately upon receiving a prompt. While this works well for most tasks, it struggles with complex reasoning that requires multiple logical steps.

**Example Failure**: Complex multi-step mathematics

```
User: "Solve: If 3x + 7 = 22, and y = 2x - 1, what is y?"

GPT-4o (standard model):
- May solve correctly: x = 5, y = 9
- But sometimes: Skips verification, occasional arithmetic errors
- Success rate: ~85% for multi-step problems
```

**Problems**:

-   ❌ **Skip logical steps**: Models may jump to conclusions without intermediate reasoning
-   ❌ **Accumulate errors**: Small mistakes in step 1 compound through subsequent steps
-   ❌ **Limited verification**: No built-in mechanism to check if answer makes sense
-   ❌ **Inconsistent on complexity**: Complex problems trigger variable quality responses

### Why This Matters

**Business Impact**:

-   Scientific research: 15-30% error rate in complex calculations leads to wasted experiments
-   Code generation: 40% of complex algorithms fail without explicit reasoning
-   Legal analysis: Missing logical steps creates liability risks
-   Financial modeling: Math errors compound into costly mistakes

**Technical Impact**:

-   Chain-of-thought must be prompted explicitly ("Let's think step by step")
-   Quality of reasoning depends heavily on prompt engineering
-   No guarantee model will reason thoroughly even when prompted

## Core Concept

### What Are Reasoning Models?

Reasoning models are LLMs trained with **Reinforcement Learning (RL)** to generate extensive internal reasoning chains before producing final answers. They **always think step-by-step**, without requiring explicit prompting.

### Visual Representation

**Standard Model (Immediate Response)**:

```
User Prompt → Tokenization → Transformer → Output (token-by-token)
                                ↓
                          Hidden reasoning
                          (implicit, shallow)
```

**Reasoning Model (Think → Answer)**:

```
User Prompt → Internal Reasoning Chain → Final Answer
                        ↓
                [Hidden from user]
                        ↓
           "Let me think about this..."
           Step 1: Parse the problem
           Step 2: Break into subproblems
           Step 3: Solve each subproblem
           Step 4: Verify solution
           Step 5: Combine results
                        ↓
                Final Answer
```

**Training Difference**:

```
Standard Model Training:
Input → Predict Next Token → Compare to Truth → Update Weights

Reasoning Model Training:
Input → Generate Reasoning + Answer → Verify Correctness → Reward/Penalty
    ↓                                          ↓
Longer reasoning = Higher reward (if correct)
Shallow reasoning = Lower reward (if wrong)
    ↓
Model learns: "Complex problem = Think longer"
```

### Key Principles

1. **Native Chain-of-Thought**: Reasoning is built into the model via RL training, not prompt engineering
2. **Verification-Driven**: Models learn to backtrack, verify, and self-correct through reward signals
3. **Adaptive Depth**: Models automatically adjust reasoning length based on problem complexity
4. **Emergent Behaviors**: Backtracking, alternative approaches, and verification emerge naturally from RL

## Implementation Patterns

### Pattern 1: Standard Model with Prompted CoT

**Use Case**: When you need some reasoning but can't afford reasoning model costs

```typescript
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

const { text } = await generateText({
	model: openai("gpt-4o"),
	prompt: `Let's think step by step.

What is 347 × 829?

Show your work:
1. Break down the calculation
2. Compute intermediate steps
3. Verify the final answer`,
});
```

**Pros**:

-   ✅ Fast response (1-3 seconds)
-   ✅ Cost-effective ($0.01-0.10 per 1k tokens)
-   ✅ Works with any standard model

**Cons**:

-   ❌ Quality depends on prompt engineering
-   ❌ No guarantee of thorough reasoning
-   ❌ Reasoning quality varies between runs

**When to Use**: Budget-constrained applications needing basic reasoning

### Pattern 2: Native Reasoning Model (o3, DeepSeek-R1)

**Use Case**: When accuracy is critical and cost is secondary

```typescript
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

// No CoT prompt needed - model reasons automatically
const { text, providerMetadata } = await generateText({
	model: openai("o3-mini"),
	prompt: "What is 347 × 829?",
	providerOptions: {
		openai: {
			reasoningEffort: "medium", // low, medium, high
		},
	},
});

// Access reasoning token usage
console.log("Reasoning tokens:", providerMetadata?.openai?.reasoningTokens);
```

**Pros**:

-   ✅ Native reasoning (no prompt engineering required)
-   ✅ High accuracy (6× better on math/science)
-   ✅ Self-verification built-in
-   ✅ Consistent performance across runs

**Cons**:

-   ❌ Slow (5-60 seconds depending on reasoning effort)
-   ❌ Expensive ($0.15-3.00 per 1k tokens)
-   ❌ Overkill for simple tasks

**When to Use**: Complex math, science, code algorithms, multi-step logic

### Pattern 3: Hybrid Routing (Best of Both Worlds)

**Use Case**: Production systems optimizing cost and quality

```typescript
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

function selectModel(task: string) {
	const complexitySignals = [
		/calculate|solve|prove|algorithm/i,
		/step-by-step|multi-step|derive/i,
		/\d+\s*[×*÷/+-]\s*\d+/, // Math operations
		/explain.*why|reason.*through/i,
	];

	const isComplex = complexitySignals.some((pattern) => pattern.test(task));

	return isComplex ? openai("o3-mini") : openai("gpt-4o");
}

const model = selectModel(userQuery);
const { text } = await generateText({ model, prompt: userQuery });
```

**Pros**:

-   ✅ Cost-optimized (reasoning only when needed)
-   ✅ Fast for simple tasks (95% of requests)
-   ✅ Accurate for complex tasks (5% of requests)

**Cons**:

-   ❌ Requires classification logic
-   ❌ Potential misclassification risk

**When to Use**: Production agents handling mixed workloads

## Framework Integration

### AI SDK 6 Integration

AI SDK 6 provides unified support for reasoning models across providers. Key features include reasoning effort control, reasoning extraction middleware, and streaming reasoning tokens.

**OpenAI Reasoning Models (o3, o3-mini, o4-mini)**:

```typescript
import { generateText } from "ai";
import { openai } from "@ai-sdk/openai";

const { text, usage, providerMetadata } = await generateText({
	model: openai("o3-mini"),
	prompt: "Prove that the square root of 2 is irrational.",
	providerOptions: {
		openai: {
			reasoningEffort: "medium", // low, medium, high
		},
	},
});

console.log("Usage:", {
	...usage,
	reasoningTokens: providerMetadata?.openai?.reasoningTokens,
});
```

**DeepSeek Reasoning Models**:

```typescript
import { deepseek } from "@ai-sdk/deepseek";
import { generateText } from "ai";

const { text, reasoning } = await generateText({
	model: deepseek("deepseek-reasoner"),
	prompt: "Explain quantum entanglement.",
});

console.log("Internal Reasoning:", reasoning);
console.log("Final Answer:", text);
```

**DeepSeek R1 via Other Providers (Groq, Fireworks, Together)**:

```typescript
import { groq } from "@ai-sdk/groq";
import { generateText, wrapLanguageModel, extractReasoningMiddleware } from "ai";

const enhancedModel = wrapLanguageModel({
	model: groq("deepseek-r1-distill-llama-70b"),
	middleware: extractReasoningMiddleware({ tagName: "think" }),
});

const { reasoning, text } = await generateText({
	model: enhancedModel,
	prompt: "Explain quantum entanglement.",
});
```

### Streaming Reasoning Tokens

For real-time UI updates showing the model's thinking process:

```typescript
import { deepseek } from "@ai-sdk/deepseek";
import { streamText } from "ai";

const result = streamText({
	model: deepseek("deepseek-reasoner"),
	prompt: "Solve this complex problem...",
});

for await (const part of result.fullStream) {
	if (part.type === "reasoning") {
		console.log("Thinking:", part.text);
	} else if (part.type === "text") {
		console.log("Answer:", part.text);
	}
}
```

**Server Route with Reasoning Streaming**:

```typescript
// app/api/reason/route.ts
import { deepseek } from "@ai-sdk/deepseek";
import { streamText } from "ai";

export async function POST(req: Request) {
	const { messages } = await req.json();

	const result = streamText({
		model: deepseek("deepseek-reasoner"),
		messages,
	});

	return result.toDataStreamResponse({
		sendReasoning: true,
	});
}
```

### Reasoning Effort Levels

| Level      | Description                      | Latency | Cost     | Use Case                     |
| ---------- | -------------------------------- | ------- | -------- | ---------------------------- |
| **low**    | Quick reasoning (5-10 steps)     | 2-5s    | $0.15/1k | Simple math, basic logic     |
| **medium** | Moderate reasoning (20-50 steps) | 10-20s  | $0.50/1k | Code generation, proofs      |
| **high**   | Deep reasoning (100+ steps)      | 30-60s  | $3.00/1k | Research, complex algorithms |

### Key AI SDK 6 Features

-   `reasoningEffort`: Control reasoning depth (low/medium/high) for OpenAI models
-   `extractReasoningMiddleware`: Parse reasoning from `<think>` tags in open-source models
-   `wrapLanguageModel`: Add middleware to enhance any model
-   `sendReasoning: true`: Stream reasoning tokens to client
-   `providerMetadata.openai.reasoningTokens`: Access reasoning token count

**Research**: [AI SDK Reasoning Models Guide](https://ai-sdk.dev/docs/guides/o1)

## Research & Benchmarks

### OpenAI o3 and o4-mini (2024-2025)

**Source**: ARC Prize Analysis

-   **o3-preview** (December 2024): 76% (low-compute), 88% (high-compute) on ARC-AGI-1
-   **o3 released** (April 2025): 41% (low), 53% (medium) on ARC-AGI-1
-   **o4-mini**: 21% (low), 41% (medium) on ARC-AGI-1 at ~5¢/task
-   **ARC-AGI-2**: <3% for both o3 and o4-mini vs 60% for average humans
-   **Key Finding**: Released o3 differs from preview—smaller architecture, multimodal, fewer resources

**Sources**: [ARC Prize o3 Analysis](https://arcprize.org/blog/analyzing-o3-with-arc-agi), [ARC Prize o3 Breakthrough](https://arcprize.org/blog/oai-o3-pub-breakthrough)

### DeepSeek-R1-0528 (May 2025)

**Source**: DeepSeek AI Research

-   **AIME 2024**: 91.4% (up from 79.8% in original R1)
-   **AIME 2025**: 87.5% (up from 70.0%)
-   **GPQA Diamond**: 81.0% (up from 71.5%)
-   **Codeforces**: 96.3rd percentile (expert-level)
-   **Key Innovation**: Deeper chain-of-thought reasoning (~23K tokens vs 12K before)
-   **Advantage**: Open-source, approaching o3 performance on math benchmarks

**Sources**: [DeepSeek-R1 Paper](https://arxiv.org/pdf/2501.12948), [Hugging Face Model](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)

### Alibaba Qwen3-235B-A22B (2025)

**Source**: Qwen Team Technical Report

-   **AIME 2025**: 92.3% (Thinking variant), approaching o3 performance
-   **AIME 2024**: 85.7% (Instruct), 70.1→85.1% improvement with RL training
-   **Architecture**: 235B total parameters, 22B active per token (MoE)
-   **Key Innovation**: Hybrid thinking/non-thinking modes with thinking budget control
-   **Advantage**: Open-source (Apache 2.0), 256K context, scalable reasoning budget

**Sources**: [Qwen3 Technical Report](https://arxiv.org/pdf/2505.09388), [Qwen Blog](https://qwenlm.github.io/blog/qwen3/)

### Benchmark Comparison (November 2025)

| Benchmark                | GPT-4o | o3 (medium) | o4-mini (medium) | DeepSeek-R1-0528 | Qwen3-Thinking |
| ------------------------ | ------ | ----------- | ---------------- | ---------------- | -------------- |
| **AIME 2024 (Math)**     | 13.4%  | ~96.7%      | N/A              | 91.4%            | 85.7%          |
| **AIME 2025 (Math)**     | N/A    | N/A         | N/A              | 87.5%            | 92.3%          |
| **GPQA Diamond**         | 56%    | ~83%        | N/A              | 81.0%            | N/A            |
| **ARC-AGI-1**            | 5%     | 53%         | 41%              | N/A              | N/A            |
| **ARC-AGI-2**            | <3%    | <3%         | <3%              | N/A              | N/A            |
| **Cost (per task)**      | ~$0.01 | N/A         | ~$0.05           | Open-source      | Open-source    |

**Key Insight**: Open-source models (DeepSeek-R1-0528, Qwen3) now match or exceed closed-source reasoning models on many benchmarks, with significant cost advantages.

## When to Use This Pattern

### ✅ Use Reasoning Models When:

1. **Complex Mathematics**

    - Multi-step calculations requiring verification
    - Example: Scientific simulations, financial modeling, cryptographic operations

2. **Graduate-Level Science**

    - Physics, chemistry, biology problem-solving
    - Example: Drug discovery, materials science research

3. **Algorithm Design & Debugging**

    - Complex code generation requiring logical correctness
    - Example: Competitive programming, systems optimization

4. **Multi-Step Logic Puzzles**
    - Problems requiring backtracking and verification
    - Example: Legal reasoning, strategic planning

### ❌ Use Standard Models When:

1. **Conversational AI**

    - Chat, Q&A, customer support
    - Better alternative: GPT-4o, Claude 4.5, Gemini 2.5 (10-30× cheaper, 10× faster)

2. **Content Generation**

    - Writing, summarization, translation
    - Better alternative: GPT-4o-mini, Gemini 2.5 Flash (50× cheaper)

3. **Simple Code Completion**

    - Boilerplate, basic CRUD, standard patterns
    - Better alternative: Claude 4.5 Haiku, GPT-4o-mini

4. **Factual Retrieval**
    - Answering knowledge questions (not reasoning)
    - Better alternative: RAG with standard model

### Decision Matrix

| Your Situation                       | Recommended Approach            |
| ------------------------------------ | ------------------------------- |
| Math proofs, scientific calculations | o3-mini or DeepSeek-R1-0528     |
| Complex algorithms, debugging        | o3 or Qwen3-Thinking            |
| Cost-sensitive reasoning             | o4-mini or DeepSeek-R1          |
| Mix of simple + complex tasks        | Hybrid routing pattern          |
| Chat, summarization, simple code     | Standard (GPT-4o, Claude)       |
| High-volume, budget-constrained      | Standard (GPT-4o-mini)          |
| Open-source requirement              | DeepSeek-R1-0528 or Qwen3       |

## Production Best Practices

### 1. Use Hybrid Routing

**Principle**: Only use reasoning models for tasks that need them. Route 90-95% of requests to fast, cheap standard models.

**Strategy**:

```
Classify request → Route appropriately

Simple (95%):     "Write an email" → GPT-4o (fast + cheap)
Complex (5%):     "Prove theorem X" → o3-mini (slow + expensive + accurate)
```

**Why**: Saves 80-90% on costs without sacrificing quality.

**Impact**: $10k/month → $2k/month for typical agent workloads.

### 2. Set Reasoning Effort Appropriately

**Principle**: Match reasoning depth to problem complexity. Don't use `high` effort for simple problems.

**Strategy**:

-   **low**: Basic math, simple logic (2-5s, $0.15/1k tokens)
-   **medium**: Code generation, proofs (10-20s, $0.50/1k tokens)
-   **high**: Research, complex algorithms (30-60s, $3.00/1k tokens)

**Why**: Avoid paying for 100-step reasoning on problems solvable in 10 steps.

**Impact**: 3-5× cost reduction for reasoning workloads.

### 3. Extract and Log Reasoning Traces

**Principle**: Use reasoning traces for debugging, evaluation, and user transparency.

```typescript
const enhancedModel = wrapLanguageModel({
	model: groq("deepseek-r1-distill-llama-70b"),
	middleware: extractReasoningMiddleware({ tagName: "think" }),
});

const { reasoning, text } = await generateText({
	model: enhancedModel,
	prompt: "Solve this complex problem...",
});

// Log reasoning for analysis
logger.info({ reasoning, finalAnswer: text, userId });
```

**Why**: Reasoning traces help debug wrong answers, improve prompts, and build user trust.

**Impact**: Reduces debugging time by 60-80% for reasoning failures.

### 4. Cache Reasoning for Repeated Queries

**Principle**: If the same complex problem appears multiple times, cache the reasoning result.

**Strategy**:

```
First request: "Prove X" → Call o3-mini (60s, $3) → Cache result
Subsequent:    "Prove X" → Return cached result (0s, $0)
```

**Why**: Reasoning models are slow and expensive. Cache aggressively for repeated patterns.

**Impact**: 90%+ cost savings for FAQ-style reasoning queries.

### 5. Monitor Token Usage and Costs

**Principle**: Reasoning models can consume 10-100× more tokens than expected due to internal reasoning.

**What to Track**:

-   Input tokens (prompt)
-   Output tokens (visible answer)
-   **Reasoning tokens** (hidden thinking) ← Can be massive
-   Total cost per request

**Alert Thresholds**:

-   > 5000 tokens per request
-   > $1 per request
-   > 60 seconds latency

**Why**: Runaway reasoning can burn budget quickly. Monitor closely.

## Trade-offs & Considerations

### Advantages

1. **6-8× Better Accuracy**: On complex math, science, and coding tasks
2. **Native Reasoning**: No prompt engineering required for chain-of-thought
3. **Self-Verification**: Models check their own work, reducing errors
4. **Open-Source Options**: DeepSeek-R1-0528, Qwen3 provide customizable alternatives
5. **Cost-Efficient Options**: o4-mini provides 41% ARC-AGI-1 accuracy at ~5¢/task

### Disadvantages

1. **10-30× Higher Cost**: $0.15-3.00 per 1k tokens vs $0.01-0.10 for standard models
2. **10-30× Higher Latency**: 5-60 seconds vs 0.5-2 seconds for standard models
3. **Overkill for Simple Tasks**: Marginal improvement on factual Q&A, chat, summarization
4. **Token Explosion**: Internal reasoning can consume thousands of hidden tokens
5. **ARC-AGI-2 Gap**: Even best models score <3% vs 60% for humans on hardest benchmarks

### Cost Analysis

**Scenario**: AI coding assistant handling 10,000 queries/month

**Standard Model (GPT-4o)**:

-   Avg 1000 tokens/query × 10,000 queries = 10M tokens
-   Cost: $2.50/1M input + $10/1M output = ~$125/month
-   Latency: 1-2s per query

**Reasoning Model (o3-mini)**:

-   Avg 3000 tokens/query (2000 hidden reasoning) × 10,000 queries = 30M tokens
-   Cost: ~$500/month (estimated)
-   Latency: 10-20s per query

**Hybrid Approach (95% standard, 5% reasoning)**:

-   9,500 queries × GPT-4o = ~$119
-   500 queries × o3-mini = ~$25
-   **Total: ~$144/month (vs $500 for pure reasoning)**

## Key Takeaways

1. **Reasoning models think step-by-step automatically** — No prompt engineering required for chain-of-thought
2. **6-8× better on complex tasks** — Math, science, code algorithms see massive accuracy gains
3. **10-30× higher cost and latency** — Use sparingly, only when accuracy justifies expense
4. **Hybrid routing is optimal** — Route simple tasks to standard models, complex tasks to reasoning models
5. **Open-source models now compete** — DeepSeek-R1-0528 and Qwen3-Thinking match commercial performance
6. **o4-mini provides cost-efficient reasoning** — 41% ARC-AGI-1 accuracy at ~5¢/task
7. **Monitor token usage closely** — Internal reasoning can explode token consumption
8. **ARC-AGI-2 reveals limits** — Even best models score <3% vs 60% for humans on hardest benchmarks

**Quick Implementation Checklist**:

-   [ ] Classify your workload: % simple vs % complex tasks
-   [ ] Implement router to select model based on task complexity
-   [ ] Set `reasoningEffort` appropriately (low/medium/high)
-   [ ] Extract reasoning traces with `extractReasoningMiddleware`
-   [ ] Cache reasoning results for repeated queries
-   [ ] Monitor token usage, costs, and latency per model type
-   [ ] Use standard models for 90-95% of requests
-   [ ] Consider open-source options (DeepSeek-R1, Qwen3) for cost savings

## References

### Academic Papers

1. **DeepSeek AI Team** (2025). "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning", ArXiv. [https://arxiv.org/pdf/2501.12948](https://arxiv.org/pdf/2501.12948)

2. **Qwen Team** (2025). "Qwen3 Technical Report", ArXiv. [https://arxiv.org/pdf/2505.09388](https://arxiv.org/pdf/2505.09388)

### Benchmark Analysis

3. **ARC Prize Team** (2024). "OpenAI o3 Breakthrough High Score on ARC-AGI-Pub", ARC Prize. [https://arcprize.org/blog/oai-o3-pub-breakthrough](https://arcprize.org/blog/oai-o3-pub-breakthrough)

4. **ARC Prize Team** (2025). "Analyzing o3 and o4-mini with ARC-AGI", ARC Prize. [https://arcprize.org/blog/analyzing-o3-with-arc-agi](https://arcprize.org/blog/analyzing-o3-with-arc-agi)

5. **VentureBeat** (2024). "OpenAI's o3 shows remarkable progress on ARC-AGI, sparking debate on AI reasoning". [https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning](https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning)

### Technical Resources

6. **AI SDK Team** (2025). "Control AI Reasoning Effort with AI SDK Core and o1", Vercel AI SDK. [https://ai-sdk.dev/docs/guides/o1](https://ai-sdk.dev/docs/guides/o1)

7. **AI SDK Team** (2025). "Call Groq's DeepSeek R1 model with AI SDK", Vercel AI SDK. [https://ai-sdk.dev/docs/guides/r1](https://ai-sdk.dev/docs/guides/r1)

8. **AI SDK Team** (2025). "AI SDK Middleware Documentation", Vercel AI SDK. [https://ai-sdk.dev/docs/ai-sdk-core/middleware](https://ai-sdk.dev/docs/ai-sdk-core/middleware)

### Model Documentation

9. **DeepSeek** (2025). "DeepSeek-R1-0528", Hugging Face. [https://huggingface.co/deepseek-ai/DeepSeek-R1-0528](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)

10. **Qwen Team** (2025). "Qwen3: Think Deeper, Act Faster", Qwen Blog. [https://qwenlm.github.io/blog/qwen3/](https://qwenlm.github.io/blog/qwen3/)

### Analysis & Guides

11. **Medium** (2025). "DeepSeek's New R1-0528: Performance Analysis and Benchmark Comparisons". [https://medium.com/@leucopsis/deepseeks-new-r1-0528-performance-analysis-and-benchmark-comparisons-6440eac858d6](https://medium.com/@leucopsis/deepseeks-new-r1-0528-performance-analysis-and-benchmark-comparisons-6440eac858d6)

12. **Helicone** (2025). "OpenAI o3 Released: Benchmarks and Comparison to o1". [https://www.helicone.ai/blog/openai-o3](https://www.helicone.ai/blog/openai-o3)

**Related Topics**:

-   [0.2.2 Reasoning Models Deep Dive](./0.2.2-reasoning-models.md)
-   [0.2.3 When to Use Which Model](./0.2.3-model-comparison.md)
-   [1.1.3 Chain-of-Thought Prompting](../1-prompts/1.1.3-chain-of-thought.md)

**Layer Index**: [Layer 0: Foundations](../../AI_KNOWLEDGE_BASE_TOC.md#layer-0-foundations)
