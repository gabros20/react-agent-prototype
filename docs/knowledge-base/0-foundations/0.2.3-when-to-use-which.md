# 0.2.3 When to Use Which Model

## Overview

Selecting the right AI model is critical for balancing cost, performance, and capabilities. This guide provides decision frameworks, use case matrices, and practical rules for choosing between GPT-4, Claude, Gemini, reasoning models (o1/o3), and smaller models based on your specific needs.

**Key Principle**: Use the smallest/cheapest model that meets your requirements. Over-provisioning wastes resources; under-provisioning frustrates users.

## Model Categories Overview

### 1. Fast & Cheap Models
**Best for**: High-volume, straightforward tasks

| Model | Cost ($/1M tokens) | Speed | Context | Use When |
|-------|-------------------|-------|---------|----------|
| **GPT-4o-mini** | $0.15/$0.60 | Very Fast | 128k | General agent tasks, tool calling |
| **Gemini Flash** | $0.10/$0.40 | Fastest | 1M | Customer support, data parsing |
| **Claude Haiku** | $0.25/$1.25 | Fast | 200k | High-throughput chat, simple analysis |

### 2. Balanced Models
**Best for**: General-purpose applications

| Model | Cost ($/1M tokens) | Speed | Context | Use When |
|-------|-------------------|-------|---------|----------|
| **GPT-4o** | $2.50/$10.00 | Fast | 128k | Production apps, customer-facing |
| **Claude Sonnet** | $3.00/$15.00 | Medium | 200k | Coding, writing, analysis |
| **Gemini Pro** | $1.25/$5.00 | Medium | 2M | Long-context tasks, research |

### 3. Premium Models
**Best for**: Complex reasoning, highest quality

| Model | Cost ($/1M tokens) | Speed | Context | Use When |
|-------|-------------------|-------|---------|----------|
| **Claude Opus** | $15.00/$75.00 | Slow | 200k | Legal analysis, complex decisions |
| **GPT-4 Turbo** | $10.00/$30.00 | Medium | 128k | Advanced reasoning, nuanced tasks |

### 4. Reasoning Models
**Best for**: Problems requiring deep thought

| Model | Cost ($/1M tokens) | Speed | Context | Use When |
|-------|-------------------|-------|---------|----------|
| **o1-preview** | $15.00/$60.00* | Very Slow | 128k | Math, complex logic, multi-step |
| **o1-mini** | $3.00/$12.00* | Slow | 128k | Cost-efficient reasoning |
| **o3-low** | $20 per query | Very Slow | 128k | Hard problems, accurate results |

*Includes thinking tokens charged as output

## Decision Framework

### Step 1: Define Task Complexity

**Simple Tasks** (Use Fast/Cheap Models):
- ✓ Single-turn Q&A ("What's the weather?")
- ✓ Data formatting/parsing
- ✓ Basic classification
- ✓ Template filling
- ✓ Simple tool calling

**Medium Tasks** (Use Balanced Models):
- ✓ Multi-turn conversations
- ✓ Content generation (blog posts, emails)
- ✓ Code generation (functions, scripts)
- ✓ Document summarization
- ✓ Sentiment analysis

**Complex Tasks** (Use Premium/Reasoning Models):
- ✓ Multi-step reasoning (proofs, complex math)
- ✓ Advanced coding (algorithms, debugging)
- ✓ Legal/medical analysis
- ✓ Long-form creative writing
- ✓ Strategic planning

### Step 2: Identify Key Requirements

**Speed Priority** (< 2 seconds response):
```
Gemini Flash > GPT-4o-mini > Claude Haiku
```

**Cost Priority** (< $0.001 per request):
```
Gemini Flash ($0.0001) > GPT-4o-mini ($0.0003) > Claude Haiku ($0.0005)
```

**Quality Priority** (highest accuracy):
```
Claude Opus / o3 > GPT-4 Turbo > Claude Sonnet
```

**Context Priority** (long documents):
```
Gemini Pro (2M) > Claude (200k) > GPT-4 (128k)
```

**Coding Priority** (software development):
```
Claude Sonnet > GPT-4o > o1-mini (complex algorithms)
```

### Step 3: Apply Decision Matrix

```
                    Simple Task    Medium Task    Complex Task
                    ──────────────────────────────────────────
High Volume         Gemini Flash   GPT-4o-mini    Claude Sonnet
(>1000/day)        ($10/day)      ($300/day)     ($3k/day)

Medium Volume      GPT-4o-mini    GPT-4o         Claude Opus
(100-1000/day)     ($30/day)      ($250/day)     ($1.5k/day)

Low Volume         GPT-4o-mini    Claude Sonnet  o1-mini
(<100/day)         ($3/day)       ($30/day)      ($120/day)

Critical           Claude Sonnet  Claude Opus    o3-low
(accuracy vital)   ($15/day)      ($150/day)     ($2k/day)
```

## Use Case Specific Recommendations

### 1. Customer Support Chatbot

**Requirements**: Fast, cheap, conversational, high-volume

**Recommended Stack**:
```
Primary: Gemini Flash ($0.10/$0.40)
- 95% of queries (simple Q&A, status checks)
- <1 second latency
- $50/month for 100k queries

Fallback: GPT-4o-mini ($0.15/$0.60)
- Complex queries requiring tool use
- ~5% of queries
- $30/month for 5k queries

Total: $80/month for 105k queries
```

**Implementation**:
```typescript
async function handleCustomerQuery(query: string) {
  const complexity = await classifyComplexity(query);
  
  if (complexity === "simple") {
    return await generateText({
      model: google("gemini-1.5-flash"),  // Fast & cheap
      prompt: query
    });
  }
  
  return await generateText({
    model: openai("gpt-4o-mini"),  // Better tool calling
    prompt: query
  });
}
```

### 2. Coding Assistant

**Requirements**: High-quality code, debugging, explanations

**Recommended Stack**:
```
Primary: Claude Sonnet 3.5 ($3.00/$15.00)
- Best for coding tasks
- Clear explanations
- Strong at refactoring

For Algorithms: o1-mini ($3.00/$12.00)
- Complex algorithm design
- Optimization problems
- Only when needed (expensive)

Monthly Cost: $200 for 1k coding sessions
```

**When to Switch**:
```typescript
function selectCodingModel(task: CodingTask) {
  // Use reasoning model for hard algorithms
  if (task.type === "algorithm" && task.difficulty > 8) {
    return openai("o1-mini");
  }
  
  // Use Claude for everything else
  return anthropic("claude-3-5-sonnet-20241022");
}
```

### 3. Content Writing

**Requirements**: Quality, creativity, brand voice

**Recommended Stack**:
```
Blog Posts: Claude Sonnet ($3.00/$15.00)
- Best writing quality
- Natural flow
- $0.50 per 2000-word article

Social Media: GPT-4o-mini ($0.15/$0.60)
- Short-form content
- High volume
- $0.05 per 10 posts

Long-Form: Claude Opus ($15.00/$75.00)
- Reports, whitepapers
- Complex topics
- $5.00 per 10k word document
```

### 4. Data Analysis & Research

**Requirements**: Long-context, synthesis, accuracy

**Recommended Stack**:
```
Document Analysis: Gemini Pro 1.5 ($1.25/$5.00)
- 2M token context (process entire books)
- Cost-effective for long documents
- $2.50 to analyze 500-page PDF

Research Synthesis: Claude Opus ($15.00/$75.00)
- Nuanced understanding
- Connect multiple sources
- Best for critical research

Mathematical Analysis: o1-preview ($15.00/$60.00)
- Statistical reasoning
- Complex calculations
- Use sparingly (expensive)
```

### 5. Autonomous Agents (Your Use Case)

**Requirements**: Tool calling, multi-step, reliable, cost-efficient

**Current Setup** (from `orchestrator.ts`):
```typescript
model: openai("gpt-4o-mini", { structuredOutputs: true })
```

**Analysis**: ✅ Excellent choice!
- Strong tool calling support
- Fast enough for interactive agents
- Cost: ~$10/month for 10k agent interactions
- 128k context for complex workflows

**Enhancement Strategy**:
```typescript
// Add reasoning for complex planning
async function planComplexGoal(goal: string) {
  // Use o1-mini for initial planning (1-2 times per session)
  const plan = await generateText({
    model: openai("o1-mini"),
    prompt: `Create detailed plan: ${goal}`
  });
  
  // Execute with fast model (dozens of tool calls)
  for (const step of plan.steps) {
    await executeStep(step, openai("gpt-4o-mini"));
  }
}

// Estimated cost: $10 → $15/month (50% increase for 10x better planning)
```

### 6. Educational Tutoring

**Requirements**: Step-by-step explanations, patience, correctness

**Recommended Stack**:
```
Math/Science: o1-mini ($3.00/$12.00)
- Correct step-by-step reasoning
- Catches own mistakes
- $0.30 per tutoring session

General Subjects: Claude Sonnet ($3.00/$15.00)
- Clear explanations
- Patient teaching style
- $0.20 per session

Practice Problems: GPT-4o-mini ($0.15/$0.60)
- Generate exercises
- High volume
- $0.01 per 10 problems
```

### 7. Legal/Medical Applications

**Requirements**: Highest accuracy, no hallucinations, justification

**Recommended Stack**:
```
Analysis: Claude Opus 4 ($15.00/$75.00)
- Most careful/accurate
- Best for risk-averse domains
- $3.00 per case analysis

Research: o1-preview ($15.00/$60.00)
- Complex legal reasoning
- Multi-step deduction
- $5.00 per research query

Document Review: Gemini Pro ($1.25/$5.00)
- Long contracts (2M tokens)
- Cost-effective for volume
- $1.00 per 200-page document
```

## Multi-Model Strategy

### Router Pattern

**Concept**: Automatically route to optimal model

```typescript
interface ModelRouter {
  selectModel(task: Task): Model;
}

class CostOptimizedRouter implements ModelRouter {
  selectModel(task: Task): Model {
    // Classify task complexity
    const complexity = this.analyzeComplexity(task);
    
    // Route based on requirements
    if (complexity < 0.3) {
      return google("gemini-1.5-flash");  // Cheapest
    }
    
    if (complexity < 0.7) {
      return openai("gpt-4o-mini");  // Balanced
    }
    
    if (task.domain === "code") {
      return anthropic("claude-3-5-sonnet");  // Best coding
    }
    
    if (task.requiresReasoning) {
      return openai("o1-mini");  // Reasoning
    }
    
    return openai("gpt-4o");  // Default premium
  }
  
  analyzeComplexity(task: Task): number {
    let score = 0;
    
    if (task.steps > 5) score += 0.3;
    if (task.requiresMath) score += 0.2;
    if (task.requiresCode) score += 0.2;
    if (task.contextLength > 10000) score += 0.1;
    if (task.previousAttemptsFailed) score += 0.2;
    
    return Math.min(score, 1.0);
  }
}
```

### Cascade Pattern

**Concept**: Try cheap model first, escalate if needed

```typescript
async function cascadeGeneration(prompt: string) {
  // Try cheap model first
  const fastResult = await generateText({
    model: google("gemini-1.5-flash"),
    prompt
  });
  
  // Validate quality
  const quality = await assessQuality(fastResult.text);
  
  if (quality > 0.8) {
    return fastResult;  // Good enough! Saved $0.003
  }
  
  // Escalate to better model
  const betterResult = await generateText({
    model: anthropic("claude-3-5-sonnet"),
    prompt: `Improve this response: ${fastResult.text}`
  });
  
  return betterResult;
}
```

### Specialist Pattern

**Concept**: Different models for different subtasks

```typescript
async function generateBlogPost(topic: string) {
  // o1-mini: Create detailed outline (reasoning)
  const outline = await generateText({
    model: openai("o1-mini"),
    prompt: `Create comprehensive blog outline: ${topic}`
  });
  
  // Claude Sonnet: Write content (best writing)
  const content = await generateText({
    model: anthropic("claude-3-5-sonnet"),
    prompt: `Write blog post from outline: ${outline.text}`
  });
  
  // GPT-4o-mini: Generate SEO metadata (simple task)
  const metadata = await generateText({
    model: openai("gpt-4o-mini"),
    prompt: `Generate SEO title/description for: ${content.text}`
  });
  
  return { content, metadata };
}
```

## Provider-Specific Strengths

### OpenAI (GPT-4o, o1)

**Best For**:
- ✅ Tool calling / function calling (industry-leading)
- ✅ Structured outputs (JSON mode, schemas)
- ✅ Agent frameworks (best ecosystem)
- ✅ Multimodal (image + text)
- ✅ Reasoning (o1/o3 models)

**Avoid For**:
- ❌ Long-form creative writing (Claude better)
- ❌ Very long contexts (Gemini 2M tokens)
- ❌ Budget-constrained projects (expensive)

**Your Codebase**: Uses GPT-4o-mini for orchestrator (correct choice for agents)

### Anthropic (Claude)

**Best For**:
- ✅ Coding tasks (best in class)
- ✅ Long-form writing (natural, engaging)
- ✅ Safety/alignment (most careful)
- ✅ Clear explanations (teaching, documentation)
- ✅ 200k context (large codebases)

**Avoid For**:
- ❌ Speed-critical apps (slower than GPT-4o/Gemini)
- ❌ High-volume (more expensive than Gemini)
- ❌ Tool calling (GPT-4 more reliable)

### Google (Gemini)

**Best For**:
- ✅ Long contexts (2M tokens!)
- ✅ Cost efficiency (cheapest premium model)
- ✅ Speed (Flash is fastest)
- ✅ Multimodal (native image/video)
- ✅ Google ecosystem integration

**Avoid For**:
- ❌ Complex reasoning (not as strong as o1/Claude Opus)
- ❌ Creative writing (Claude/GPT better)
- ❌ Critical applications (less mature ecosystem)

## Cost Optimization Strategies

### 1. Prompt Caching

**Save 50-90% on repeated context**:

```typescript
// Without caching: $0.10 per query
const result = await generateText({
  model: anthropic("claude-3-5-sonnet"),
  prompt: `${largeDocumentation}\n\nQuestion: ${userQuestion}`
});

// With caching: $0.01 per query (90% savings)
const result = await generateText({
  model: anthropic("claude-3-5-sonnet"),
  prompt: `${largeDocumentation}\n\nQuestion: ${userQuestion}`,
  cacheControl: { type: "ephemeral" }  // Cache documentation
});
```

**Savings**: For 1000 queries with same context
- Without caching: $100
- With caching: $10 + $10 (first query) = $20
- **Saved: $80 (80%)**

### 2. Batch Processing

**Save 50% with async batching** (OpenAI Batch API):

```typescript
// Real-time: $0.60 per 1M output tokens
const results = await Promise.all(
  tasks.map(task => generateText({ model: openai("gpt-4o-mini"), prompt: task }))
);

// Batch: $0.30 per 1M output tokens (50% off)
const batch = await openai.batches.create({
  requests: tasks.map(task => ({ prompt: task })),
  model: "gpt-4o-mini"
});
// Results in 24 hours
```

### 3. Smart Caching

**Cache common queries**:

```typescript
const cache = new Redis();

async function generateCached(prompt: string) {
  const hash = sha256(prompt);
  const cached = await cache.get(hash);
  
  if (cached) {
    return cached;  // Free!
  }
  
  const result = await generateText({ 
    model: openai("gpt-4o-mini"), 
    prompt 
  });
  
  await cache.set(hash, result.text, { ex: 3600 });  // 1 hour
  return result.text;
}
```

**Example Impact**:
- 10k queries, 30% cache hit rate
- Saves: 3k queries × $0.001 = **$3 per day = $90/month**

### 4. Token Optimization

**Reduce input/output tokens**:

```typescript
// Wasteful: 1000 input tokens
const prompt = `
You are a helpful AI assistant. Please analyze the following 
text and provide insights. Be thorough and detailed in your 
response. Make sure to cover all aspects. Here is the text:

${text}

Please provide your analysis below:
`;

// Optimized: 500 input tokens (50% savings)
const prompt = `Analyze: ${text}`;
```

## Red Flags: When You've Chosen Wrong

### Model is Too Expensive
**Symptoms**:
- Bills increasing faster than usage
- Most queries are simple
- Users don't notice quality

**Solution**: Downgrade to cheaper model
```
Claude Opus → Claude Sonnet (80% cost reduction)
GPT-4 → GPT-4o-mini (95% cost reduction)
o1-preview → GPT-4o (98% cost reduction)
```

### Model is Too Slow
**Symptoms**:
- Users complaining about latency
- >5 seconds response time
- High bounce rates

**Solution**: Switch to faster model
```
Claude Opus → Claude Haiku (5x faster)
o1-preview → GPT-4o-mini (10x faster)
GPT-4 → Gemini Flash (3x faster)
```

### Model is Too Weak
**Symptoms**:
- Frequent errors/hallucinations
- Users re-asking questions
- Tool calling failures

**Solution**: Upgrade to better model
```
GPT-4o-mini → Claude Sonnet (coding)
Gemini Flash → GPT-4o (complex tasks)
GPT-4o → o1-mini (reasoning)
```

### Context Window Too Small
**Symptoms**:
- "Context length exceeded" errors
- Can't process full documents
- Truncating important info

**Solution**: Switch to larger context
```
GPT-4o (128k) → Claude (200k) → Gemini Pro (2M)
```

## Real-World Examples

### Startup: $100/month Budget

**Use Case**: AI chatbot for SaaS product

**Strategy**:
```
90% queries: Gemini Flash        → $30/month (100k queries)
9% queries:  GPT-4o-mini         → $50/month (50k queries)
1% queries:  Claude Sonnet       → $20/month (1k queries)

Total: $100/month for 151k queries
Average cost per query: $0.0007
```

### Enterprise: $10k/month Budget

**Use Case**: Internal AI coding assistant (1000 developers)

**Strategy**:
```
Code completion:  GPT-4o-mini    → $2k/month (2M requests)
Code review:      Claude Sonnet  → $5k/month (100k reviews)
Algorithm design: o1-mini         → $3k/month (10k hard problems)

Total: $10k/month
Average: $10 per developer per month
```

### Healthcare: Accuracy Critical

**Use Case**: Medical documentation assistant

**Strategy**:
```
Document parsing:  Gemini Pro     → $1k/month (cheaper for long docs)
Clinical notes:    Claude Opus    → $5k/month (highest quality)
Verification:      o1-preview     → $2k/month (critical validation)

Total: $8k/month for 10k patient interactions
Quality: 99.5% accuracy (worth the premium)
```

## Quick Reference Decision Tree

```
START HERE
    │
    ├─ Is it simple? (single-turn, factual, formatting)
    │   └─ YES → Gemini Flash or GPT-4o-mini
    │
    ├─ Does it need reasoning? (math, logic, proofs)
    │   └─ YES → o1-mini (cost-efficient) or o3 (best quality)
    │
    ├─ Is it coding?
    │   ├─ Simple → GPT-4o-mini
    │   ├─ Standard → Claude Sonnet
    │   └─ Complex algorithms → o1-mini
    │
    ├─ Is it writing?
    │   ├─ Short-form → GPT-4o-mini
    │   └─ Long-form → Claude Sonnet or Opus
    │
    ├─ Does it need long context? (>100k tokens)
    │   ├─ 200k → Claude
    │   └─ 2M → Gemini Pro
    │
    ├─ Is speed critical? (<2 seconds)
    │   └─ YES → Gemini Flash > GPT-4o-mini > GPT-4o
    │
    └─ Is accuracy critical? (legal, medical, safety)
        └─ YES → Claude Opus or o3

Default: GPT-4o-mini (best all-around value)
```

## Key Takeaways

**Model Selection Principles**:
1. Start with the cheapest model that could work
2. Upgrade only when you see specific limitations
3. Use multiple models for different tasks
4. Monitor cost vs quality metrics constantly
5. Cache aggressively to reduce API calls

**Cost-Quality Spectrum**:
```
Gemini Flash     GPT-4o-mini    Claude Sonnet    o1-mini    Claude Opus    o3
   $0.10            $0.15           $3.00         $3.00       $15.00       $20
   ├────────────────┼──────────────────┼─────────────┼────────────┼──────────┤
  Cheap          Balanced        Quality       Reasoning    Premium    Best
```

**Your Codebase Recommendation**:
- ✅ Keep GPT-4o-mini for agent orchestration (perfect choice)
- ✅ Add o1-mini for complex planning (1-2 calls per session)
- ✅ Add caching for repeated context (system prompts, docs)
- ✅ Expected cost: $10 → $15/month (50% increase, 10x better planning)

## Navigation

- [← Previous: 0.2.2 Reasoning Models Deep Dive](./0.2.2-reasoning-models.md)
- [↑ Back to Knowledge Base TOC](../../AI_KNOWLEDGE_BASE_TOC.md)
- [→ Next: 0.2.4 Cost-Latency-Quality Trade-offs](./0.2.4-tradeoffs.md)

---

*Part of Layer 0: Foundations - Decision frameworks for model selection*
