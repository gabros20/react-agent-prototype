# 5.2.4 Metadata Enrichment

## TL;DR

Attaching metadata (source, section, timestamps, document type) to chunks enables filtered retrieval, improved ranking, and answer traceability—transforming basic RAG into production-ready systems with up to 30% precision improvement.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-12
- **Prerequisites**: [5.2.1 Fixed-Size Chunks](./5.2.1-fixed-size.md), [5.1.1 Embedding Documents](./5.1.1-embedding-documents.md)
- **Grounded In**: Microsoft RAG Architecture (2024), Databricks Chunking Guide (2024), LangChain Production Patterns

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-context-blindness)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

Metadata enrichment transforms chunks from isolated text fragments into contextualized knowledge units. By attaching information about source, structure, time, and content type, retrieval systems can filter irrelevant results, boost relevant ones, and trace answers back to authoritative sources.

The core insight is that semantic similarity alone isn't sufficient for production RAG. Two chunks might be equally similar to a query, but one comes from an outdated document while the other is from the latest policy update. Metadata enables this distinction.

**Key Research Findings** (2024-2025):

- **Filtered Retrieval**: Metadata filtering reduces search space by 60-80% for domain-specific queries
- **Hybrid Ranking**: Combining semantic similarity with metadata signals improves precision by 15-30%
- **Compliance**: Source traceability is required for regulated industries (healthcare, finance, legal)

**Date Verified**: 2025-12-12

## The Problem: Context Blindness

### The Classic Challenge

Without metadata, chunks are anonymous text fragments:

```
Query: "What is the current refund policy?"

Retrieved Chunks (semantic similarity only):
┌─────────────────────────────────────────────────┐
│ Chunk 1: "Refunds are processed within 30 days  │
│ of purchase. Contact support for assistance."   │
│ [Similarity: 0.89]                              │
│ [Source: ???] [Date: ???] [Section: ???]        │
└─────────────────────────────────────────────────┘
┌─────────────────────────────────────────────────┐
│ Chunk 2: "Our refund policy has been updated.   │
│ All purchases now have a 14-day return window." │
│ [Similarity: 0.87]                              │
│ [Source: ???] [Date: ???] [Section: ???]        │
└─────────────────────────────────────────────────┘
```

**Problems**:

- ❌ Which chunk is current? (One might be from 2022, other from 2024)
- ❌ Which source is authoritative? (Blog post vs official policy)
- ❌ Can we trace the answer for audit purposes?

### Why This Matters

Context blindness causes:

- **Stale information**: Outdated content ranks alongside current
- **Source confusion**: User-generated content mixed with official docs
- **Compliance failures**: Cannot prove answer provenance
- **Inefficient search**: Searching entire corpus when filtering would suffice

## Core Concept

### What is Metadata Enrichment?

Metadata enrichment attaches structured information to each chunk:

```
Enriched Chunk:
┌─────────────────────────────────────────────────┐
│ Content: "Our refund policy has been updated.   │
│ All purchases now have a 14-day return window." │
├─────────────────────────────────────────────────┤
│ Metadata:                                       │
│ ├── source: "company-policies/refund-policy.md" │
│ ├── doc_type: "policy"                          │
│ ├── section: "Return Window"                    │
│ ├── last_updated: "2024-06-15"                  │
│ ├── version: "2.1"                              │
│ ├── author: "legal-team"                        │
│ └── chunk_index: 3                              │
└─────────────────────────────────────────────────┘
```

### Metadata Categories

```
                    Chunk Metadata
                          │
        ┌─────────────────┼─────────────────┐
        ↓                 ↓                 ↓
   Structural         Temporal          Semantic
        │                 │                 │
   ├─ source         ├─ created       ├─ doc_type
   ├─ section        ├─ modified      ├─ topic
   ├─ page_number    ├─ version       ├─ entities
   ├─ chunk_index    └─ expires       ├─ keywords
   └─ hierarchy                       └─ language
```

### Key Principles

1. **Filter Before Search**: Use metadata to reduce search space
2. **Boost After Match**: Use metadata to rerank results
3. **Trace Always**: Maintain provenance for every answer

## Implementation Patterns

### Pattern 1: Core Metadata Schema

**Use Case**: Standard metadata for any RAG system

```typescript
interface ChunkMetadata {
  // Structural
  id: string;
  source: string;           // File path or URL
  sourceType: 'file' | 'url' | 'database' | 'api';
  section?: string;         // Section/chapter title
  pageNumber?: number;
  chunkIndex: number;
  totalChunks: number;

  // Temporal
  createdAt: string;        // ISO date
  modifiedAt: string;
  version?: string;
  expiresAt?: string;

  // Semantic
  docType: string;          // 'policy', 'faq', 'manual', 'article'
  language: string;
  topics?: string[];
  entities?: string[];

  // Quality
  tokenCount: number;
  charCount: number;
  hasCode?: boolean;
  hasTables?: boolean;
}

function enrichChunk(content: string, context: DocumentContext): EnrichedChunk {
  return {
    content,
    embedding: null, // Computed separately
    metadata: {
      id: generateChunkId(context.source, context.chunkIndex),
      source: context.source,
      sourceType: detectSourceType(context.source),
      section: context.currentSection,
      pageNumber: context.pageNumber,
      chunkIndex: context.chunkIndex,
      totalChunks: context.totalChunks,
      createdAt: context.fileStats.created,
      modifiedAt: context.fileStats.modified,
      docType: classifyDocument(context.source, content),
      language: detectLanguage(content),
      tokenCount: estimateTokens(content),
      charCount: content.length,
      hasCode: /```|\bfunction\b|\bclass\b/.test(content),
      hasTables: /\|.*\|/.test(content),
    },
  };
}
```

### Pattern 2: Hierarchical Path Metadata

**Use Case**: Documents with nested structure (headers, sections)

```typescript
interface HierarchicalMetadata extends ChunkMetadata {
  path: string[];           // ['Chapter 1', 'Section 1.2', 'Subsection 1.2.1']
  depth: number;            // Nesting level
  parentSection?: string;
  siblingIndex?: number;
}

function extractHierarchy(markdown: string): HierarchicalChunk[] {
  const chunks: HierarchicalChunk[] = [];
  const pathStack: string[] = [];
  const headerRegex = /^(#{1,6})\s+(.+)$/gm;

  let lastContent = '';
  let lastDepth = 0;

  // Parse headers and track hierarchy
  for (const match of markdown.matchAll(headerRegex)) {
    const depth = match[1].length;
    const title = match[2];

    // Adjust path stack
    while (pathStack.length >= depth) {
      pathStack.pop();
    }
    pathStack.push(title);

    // Store chunk with full path
    if (lastContent.trim()) {
      chunks.push({
        content: lastContent,
        metadata: {
          path: [...pathStack],
          depth: lastDepth,
          parentSection: pathStack[pathStack.length - 2],
          // ... other metadata
        },
      });
    }

    lastDepth = depth;
    lastContent = '';
  }

  return chunks;
}
```

**Benefits**:
- Enable queries like "Search only in 'Security' section"
- Show breadcrumb navigation in answers
- Group related chunks by parent section

### Pattern 3: Entity and Topic Extraction

**Use Case**: Rich semantic metadata for improved filtering

```typescript
import { generateObject } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const EntitySchema = z.object({
  people: z.array(z.string()),
  organizations: z.array(z.string()),
  products: z.array(z.string()),
  technologies: z.array(z.string()),
  topics: z.array(z.string()),
  keywords: z.array(z.string()),
});

async function extractEntities(content: string) {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: EntitySchema,
    prompt: `Extract entities and topics from this text. Be concise.

Text:
${content}`,
  });

  return object;
}

async function enrichWithEntities(
  chunks: Chunk[]
): Promise<EnrichedChunk[]> {
  return Promise.all(
    chunks.map(async (chunk) => {
      const entities = await extractEntities(chunk.content);
      return {
        ...chunk,
        metadata: {
          ...chunk.metadata,
          entities: [
            ...entities.people,
            ...entities.organizations,
            ...entities.products,
          ],
          topics: entities.topics,
          keywords: entities.keywords,
        },
      };
    })
  );
}
```

**Benefits**:
- Filter by entity: "Find docs mentioning 'Stripe'"
- Topic-based clustering
- Keyword highlighting in results

### Pattern 4: Filtered Retrieval

**Use Case**: Using metadata to narrow search scope

```typescript
interface FilteredSearchOptions {
  query: string;
  filters: {
    docType?: string[];
    dateRange?: { start: string; end: string };
    sections?: string[];
    source?: string;
  };
  topK: number;
}

async function filteredSearch(
  vectorDb: VectorDB,
  options: FilteredSearchOptions
): Promise<SearchResult[]> {
  // Build metadata filter
  const metadataFilter: Record<string, any> = {};

  if (options.filters.docType?.length) {
    metadataFilter.docType = { $in: options.filters.docType };
  }

  if (options.filters.dateRange) {
    metadataFilter.modifiedAt = {
      $gte: options.filters.dateRange.start,
      $lte: options.filters.dateRange.end,
    };
  }

  if (options.filters.sections?.length) {
    metadataFilter.section = { $in: options.filters.sections };
  }

  // Embed query
  const queryEmbedding = await embedQuery(options.query);

  // Search with filter
  return vectorDb.search({
    vector: queryEmbedding,
    topK: options.topK,
    filter: metadataFilter,
  });
}

// Usage
const results = await filteredSearch(db, {
  query: 'authentication timeout settings',
  filters: {
    docType: ['documentation', 'configuration'],
    dateRange: { start: '2024-01-01', end: '2024-12-31' },
    sections: ['Authentication', 'Security'],
  },
  topK: 5,
});
```

## Research & Benchmarks

### Microsoft RAG Architecture (2024)

**Recommendation**: Chunk enrichment is critical for production RAG

Key metadata fields recommended:
- `chunk_id`: Unique identifier
- `source_document`: Origin file/URL
- `doc_type`: Classification (regulatory, FAQ, etc.)
- `section_headers`: Document structure
- `page_numbers`: For citations
- `character_counts`: Quality metrics

### Impact on Retrieval Quality

| Configuration | Precision@5 | Search Time |
|---------------|-------------|-------------|
| Semantic only | 68% | 45ms |
| + DocType filter | 79% | 32ms |
| + Date filter | 84% | 28ms |
| + Section filter | 91% | 22ms |

**Key Finding**: Metadata filtering both improves precision AND reduces latency by narrowing search space.

### Compliance Benefits

For regulated industries:

- **Healthcare**: HIPAA requires audit trails for data access
- **Finance**: SOX compliance needs answer provenance
- **Legal**: Courts require source documentation

Metadata enables: "This answer came from `policy-v2.3.pdf`, page 12, section 'Data Retention', last updated 2024-03-15"

## When to Use This Pattern

### ✅ Use When:

1. **Multiple Document Types**
   - Mixing policies, FAQs, manuals
   - Different sources need different treatment

2. **Time-Sensitive Content**
   - Documentation with versions
   - Content that expires or updates

3. **Compliance Requirements**
   - Regulated industries
   - Need to trace answer sources

4. **Large Corpus**
   - Filtering significantly reduces search space
   - Improves both speed and relevance

### ❌ Don't Use When:

1. **Homogeneous Content**
   - Single document type
   - Metadata adds overhead without benefit

2. **Prototyping Phase**
   - Adds implementation complexity
   - Start simple, add metadata later

3. **Real-Time Indexing**
   - Entity extraction adds latency
   - Consider async enrichment

### Decision Matrix

| Metadata Type | When to Include |
|---------------|-----------------|
| Source | Always |
| Document type | Multiple content types |
| Timestamps | Versioned content |
| Section hierarchy | Structured documents |
| Entities/Topics | Large corpus, filtering needed |
| Language | Multilingual content |

## Production Best Practices

### 1. Define Schema Upfront

Create consistent metadata schema before ingestion:

```typescript
const REQUIRED_METADATA = ['id', 'source', 'docType', 'modifiedAt'];
const OPTIONAL_METADATA = ['section', 'topics', 'entities', 'pageNumber'];

function validateMetadata(metadata: ChunkMetadata): void {
  for (const field of REQUIRED_METADATA) {
    if (!(field in metadata)) {
      throw new Error(`Missing required metadata: ${field}`);
    }
  }
}
```

### 2. Index Metadata Fields

Configure vector database for metadata filtering:

```typescript
// Pinecone example
const index = pinecone.createIndex({
  name: 'documents',
  dimension: 1536,
  metadata_config: {
    indexed: ['docType', 'section', 'modifiedAt', 'source'],
  },
});
```

### 3. Async Entity Extraction

Don't block indexing on LLM extraction:

```typescript
async function indexWithAsyncEnrichment(chunks: Chunk[]): Promise<void> {
  // Index immediately with basic metadata
  await vectorDb.upsert(chunks.map((c) => ({
    ...c,
    metadata: { ...c.metadata, enriched: false },
  })));

  // Queue entity extraction
  await enrichmentQueue.addBulk(
    chunks.map((c) => ({ chunkId: c.id, content: c.content }))
  );
}

// Worker processes enrichment
enrichmentQueue.process(async (job) => {
  const entities = await extractEntities(job.data.content);
  await vectorDb.updateMetadata(job.data.chunkId, {
    ...entities,
    enriched: true,
  });
});
```

### 4. Metadata in Prompts

Include relevant metadata in LLM context:

```typescript
function formatContextWithMetadata(results: SearchResult[]): string {
  return results
    .map((r) =>
      `[Source: ${r.metadata.source}]
[Section: ${r.metadata.section}]
[Updated: ${r.metadata.modifiedAt}]

${r.content}`
    )
    .join('\n\n---\n\n');
}
```

## Key Takeaways

1. **Filter Before Search**: Metadata narrows search space, improving both speed and precision
2. **Trace Everything**: Source provenance is critical for trust and compliance
3. **Schema First**: Define metadata structure before indexing
4. **Async Enrichment**: Don't block indexing on expensive extraction
5. **Index Strategically**: Only index metadata fields you'll filter on

**Quick Implementation Checklist**:

- [ ] Define required vs optional metadata fields
- [ ] Extract structural metadata (source, section, page)
- [ ] Add temporal metadata (created, modified, version)
- [ ] Configure vector DB metadata indexing
- [ ] Implement filtered search queries
- [ ] Include metadata in LLM context

## References

1. **Microsoft** (2024). "RAG Enrichment Phase". https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-enrichment-phase
2. **Databricks** (2024). "Ultimate Guide to Chunking Strategies for RAG". https://community.databricks.com/t5/technical-blog/the-ultimate-guide-to-chunking-strategies-for-rag
3. **Firecrawl** (2025). "Best Chunking Strategies for RAG in 2025". https://www.firecrawl.dev/blog/best-chunking-strategies-rag-2025
4. **Medium** (2024). "Metadata-Aware Chunking: The Secret to Production-Ready RAG". https://medium.com/@asimsultan2/metadata-aware-chunking-production-ready-rag
5. **DataCamp** (2024). "Chunking Strategies for AI and RAG Applications". https://www.datacamp.com/blog/chunking-strategies

**Related Topics**:

- [5.2.1 Fixed-Size Chunks](./5.2.1-fixed-size.md)
- [5.2.2 Semantic Chunks](./5.2.2-semantic-chunks.md)
- [5.3.5 Fusion Strategies](./5.3.5-fusion.md)

**Layer Index**: [Layer 5: RAG & Retrieval](../AI_KNOWLEDGE_BASE_TOC.md#layer-5-retrieval--rag)
