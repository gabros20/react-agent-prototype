# 5.1.3 - Vector Index Types: HNSW, IVF, Flat

## TL;DR

**Vector indexes enable fast approximate nearest neighbor (ANN) search across millions of vectors—HNSW is the production default (95%+ recall, <100ms latency), IVF is better for very large datasets (>100M vectors) with memory constraints, and Flat is only for prototyping (<10K vectors).**

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-12
- **Prerequisites**: [5.1.2 Similarity Metrics](./5.1.2-similarity-metrics.md)
- **Grounded In**: Milvus (2024), Pinecone (2024), VIBE Benchmark (2025)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-search-at-scale)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

Vector indexes are data structures that enable fast approximate nearest neighbor (ANN) search across millions or billions of vectors. Without an index, finding the k-nearest vectors requires comparing the query against every stored vector (O(N))—impractical at scale.

Three index types dominate production systems: **HNSW** (graph-based, highest accuracy), **IVF** (partition-based, memory-efficient), and **Flat** (brute force, exact but slow). HNSW is the gold standard for most RAG applications, achieving 95%+ recall with sub-100ms latency.

**Key Research Findings (2024-2025)**:

- **HNSW dominance**: Best default choice—**95%+ recall, <100ms latency** at 10M vectors ([Milvus, 2024](https://milvus.io/blog/understanding-ivf-vector-index-how-It-works-and-when-to-choose-it-over-hnsw.md))
- **HNSW vs IVF**: HNSW is **3× faster** with better accuracy than IVFFlat ([MyScale, 2024](https://www.myscale.com/blog/hnsw-vs-ivf-explained-powerful-comparison/))
- **IVF advantage**: **10-20× faster indexing** and lower memory than HNSW ([Milvus, 2024](https://milvus.io/blog/understanding-ivf-vector-index-how-It-works-and-when-to-choose-it-over-hnsw.md))
- **Filtering challenge**: Metadata filters can **slow searches 2-10×**; use integrated filtering ([Pinecone, 2024](https://yudhiesh.github.io/2025/05/09/the-achilles-heel-of-vector-search-filters))

## The Problem: Search at Scale

### The Classic Challenge

Without an index, vector search is O(N)—linearly slow as dataset grows:

```
Dataset Size → Query Latency (brute force)
─────────────────────────────────────────
10K vectors  → 10ms   ✓ Acceptable
100K vectors → 100ms  ⚠️ Slow
1M vectors   → 850ms  ❌ Too slow
10M vectors  → 8.5s   ❌ Unusable
100M vectors → 85s    ❌ Impossible
```

**Problems**:

- ❌ **Linear scaling**: 10× more data = 10× slower queries
- ❌ **Memory pressure**: Must load all vectors to compute distances
- ❌ **Cost explosion**: More compute for same results
- ❌ **User experience**: >100ms latency = noticeable delay

### Why This Matters

RAG systems need sub-second retrieval to feel responsive. A 10M document knowledge base with brute force search would take 8+ seconds per query—unacceptable for production. Indexes trade perfect recall (100%) for dramatic speed improvements (1000×).

## Core Concept

### The Three Core Index Types

```
┌─────────────────────────────────────────────────────────────────┐
│                    HNSW (Graph-Based)                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Layer 2 (coarse):  A ──────── E ──────── I                    │
│                     │          │          │                     │
│  Layer 1 (medium):  A ── B ── E ── F ── I ── J                 │
│                     │    │    │    │    │    │                  │
│  Layer 0 (fine):    A-B-C-D-E-F-G-H-I-J-K-L                    │
│                     └─ All vectors stored here ─┘               │
│                                                                  │
│  Search: Start top layer → descend → find neighbors            │
│  Complexity: O(log N)                                           │
│                                                                  │
├─────────────────────────────────────────────────────────────────┤
│                    IVF (Partition-Based)                        │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  Cluster 1 (tech):    [vec1, vec4, vec7, vec12, ...]           │
│  Cluster 2 (health):  [vec2, vec5, vec9, vec15, ...]           │
│  Cluster 3 (finance): [vec3, vec6, vec8, vec11, ...]           │
│                                                                  │
│  Search: Find closest cluster → search within cluster          │
│  Complexity: O(N/k) where k = number of clusters               │
│                                                                  │
├─────────────────────────────────────────────────────────────────┤
│                    Flat (Brute Force)                           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  [vec1][vec2][vec3][vec4]...[vecN]                             │
│     ↑     ↑     ↑     ↑        ↑                                │
│     └─────┴─────┴─────┴────────┘                                │
│         Compare query to ALL vectors                            │
│                                                                  │
│  Search: Compare every vector                                   │
│  Complexity: O(N)                                               │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

### Key Characteristics

| Index | Speed | Recall | Memory | Build Time | Updates |
|-------|-------|--------|--------|------------|---------|
| **HNSW** | Fastest | 95-99% | High | Slow | Good |
| **IVF** | Fast | 90-95% | Low | Fast | Poor |
| **Flat** | Slow | 100% | Medium | None | Good |

## Implementation Patterns

### Pattern 1: HNSW (Production Default)

**Use Case**: Most RAG applications, frequent updates, high accuracy requirements

HNSW builds a multi-layer graph where each node connects to nearby neighbors. Searches start at the top (sparse) layer and descend to find nearest neighbors.

```typescript
// HNSW parameters
interface HNSWConfig {
  M: number; // Max connections per node (default: 16)
  efConstruction: number; // Build-time search depth (default: 200)
  efSearch: number; // Query-time search depth (default: 50)
}

// Higher M = better recall, more memory
// Higher ef = better accuracy, slower search
```

**Pros**:

- ✅ **Highest recall**: 95-99% with proper tuning
- ✅ **Fastest queries**: <100ms for 10M vectors
- ✅ **Supports updates**: O(log N) insertion/deletion

**Cons**:

- ❌ **Memory intensive**: 2-4× vector size for graph storage
- ❌ **Slow initial build**: Hours for 100M vectors
- ❌ **Filtering degrades**: Graph fragmentation with high filter ratios

**When to Use**: Default choice for <50M vectors, frequent updates, high accuracy needs

### Pattern 2: IVF (Large-Scale, Memory-Efficient)

**Use Case**: Very large datasets (>100M vectors), batch updates, memory constraints

IVF partitions vectors into clusters using K-means, then searches only relevant clusters.

```typescript
// IVF parameters
interface IVFConfig {
  nlist: number; // Number of clusters (default: sqrt(N))
  nprobe: number; // Clusters to search at query time (default: 10)
}

// More nlist = finer partitioning, faster search
// More nprobe = better recall, slower search
// Rule of thumb: nlist = sqrt(N), nprobe = 1-10% of nlist
```

**Pros**:

- ✅ **10-20× faster indexing** than HNSW
- ✅ **Lower memory**: Stores cluster assignments, not graph
- ✅ **GPU-friendly**: Easy to parallelize
- ✅ **Better for filtered search**: Clusters can align with metadata

**Cons**:

- ❌ **Lower recall**: 90-95% typical vs 95-99% for HNSW
- ❌ **Requires training**: Must train on representative data
- ❌ **Update-unfriendly**: New data may require re-clustering

**When to Use**: >100M vectors, batch updates, memory-constrained environments

### Pattern 3: Flat Index (Prototyping Only)

**Use Case**: Small datasets (<10K), prototyping, accuracy validation

Flat index stores vectors and computes distance to all during search—exact but slow.

```typescript
// Flat index: No approximation, 100% recall
class FlatIndex {
  private vectors: { id: string; vector: number[] }[] = [];

  search(query: number[], k: number) {
    return this.vectors
      .map((v) => ({
        id: v.id,
        score: cosineSimilarity(query, v.vector),
      }))
      .sort((a, b) => b.score - a.score)
      .slice(0, k);
  }
}
```

**Pros**:

- ✅ **100% recall**: Exact nearest neighbors
- ✅ **No training**: Just store vectors
- ✅ **Simple debugging**: Easy to verify results

**Cons**:

- ❌ **O(N) search**: Linearly slow
- ❌ **Impractical at scale**: 850ms for 1M vectors

**When to Use**: <10K vectors, validating ANN accuracy, debugging

## Framework Integration

### LanceDB with HNSW

```typescript
import { connect } from 'vectordb';

const db = await connect('./data/lancedb');

// Create table
await db.createTable('documents', [
  {
    id: '1',
    text: 'Next.js performance guide',
    vector: embedding,
  },
]);

const table = await db.openTable('documents');

// Create HNSW index
await table.createIndex({
  column: 'vector',
  type: 'IVF_PQ', // LanceDB uses IVF_PQ by default
  config: {
    nlist: 1000, // Clusters
    nprobe: 20, // Clusters to search
  },
});

// Search
const results = await table.search(queryEmbedding).limit(10).execute();
```

### Pinecone Index Configuration

```typescript
import { Pinecone } from '@pinecone-database/pinecone';

const pinecone = new Pinecone({ apiKey: process.env.PINECONE_API_KEY });

// Create index with specific configuration
await pinecone.createIndex({
  name: 'documents',
  dimension: 1536,
  metric: 'cosine',
  spec: {
    serverless: {
      cloud: 'aws',
      region: 'us-east-1',
    },
  },
});

// Pinecone manages index type automatically
// Uses HNSW-like algorithm internally
```

### pgvector with PostgreSQL

```sql
-- Enable extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create table with vector column
CREATE TABLE documents (
  id SERIAL PRIMARY KEY,
  content TEXT,
  embedding vector(1536)
);

-- Create HNSW index (recommended)
CREATE INDEX ON documents
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Or IVFFlat for memory efficiency
CREATE INDEX ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Query with vector similarity
SELECT content, embedding <=> query_embedding AS distance
FROM documents
ORDER BY distance
LIMIT 10;
```

## Research & Benchmarks

### Performance Comparison (1M Vectors, 1536 Dimensions)

| Index Type | Build Time | Memory | Query Latency | Recall@10 |
|------------|-----------|--------|---------------|-----------|
| **Flat** | 0s | 6 GB | 850ms | 100% |
| **IVF (nlist=1000)** | 2min | 7 GB | 12ms | 92% |
| **HNSW (M=16)** | 15min | 24 GB | 8ms | 96% |
| **HNSW (M=32)** | 25min | 48 GB | 6ms | 98% |

### Scaling Characteristics

```
Query Latency vs Dataset Size:

Latency (ms)
1000 |                              Flat ────────
     |                           /
 100 |                        /
     |                IVF  /
  10 |           ────/────
     |    HNSW──/
   1 |───/──────
     +──────────────────────────────────────
       10K  100K   1M   10M    Vectors

HNSW: O(log N) - logarithmic growth
IVF:  O(N/k)   - sublinear growth
Flat: O(N)     - linear growth
```

## When to Use This Pattern

### ✅ Use HNSW When:

1. **General production RAG**
   - Need >95% recall
   - Query latency <100ms required

2. **Frequent updates**
   - Adding/removing documents daily
   - Real-time indexing requirements

3. **Memory available**
   - Can allocate 2-4× vector storage for graph

### ✅ Use IVF When:

1. **Very large scale (>100M vectors)**
   - HNSW memory too expensive
   - Batch updates acceptable

2. **GPU available**
   - IVF parallelizes well
   - FAISS GPU implementation

3. **Filtered search common**
   - Filters align with cluster boundaries
   - Less graph fragmentation

### ✅ Use Flat When:

1. **Prototyping**
   - Validating embedding quality
   - Testing retrieval pipeline

2. **Small datasets (<10K)**
   - Index overhead not worth it
   - Exact results needed

### Decision Matrix

| Dataset Size | Recommended Index | Configuration |
|--------------|------------------|---------------|
| **< 10K** | Flat | No index needed |
| **10K - 1M** | HNSW | M=16, efSearch=50 |
| **1M - 10M** | HNSW | M=16-32, efSearch=100 |
| **10M - 100M** | IVF + PQ | nlist=10K, nprobe=20 |
| **100M+** | IVF + PQ or DiskANN | Distributed setup |

## Production Best Practices

### 1. Tune HNSW Parameters

```typescript
// Conservative (high recall)
const highRecall = { M: 32, efConstruction: 400, efSearch: 100 };
// Recall: 98%, Latency: ~10ms, Memory: 4× vectors

// Balanced (default)
const balanced = { M: 16, efConstruction: 200, efSearch: 50 };
// Recall: 96%, Latency: ~8ms, Memory: 2× vectors

// Fast (lower recall)
const fast = { M: 8, efConstruction: 100, efSearch: 20 };
// Recall: 90%, Latency: ~5ms, Memory: 1.5× vectors
```

### 2. Handle Filtered Search Properly

```typescript
// BAD: Post-filter (wastes retrieval)
const results = await index.search(query, { topK: 1000 });
const filtered = results.filter((r) => r.category === 'tech').slice(0, 10);
// Problem: Retrieved 1000, kept 10

// GOOD: Integrated filtering (vector DB feature)
const results = await index.query({
  vector: queryEmbedding,
  topK: 10,
  filter: { category: { $eq: 'tech' } },
});
// Vector DB optimizes filter + ANN together
```

### 3. Monitor Recall Quality

```typescript
// Periodically validate ANN accuracy vs exact search
async function measureRecall(testQueries: number[][], index: VectorIndex) {
  const recalls: number[] = [];

  for (const query of testQueries) {
    const annResults = await index.search(query, { topK: 10 });
    const exactResults = await flatIndex.search(query, { topK: 10 });

    const annIds = new Set(annResults.map((r) => r.id));
    const hits = exactResults.filter((r) => annIds.has(r.id)).length;
    recalls.push(hits / 10);
  }

  const avgRecall = recalls.reduce((a, b) => a + b, 0) / recalls.length;
  console.log(`Recall@10: ${(avgRecall * 100).toFixed(1)}%`);

  if (avgRecall < 0.9) {
    console.warn('Recall below 90%! Consider increasing efSearch or M');
  }
}
```

### Common Pitfalls

#### ❌ Pitfall: Using Flat for Large Datasets

**Problem**: Query latency becomes unacceptable.

```
1M vectors × 1536 dims × 4 bytes = 6GB to scan per query
Result: 850ms per query (8.5s for 10M)
```

**Solution**: Switch to HNSW or IVF at >10K vectors.

#### ❌ Pitfall: Under-Provisioning HNSW Parameters

**Problem**: Low M and efSearch result in poor recall.

```typescript
// BAD: Recall ~75%
const config = { M: 8, efSearch: 10 };

// GOOD: Recall ~96%
const config = { M: 16, efSearch: 50 };
```

#### ❌ Pitfall: Not Training IVF on Representative Data

**Problem**: Clusters don't match actual data distribution.

```typescript
// BAD: Train on random sample, deploy on different data
await index.train(randomSample);
await index.add(actualData); // Clusters don't fit!

// GOOD: Train on actual data sample
const trainingSample = actualData.slice(0, Math.min(100000, actualData.length));
await index.train(trainingSample);
await index.add(actualData);
```

## Key Takeaways

1. **HNSW is the production default** - 95%+ recall, <100ms latency, handles updates well
2. **IVF for extreme scale** - Use at >100M vectors when memory is constrained
3. **Flat for prototyping only** - Never deploy with >10K vectors
4. **Tune parameters for your use case** - Higher M/efSearch = better recall, more memory
5. **Monitor recall in production** - ANN accuracy can degrade with data drift

**Quick Implementation Checklist**:

- [ ] Choose index type based on dataset size
- [ ] Configure HNSW: M=16, efConstruction=200, efSearch=50 (start here)
- [ ] Use integrated filtering (not post-filtering)
- [ ] Monitor recall with test queries
- [ ] Plan for index rebuilds as data grows

## References

1. **Milvus** (2024). "IVF vs HNSW: How to Choose". https://milvus.io/blog/understanding-ivf-vector-index-how-It-works-and-when-to-choose-it-over-hnsw.md
2. **MyScale** (2024). "HNSW vs IVF Explained". https://www.myscale.com/blog/hnsw-vs-ivf-explained-powerful-comparison/
3. **Supabase** (2024). "HNSW Indexes". https://supabase.com/docs/guides/ai/vector-indexes/hnsw-indexes
4. **VIBE Benchmark** (2025). "Vector Index Benchmark for Embeddings". *arXiv*. https://arxiv.org/abs/2505.17810
5. **Zilliz** (2024). "How to Pick a Vector Index". https://zilliz.com/learn/how-to-pick-a-vector-index-in-milvus-visual-guide

**Related Topics**:

- [5.1.2 Similarity Metrics](./5.1.2-similarity-metrics.md)
- [5.1.4 Query Strategies](./5.1.4-query-strategies.md)
- [4.3.1 Vector Databases](../4-memory/4.3.1-vector-databases.md)

**Layer Index**: [Layer 5: RAG & Retrieval](../AI_KNOWLEDGE_BASE_TOC.md#layer-5-rag--retrieval)
