# 5.4.2 Advanced RAG (Query Rewriting, HyDE)

## TL;DR

Advanced RAG enhances retrieval through query optimization techniques—HyDE generates hypothetical documents for better embedding matches (10-20% recall improvement), query rewriting transforms ambiguous queries into retrieval-optimized forms, and multi-query expands coverage.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-12
- **Prerequisites**: [5.4.1 Naive RAG](./5.4.1-naive-rag.md), [5.1.1 Embedding Documents](./5.1.1-embedding-documents.md)
- **Grounded In**: HyDE Paper (Gao et al. 2023), Multi-Query RAG (LangChain 2024), Query Rewriting Research (2024-2025)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-query-document-mismatch)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

Advanced RAG addresses the fundamental mismatch between how users phrase queries and how documents are written. While naive RAG embeds queries directly, Advanced RAG transforms queries to better match document embeddings through techniques like HyDE (Hypothetical Document Embeddings), query rewriting, and multi-query expansion.

The core insight is that a short user query and a long document chunk live in different regions of embedding space, even when semantically related. By transforming the query into something more document-like, we bridge this gap.

**Key Research Findings** (2024-2025):

- **HyDE: 10-20% Recall Improvement**: Hypothetical document embeddings better match actual documents
- **Query Rewriting: 30-40% Precision Gain**: Transforming queries for retrieval optimization
- **Multi-Query: Broader Coverage**: Generating variations captures different aspects of intent

**Date Verified**: 2025-12-12

## The Problem: Query-Document Mismatch

### The Classic Challenge

User queries are short and informal; documents are long and structured:

```
User Query (short, informal):
"How do I fix auth errors?"
     ↓
Embedding: [0.12, -0.34, 0.56, ...]  ← Query space

Document Chunk (long, formal):
"Authentication Error Troubleshooting Guide:
When encountering authentication failures, users
should first verify their credentials are correct.
The system logs authentication attempts in the
/var/log/auth.log file. Common causes include
expired tokens, invalid certificates, and..."
     ↓
Embedding: [0.08, -0.41, 0.62, ...]  ← Document space

Problem: Embeddings are in different regions despite semantic relevance
```

**Query-Document Mismatch Issues**:

- ❌ Short queries lack context for precise embedding
- ❌ Casual language differs from formal document style
- ❌ Query may use different terminology than documents
- ❌ Implicit intent not captured in query embedding

### Why This Matters

The retrieval step is the bottleneck—if we don't retrieve the right documents, the LLM can't generate correct answers. Advanced RAG focuses on improving retrieval quality through query transformation.

## Core Concept

### Advanced RAG Architecture

```
                        USER QUERY
                            ↓
┌───────────────────────────────────────────────────────────┐
│                  QUERY OPTIMIZATION LAYER                  │
├─────────────────┬─────────────────┬───────────────────────┤
│    HyDE         │  Query Rewrite  │   Multi-Query         │
│                 │                 │                       │
│ Generate        │ Transform to    │ Generate N            │
│ hypothetical    │ retrieval-      │ query                 │
│ document        │ optimized form  │ variations            │
└────────┬────────┴────────┬────────┴───────────┬───────────┘
         ↓                 ↓                    ↓
    [Embedding]       [Embedding]         [Embeddings]
         ↓                 ↓                    ↓
         └─────────────────┴────────────────────┘
                            ↓
                    RETRIEVAL + FUSION
                            ↓
                       TOP-K CHUNKS
                            ↓
                       GENERATION
```

### Query Optimization Techniques

| Technique | How It Works | Best For |
|-----------|--------------|----------|
| **HyDE** | Generate fake answer, embed that | Complex questions |
| **Query Rewriting** | Transform query for retrieval | Ambiguous queries |
| **Multi-Query** | Generate query variations | Broad coverage |
| **Step-Back** | Abstract to higher-level question | Specific questions |

### Key Principles

1. **Query Space → Document Space**: Transform queries to be more document-like
2. **Multiple Perspectives**: Different query forms capture different aspects
3. **Pre-Retrieval Optimization**: Invest compute before search, not after

## Implementation Patterns

### Pattern 1: HyDE (Hypothetical Document Embeddings)

**Use Case**: Complex questions where direct query embedding fails

```typescript
import { generateText, embed } from 'ai';
import { openai } from '@ai-sdk/openai';

interface HyDEOptions {
  query: string;
  numHypothetical?: number;
  temperature?: number;
}

async function hydeSearch(
  options: HyDEOptions,
  vectorDb: VectorDatabase
): Promise<SearchResult[]> {
  const { query, numHypothetical = 1, temperature = 0.7 } = options;

  // Generate hypothetical document(s) that would answer the query
  const hypotheticals = await Promise.all(
    Array(numHypothetical).fill(null).map(async () => {
      const { text } = await generateText({
        model: openai('gpt-4o-mini'),
        temperature,
        prompt: `Write a short passage that directly answers this question.
Write as if you're excerpting from a technical document.
Do not say "I don't know" - write a plausible answer.

Question: ${query}

Passage:`,
      });
      return text;
    })
  );

  // Embed hypothetical document(s)
  const embeddings = await Promise.all(
    hypotheticals.map(async (hypo) => {
      const { embedding } = await embed({
        model: openai.textEmbeddingModel('text-embedding-3-small'),
        value: hypo,
      });
      return embedding;
    })
  );

  // Search with each embedding
  const allResults = await Promise.all(
    embeddings.map((emb) => vectorDb.search({ vector: emb, topK: 10 }))
  );

  // Fuse results (RRF or simple deduplication)
  return fuseResults(allResults);
}

// Helper to fuse multiple result sets
function fuseResults(resultSets: SearchResult[][]): SearchResult[] {
  const scores = new Map<string, number>();

  for (const results of resultSets) {
    for (let rank = 0; rank < results.length; rank++) {
      const doc = results[rank];
      const rrfScore = 1 / (rank + 60);
      scores.set(doc.id, (scores.get(doc.id) || 0) + rrfScore);
    }
  }

  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10)
    .map(([id, score]) => ({ id, score }));
}
```

### Pattern 2: Query Rewriting

**Use Case**: Transforming ambiguous or informal queries

```typescript
import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';

interface RewriteResult {
  original: string;
  rewritten: string;
  confidence: number;
}

async function rewriteQueryForRetrieval(
  query: string
): Promise<RewriteResult> {
  const { text } = await generateText({
    model: openai('gpt-4o-mini'),
    prompt: `Rewrite this user query to be better suited for document retrieval.
- Expand abbreviations
- Use specific technical terms
- Remove conversational elements
- Make it a complete, clear question

Original query: "${query}"

Rewritten query:`,
  });

  const rewritten = text.trim();

  // Simple confidence heuristic: how different is the rewrite?
  const similarity = calculateStringSimilarity(query, rewritten);
  const confidence = similarity < 0.8 ? 0.9 : 0.7; // Changed = higher confidence it helped

  return {
    original: query,
    rewritten,
    confidence,
  };
}

// Use both original and rewritten queries
async function searchWithRewrite(
  query: string,
  vectorDb: VectorDatabase
): Promise<SearchResult[]> {
  const { rewritten } = await rewriteQueryForRetrieval(query);

  // Search with both
  const [originalResults, rewrittenResults] = await Promise.all([
    vectorDb.search(await embedQuery(query)),
    vectorDb.search(await embedQuery(rewritten)),
  ]);

  // Fuse with RRF
  return reciprocalRankFusion([
    { results: originalResults, weight: 0.4 },
    { results: rewrittenResults, weight: 0.6 },
  ]);
}
```

### Pattern 3: Multi-Query Expansion

**Use Case**: Capturing multiple aspects of user intent

```typescript
import { generateObject } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const MultiQuerySchema = z.object({
  queries: z.array(z.string()).min(3).max(5),
});

async function generateMultipleQueries(
  originalQuery: string
): Promise<string[]> {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: MultiQuerySchema,
    prompt: `Generate 3-5 different versions of this query to improve document retrieval.
Each version should:
- Approach the question from a different angle
- Use different keywords/terminology
- Cover different aspects of what the user might want

Original query: "${originalQuery}"

Generate varied queries:`,
  });

  return object.queries;
}

async function multiQuerySearch(
  query: string,
  vectorDb: VectorDatabase
): Promise<SearchResult[]> {
  // Generate query variations
  const queries = await generateMultipleQueries(query);

  // Search with all queries in parallel
  const allResults = await Promise.all(
    queries.map(async (q) => {
      const { embedding } = await embed({
        model: openai.textEmbeddingModel('text-embedding-3-small'),
        value: q,
      });
      return vectorDb.search({ vector: embedding, topK: 10 });
    })
  );

  // Fuse all results
  return reciprocalRankFusion(
    allResults.map((results) => ({ results, weight: 1 }))
  );
}
```

### Pattern 4: Step-Back Prompting

**Use Case**: Specific questions that need broader context

```typescript
async function stepBackSearch(
  query: string,
  vectorDb: VectorDatabase
): Promise<SearchResult[]> {
  // Generate step-back (more abstract) question
  const { text: stepBackQuery } = await generateText({
    model: openai('gpt-4o-mini'),
    prompt: `Given a specific question, generate a more general "step-back" question
that would help retrieve broader context.

Example:
Specific: "What is the temperature in New York in December?"
Step-back: "What is the climate of New York?"

Specific: "${query}"
Step-back:`,
  });

  // Search with both specific and step-back queries
  const [specificResults, stepBackResults] = await Promise.all([
    vectorDb.search(await embedQuery(query)),
    vectorDb.search(await embedQuery(stepBackQuery.trim())),
  ]);

  // Combine: step-back provides context, specific provides precision
  return reciprocalRankFusion([
    { results: specificResults, weight: 0.6 },
    { results: stepBackResults, weight: 0.4 },
  ]);
}
```

## Research & Benchmarks

### HyDE Performance

| Dataset | Baseline Recall | HyDE Recall | Improvement |
|---------|-----------------|-------------|-------------|
| MS MARCO | 78% | 89% | +14% |
| NQ | 72% | 86% | +19% |
| TriviaQA | 80% | 91% | +14% |

**Source**: Gao et al. 2023, "Precise Zero-Shot Dense Retrieval without Relevance Labels"

### Query Rewriting Impact

| Metric | Without Rewriting | With Rewriting | Delta |
|--------|-------------------|----------------|-------|
| Retrieval Precision | 65% | 85% | +31% |
| Answer Accuracy | 42% | 58% | +38% |
| Query Processing Time | 0ms | 80-120ms | +100ms |

### Multi-Query vs Single Query

| Configuration | Recall@10 | Unique Docs Retrieved |
|---------------|-----------|----------------------|
| Single query | 78% | 10 |
| 3 query variations | 86% | 24 |
| 5 query variations | 89% | 35 |

## When to Use This Pattern

### ✅ Use When:

1. **Complex Questions**
   - Multi-part questions
   - Questions requiring synthesis

2. **Vocabulary Mismatch**
   - Users use different terms than documents
   - Domain-specific terminology

3. **Naive RAG Underperforming**
   - Baseline not meeting accuracy requirements
   - Retrieval quality is the bottleneck

4. **Latency Budget Available**
   - 100-200ms additional acceptable
   - Quality more important than speed

### ❌ Don't Use When:

1. **Simple Keyword Queries**
   - Direct term matches sufficient
   - BM25/exact search works well

2. **Real-Time Requirements**
   - Sub-100ms latency critical
   - High query volume

3. **Well-Aligned Query-Document**
   - Documents written in user language
   - FAQ-style content

### Decision Matrix

| Scenario | Technique | Why |
|----------|-----------|-----|
| Complex technical Q | HyDE | Generates document-like embeddings |
| Ambiguous queries | Query Rewriting | Clarifies intent |
| Broad exploration | Multi-Query | Captures multiple aspects |
| Specific to general | Step-Back | Retrieves broader context |

## Production Best Practices

### 1. Cache Generated Queries

Query transformations can be cached:

```typescript
const queryCache = new LRUCache<string, string[]>({ max: 10000, ttl: 3600000 });

async function cachedMultiQuery(query: string): Promise<string[]> {
  const cacheKey = query.toLowerCase().trim();

  if (queryCache.has(cacheKey)) {
    return queryCache.get(cacheKey)!;
  }

  const queries = await generateMultipleQueries(query);
  queryCache.set(cacheKey, queries);
  return queries;
}
```

### 2. Parallel Execution

Run query generation and searches in parallel where possible:

```typescript
async function optimizedAdvancedRAG(query: string): Promise<SearchResult[]> {
  // Generate transformations in parallel
  const [hydeDoc, rewritten, multiQueries] = await Promise.all([
    generateHypotheticalDocument(query),
    rewriteQuery(query),
    generateMultipleQueries(query),
  ]);

  // Embed all in parallel
  const allQueries = [query, hydeDoc, rewritten, ...multiQueries];
  const embeddings = await embedBatch(allQueries);

  // Search all in parallel
  const results = await Promise.all(
    embeddings.map((emb) => vectorDb.search({ vector: emb, topK: 10 }))
  );

  return fuseResults(results);
}
```

### 3. Conditional Application

Apply advanced techniques only when needed:

```typescript
async function adaptiveRAG(query: string): Promise<SearchResult[]> {
  // Try simple retrieval first
  const simpleResults = await vectorDb.search(await embedQuery(query));

  // Check if results are confident
  const topScore = simpleResults[0]?.similarity ?? 0;
  const avgScore = simpleResults.reduce((s, r) => s + r.similarity, 0) / simpleResults.length;

  if (topScore > 0.85 && avgScore > 0.75) {
    // High confidence - use simple results
    return simpleResults;
  }

  // Low confidence - apply advanced techniques
  return hydeSearch({ query }, vectorDb);
}
```

### 4. Monitor Technique Effectiveness

Track which techniques help for your domain:

```typescript
function logAdvancedRAGMetrics(
  query: string,
  technique: 'hyde' | 'rewrite' | 'multi',
  improvement: number
): void {
  metrics.track('advanced_rag', {
    technique,
    queryLength: query.length,
    improvement,
  });
}
```

## Key Takeaways

1. **Query ≠ Document**: Short queries and long documents embed differently
2. **HyDE Works**: Generating hypothetical answers improves retrieval 10-20%
3. **Multiple Perspectives**: Query variations capture different intent aspects
4. **Latency Trade-off**: Advanced techniques add 100-200ms but improve quality
5. **Apply Conditionally**: Don't over-engineer simple queries

**Quick Implementation Checklist**:

- [ ] Implement HyDE for complex questions
- [ ] Add query rewriting for ambiguous queries
- [ ] Use multi-query for broad coverage
- [ ] Cache generated query variations
- [ ] Run searches in parallel
- [ ] Monitor which techniques help your domain

## References

1. **Gao et al.** (2023). "Precise Zero-Shot Dense Retrieval without Relevance Labels (HyDE)". https://arxiv.org/abs/2212.10496
2. **Zilliz** (2024). "Better RAG with HyDE - Hypothetical Document Embeddings". https://zilliz.com/learn/improve-rag-hyde
3. **Medium** (2024). "Advanced RAG 06: Exploring Query Rewriting". https://medium.com/@florian_algo/advanced-rag-query-rewriting
4. **DEV.to** (2024). "Build an Advanced RAG App: Query Rewriting". https://dev.to/rogiia/build-an-advanced-rag-query-rewriting
5. **Coralogix** (2024). "Enhancing RAG Performance Using HyDE". https://coralogix.com/ai-blog/enhancing-rag-hyde

**Related Topics**:

- [5.4.1 Naive RAG](./5.4.1-naive-rag.md)
- [5.4.3 Agentic RAG](./5.4.3-agentic-rag.md)
- [5.3.4 Reranking](./5.3.4-reranking.md)

**Layer Index**: [Layer 5: RAG & Retrieval](../AI_KNOWLEDGE_BASE_TOC.md#layer-5-retrieval--rag)
