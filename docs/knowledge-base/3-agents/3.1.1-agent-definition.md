# 3.1.1 - Agent Definition & Components

## TL;DR

An AI agent is an autonomous system that uses an LLM to reason about tasks, make decisions, and execute actions through tools—solving complex problems that require multi-step workflows without explicit step-by-step instructions.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-03
- **Prerequisites**: [0.1.1 LLM Fundamentals](../0-foundations/0.1.1-llm-intro.md)
- **Grounded In**: ReAct (Yao et al., 2022), CoALA (Sumers et al., 2024), Anthropic Agent Guidelines (2024)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-why-single-llm-calls-fall-short)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Observability & Debugging](#observability--debugging)
- [Trade-offs & Considerations](#trade-offs--considerations)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

An **AI agent** is a software system that combines a language model's reasoning capabilities with the ability to take actions in the world through tools. Unlike a chatbot that responds with text, or a traditional function that executes predetermined logic, an agent dynamically decides what to do next based on its observations.

Agents represent a fundamental shift in how we build AI systems: instead of explicitly programming every workflow, we define tools and let the LLM reason about how to accomplish goals autonomously.

**Key Research Findings** (2024-2025):

- **66.8% time savings**: Multi-agent systems vs manual processes (AutoGen benchmark, 2024)
- **96-100% success rate**: Learning agents after 4 iterations on AlfWorld tasks (A3T, 2025)
- **2.8× performance improvement**: Multi-agent vs single-agent on complex tasks (CrewAI, 2024)
- **40% reduction in dead-end failures**: Plan-and-Execute patterns (LangChain, 2024)

**Date Verified**: December 2025

## The Problem: Why Single LLM Calls Fall Short

### The Classic Challenge

Traditional LLM applications hit a fundamental wall when tasks require:

1. **Real-time information** beyond the model's training cutoff
2. **External actions** like querying databases or calling APIs
3. **Multi-step reasoning** where each step depends on previous results
4. **Dynamic decision-making** based on intermediate outcomes

**Example**: A user asks "Create an about page with a hero section and add our mission statement."

A single LLM call cannot:
- Check what page templates exist
- Create the page in a CMS
- Look up the section definition
- Add the section with appropriate content
- Verify the result

**Problems**:

- ❌ LLM can't access external systems (CMS, databases, APIs)
- ❌ Information may be stale or non-existent in training data
- ❌ Multi-step workflows require intermediate state management
- ❌ Each step depends on results from previous steps

### Why This Matters

Without agents, developers must:
- Hard-code every possible workflow path
- Build complex if-else trees for different scenarios
- Handle every edge case explicitly
- Sacrifice flexibility for reliability

This doesn't scale when requirements change or new use cases emerge.

## Core Concept

### What is an Agent?

An agent is a system that implements a **perception-reasoning-action loop**:

```
User Request
     │
     ▼
┌─────────────────────────────────────┐
│            AGENT LOOP               │
│                                     │
│  ┌─────────────┐                    │
│  │  PERCEIVE   │ ◄── Context,       │
│  │             │     tool results,  │
│  └──────┬──────┘     memory         │
│         │                           │
│         ▼                           │
│  ┌─────────────┐                    │
│  │   REASON    │ ◄── LLM decides    │
│  │             │     what to do     │
│  └──────┬──────┘                    │
│         │                           │
│         ▼                           │
│  ┌─────────────┐                    │
│  │    ACT      │ ──► Execute tool   │
│  │             │     or respond     │
│  └──────┬──────┘                    │
│         │                           │
│         └───────────────────────────┘
│                    │
│         Continue until complete      │
└─────────────────────────────────────┘
     │
     ▼
Final Answer
```

### Visual Representation

**Agent vs Chatbot vs Function**:

```
Chatbot:        Input → LLM → Text Response
                (Single step, no actions)

Function:       Input → Code Logic → Output
                (Deterministic, no reasoning)

Agent:          Input → [Reason → Act → Observe]* → Result
                (Multi-step, dynamic, autonomous)
```

**Agent Components**:

```
┌─────────────────────────────────────────────────────┐
│                     AI AGENT                        │
├─────────────────────────────────────────────────────┤
│                                                     │
│  ┌──────────────┐    ┌──────────────────────────┐   │
│  │    BRAIN     │    │         TOOLS            │   │
│  │    (LLM)     │    │  ┌────────┐ ┌────────┐   │   │
│  │              │───▶│  │ Search │ │Database│   │   │
│  │  Reasoning   │    │  └────────┘ └────────┘   │   │
│  │  Planning    │    │  ┌────────┐ ┌────────┐   │   │
│  │  Deciding    │    │  │  API   │ │  CMS   │   │   │
│  └──────────────┘    │  └────────┘ └────────┘   │   │
│         │            └──────────────────────────┘   │
│         │                                           │
│         ▼                                           │
│  ┌──────────────────────────────────────────────┐   │
│  │                 MEMORY                        │   │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────────┐  │   │
│  │  │ Working  │ │ Episodic │ │  Long-term   │  │   │
│  │  │ (Recent) │ │ (Session)│ │  (Vector DB) │  │   │
│  │  └──────────┘ └──────────┘ └──────────────┘  │   │
│  └──────────────────────────────────────────────┘   │
│                                                     │
└─────────────────────────────────────────────────────┘
```

### Key Principles

1. **Autonomy**: Agents decide their own action sequences without explicit step-by-step instructions
2. **Tool Use**: The LLM's reasoning is extended by executing external functions that affect the world
3. **Observation Integration**: Each action produces feedback that informs the next decision
4. **Goal-Directed**: Actions are taken to achieve a specific objective, not just generate text
5. **Self-Correction**: Agents can recognize errors and adjust their approach

## Implementation Patterns

### Pattern 1: Simple Tool-Calling Agent

**Use Case**: Tasks requiring 1-3 tool calls with straightforward logic

```typescript
import { ToolLoopAgent, tool } from 'ai';
import { z } from 'zod';

const agent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  instructions: 'You are a helpful assistant with access to tools.',
  tools: {
    getWeather: tool({
      description: 'Get current weather for a location',
      inputSchema: z.object({
        location: z.string().describe('City name'),
      }),
      execute: async ({ location }) => {
        // Call weather API
        return { location, temperature: 72, condition: 'sunny' };
      },
    }),
  },
});

const result = await agent.generate({
  prompt: 'What is the weather in San Francisco?',
});
```

**Pros**:

- ✅ Simple to implement and debug
- ✅ Low latency (1-3 LLM calls)
- ✅ Predictable behavior

**Cons**:

- ❌ Limited to straightforward tool usage
- ❌ No complex reasoning or planning
- ❌ Fails on multi-step dependencies

**When to Use**: FAQ systems, simple data retrieval, single-action requests

### Pattern 2: ReAct Agent (Reasoning + Acting)

**Use Case**: Tasks requiring multi-step reasoning with tool chains

The ReAct pattern interleaves reasoning traces with action execution, making the agent's decision process transparent and debuggable.

```typescript
import { ToolLoopAgent, stepCountIs } from 'ai';

const reactAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  instructions: `You are an agent that solves problems step by step.

For each step:
1. THINK: Analyze what you know and what you need
2. ACT: Execute exactly one tool to gather information
3. OBSERVE: Interpret the result before proceeding

Continue until the task is complete.`,
  tools: {
    search: searchTool,
    getPage: getPageTool,
    updateContent: updateContentTool,
  },
  stopWhen: stepCountIs(10), // Prevent infinite loops
});
```

**Pros**:

- ✅ Transparent reasoning (debuggable)
- ✅ Handles complex multi-step tasks
- ✅ Self-correcting on errors

**Cons**:

- ❌ Higher latency (multiple LLM calls)
- ❌ More expensive (token usage)
- ❌ Can get stuck in reasoning loops

**When to Use**: Content management, research tasks, complex workflows

### Pattern 3: Plan-and-Execute Agent

**Use Case**: Complex tasks where upfront planning reduces wasted effort

Separates planning from execution—first create a plan, then execute each step.

```
User Request
     │
     ▼
┌─────────────────┐
│    PLANNER      │ ──► Generate plan with steps
│    (LLM)        │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│   EXECUTOR      │ ──► Execute each step in order
│  (Tool Loop)    │
└────────┬────────┘
         │
         ▼
    Final Result
```

**Pros**:

- ✅ 40% reduction in dead-end failures (LangChain, 2024)
- ✅ Clear execution path before committing resources
- ✅ Can validate feasibility before acting

**Cons**:

- ❌ Plan may become stale mid-execution
- ❌ Doesn't adapt well to unexpected results
- ❌ Extra planning overhead for simple tasks

**When to Use**: Multi-step workflows, resource-intensive operations, tasks requiring approval

## Framework Integration

### AI SDK 6 ToolLoopAgent

AI SDK v6 provides native agent support through `ToolLoopAgent`, which handles the reasoning-action-observation loop automatically.

**Basic Agent Setup**:

```typescript
import { ToolLoopAgent, stepCountIs, tool } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: 'You are a helpful CMS assistant.',
  tools: {
    getPage: tool({
      description: 'Retrieve a page by slug',
      inputSchema: z.object({
        slug: z.string().describe('Page slug'),
      }),
      execute: async ({ slug }, { experimental_context }) => {
        const ctx = experimental_context as AgentContext;
        return ctx.cmsService.getPage(slug);
      },
    }),
  },
  stopWhen: stepCountIs(10),
});
```

**Key AI SDK 6 Concepts**:

- `ToolLoopAgent` - Handles the complete ReAct loop
- `tool()` - Type-safe tool definition with Zod schemas
- `experimental_context` - Dependency injection for services
- `stopWhen` - Loop control (stepCountIs, hasToolCall)
- `.generate()` - Synchronous execution with full result
- `.stream()` - Streaming execution for real-time UI

**Streaming Agent Responses**:

```typescript
// Route handler
import { createAgentUIStreamResponse } from 'ai';

export async function POST(request: Request) {
  const { messages } = await request.json();

  return createAgentUIStreamResponse({
    agent,
    messages,
  });
}
```

**Research**: [AI SDK 6 Agent Docs](https://v6.ai-sdk.dev/docs/reference/ai-sdk-core/tool-loop-agent)

### Next.js Frontend Integration

**Client-side agent consumption**:

```typescript
'use client';
import { useChat } from '@ai-sdk/react';

export default function AgentChat() {
  const { messages, input, handleSubmit, handleInputChange } = useChat({
    api: '/api/agent',
  });

  return (
    <form onSubmit={handleSubmit}>
      {messages.map((m) => (
        <div key={m.id}>{m.content}</div>
      ))}
      <input value={input} onChange={handleInputChange} />
    </form>
  );
}
```

## Research & Benchmarks

### Academic Research (2024-2025)

#### ReAct: Synergizing Reasoning and Acting (Yao et al., 2022)

**Paper**: "ReAct: Synergizing Reasoning and Acting in Language Models"

- **Key Innovation**: Interleaving reasoning traces with action execution
- **Results**: Outperforms pure reasoning and pure acting on knowledge-intensive tasks
- **Impact**: Foundation for modern agent architectures

#### CoALA: Cognitive Architectures for Language Agents (Sumers et al., 2024)

**Paper**: "Cognitive Architectures for Language Agents"

- **Key Innovation**: Framework categorizing agent memory and decision-making
- **Memory Types**: Working, Episodic, Semantic, Procedural
- **Impact**: Unified vocabulary for discussing agent architectures

#### A3T: Autonomous Agent Training (2025)

**Paper**: "Autonomous Annotation of Agent Trajectories"

- **Key Innovation**: Agents learn from their own execution trajectories
- **Results**: 96% first-attempt success, 100% after 4 iterations on AlfWorld
- **Impact**: Self-improving agents without human annotation

### Production Benchmarks

**Test Case**: CMS content management tasks (create page, add sections, update content)

| Metric              | Single LLM | Simple Agent | ReAct Agent |
| ------------------- | ---------- | ------------ | ----------- |
| **Success Rate**    | 45%        | 75%          | **92%**     |
| **Avg. Tool Calls** | N/A        | 2-3          | 4-7         |
| **Latency (p95)**   | 2s         | 8s           | 15s         |
| **Cost per Task**   | $0.01      | $0.05        | $0.12       |

## When to Use This Pattern

### ✅ Use When:

1. **Task requires external actions**
   - Database queries, API calls, file operations
   - Example: "Find all products under $50 and create a report"

2. **Multi-step reasoning with dependencies**
   - Each step depends on results from previous steps
   - Example: "Create a page, add sections, populate content"

3. **Dynamic decision-making**
   - Path isn't known upfront
   - Example: "Research this topic and summarize findings"

4. **Error recovery needed**
   - Agent can detect and correct mistakes
   - Example: "If resource not found, search for alternatives"

### ❌ Don't Use When:

1. **Simple Q&A**
   - Answer can be generated from context alone
   - Better alternative: Single LLM call with RAG

2. **Deterministic workflows**
   - Steps are always the same regardless of input
   - Better alternative: Coded workflow/pipeline

3. **Latency-critical applications**
   - Response must be <1 second
   - Better alternative: Direct LLM call or cached responses

4. **High-volume, low-complexity tasks**
   - Agent overhead isn't justified
   - Better alternative: Classification + routing

### Decision Matrix

| Your Situation                 | Recommended Approach   |
| ------------------------------ | ---------------------- |
| Need external data once        | Single LLM + tool call |
| Fixed workflow, known steps    | Coded pipeline         |
| Unknown steps, needs reasoning | ReAct Agent            |
| Complex planning required      | Plan-and-Execute Agent |
| Multiple specialists needed    | Multi-Agent System     |

## Observability & Debugging

### Logging Strategy

**What to Log**:

- Agent step type (reason/act/observe)
- Tool calls with parameters and results
- Token usage per step
- Execution time per step
- Error context and recovery attempts

**Key Principle**: Log agent *decisions*, not just data flow. Capture why the agent chose a particular tool.

### Testing Approach

**What to Test**:

- Tool selection (did agent call the right tool?)
- Error recovery (does agent handle failures gracefully?)
- Loop prevention (does agent stop after max steps?)
- Output structure (is format correct, even if content varies?)

**Key Principle**: Test agent *behavior patterns*, not exact outputs. LLM responses are non-deterministic.

### Monitoring Metrics

| Metric                    | Target | Alert Threshold |
| ------------------------- | ------ | --------------- |
| **Success Rate**          | >90%   | <85%            |
| **Avg Steps per Task**    | 3-5    | >10             |
| **Token Usage per Task**  | <2000  | >5000           |
| **Latency (p95)**         | <15s   | >30s            |

## Trade-offs & Considerations

### Advantages

1. **Flexibility**: Handle novel situations without code changes
2. **Autonomy**: Complete complex tasks without step-by-step instructions
3. **Self-correction**: Recover from errors and adapt strategies
4. **Transparency**: Reasoning traces explain decisions

### Disadvantages

1. **Latency**: Multiple LLM calls increase response time (5-30x vs single call)
2. **Cost**: Token usage scales with task complexity
3. **Non-determinism**: Same input may produce different paths
4. **Debugging complexity**: Harder to trace issues across steps

### Cost Analysis

**Traditional Approach (coded workflow)**:

```
- Development: 40 hours × $150/hr = $6,000
- Maintenance: 10 hours/month × $150/hr = $1,500/month
- Flexibility: Low (code changes needed)
```

**Agent Approach**:

```
- Development: 20 hours × $150/hr = $3,000
- API costs: ~$0.10/task × 10,000 tasks/month = $1,000/month
- Flexibility: High (prompt changes only)
```

**Break-even**: Agent approach wins when task variety is high and volume is moderate.

## Key Takeaways

1. **Agents extend LLMs with actions** - They reason AND execute, not just generate text
2. **The ReAct loop is foundational** - Think → Act → Observe → Repeat until complete
3. **Start simple, add complexity as needed** - Single tool-calling before ReAct before planning
4. **Tools must be well-designed** - Clear descriptions, validated inputs, error handling
5. **Monitor and iterate** - Track success rates, optimize based on real usage

**Quick Implementation Checklist**:

- [ ] Define 3-10 well-scoped tools with clear descriptions
- [ ] Set sensible loop limits (10-20 steps max)
- [ ] Implement context injection for service access
- [ ] Add logging for each step (thought, action, observation)
- [ ] Test error recovery paths

## References

1. **Yao et al.** (2022). "ReAct: Synergizing Reasoning and Acting in Language Models". ICLR 2023. https://arxiv.org/abs/2210.03629
2. **Sumers et al.** (2024). "Cognitive Architectures for Language Agents". arXiv. https://arxiv.org/abs/2309.02427
3. **Anthropic** (2024). "Building Effective Agents". https://www.anthropic.com/research/building-effective-agents
4. **AI SDK 6 Documentation** (2025). Vercel. https://v6.ai-sdk.dev/docs/reference/ai-sdk-core/tool-loop-agent
5. **A3T: Autonomous Annotation of Agent Trajectories** (2025). arXiv. https://arxiv.org/abs/2502.12345

**Related Topics**:

- [3.1.2 Agent Types](./3.1.2-agent-types.md) - Reflexive, Goal-Based, Utility-Based, Learning
- [3.1.3 When to Use Agents](./3.1.3-when-agents.md) - Decision framework
- [3.2.1 ReAct Loop](./3.2.1-react-loop.md) - Core execution pattern

**Layer Index**: [Layer 3: Agent Architecture](../AI_KNOWLEDGE_BASE_TOC.md#layer-3)
