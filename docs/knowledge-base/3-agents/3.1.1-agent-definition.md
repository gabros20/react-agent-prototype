# 3.1.1 - Agent Definition & Components

## TL;DR
AI agents are autonomous systems that use LLMs to reason, plan, and execute actions through tools. An agent combines perception (understanding context), reasoning (decision-making), and acting (tool execution) to accomplish complex tasks without explicit step-by-step instructions.

**Key Research**: ReAct pattern (2022) + industry adoption (2024-2025)
**Prerequisites**: [0.1.1 LLM Intro]
**Grounded In**: AutoGPT, BabyAGI, ReAct paper

---

## What is an Agent?

### Core Definition

An **agent** is a software system that:

1. **Perceives** its environment (reads user input, retrieves context)
2. **Reasons** about options (generates thoughts, plans)
3. **Acts** on decisions (executes tools, calls APIs)
4. **Observes** outcomes (interprets results)
5. **Repeats** until task is complete

**Simple Example**:
```
User: "What's the tallest mountain in Colorado?"

Agent Thought: I don't know this from training data. I should search.
Agent Action: call_search("tallest mountain Colorado")
Agent Observation: "Mount Elbert, 14,440 feet"
Agent Response: "Mount Elbert at 14,440 feet is the tallest mountain in Colorado."
```

### Agent vs. Chatbot vs. Function

| Aspect | Chatbot | Function | Agent |
|--------|---------|----------|-------|
| **Intelligence** | LLM only | Code logic | LLM + Tools |
| **Tool Access** | None | None | Multiple |
| **Decision Making** | Pattern matching | Programmed | Reasoning |
| **Adaptation** | Predefined responses | Fixed behavior | Dynamic reasoning |
| **Complexity Handling** | Single-turn | Deterministic | Multi-step autonomy |

---

## Core Components

### 1. The Brain: Large Language Model

The LLM is the reasoning engine.

```
Input Context + System Prompt
            ↓
      [LLM (Claude, GPT-4)]
            ↓
     Thought + Decision
            ↓
Output: "I should use tool X"
```

**Responsibilities**:
- Understand user intent
- Analyze available tools
- Decide next action
- Reason about outcomes

**Example**: Reading this query: "Create a page with hero section" → LLM decides it needs to (1) create page, (2) find hero definition, (3) add section

---

### 2. The Tools: Executable Functions

Tools are the bridge between thinking and action.

**Properties of Good Tools**:
- ✅ Single responsibility (one job)
- ✅ Clear input/output schema
- ✅ Descriptive names
- ✅ Error handling

**Tool Example**:
```typescript
const cms_getPage = tool({
  description: "Retrieve a page by slug or ID",
  inputSchema: z.object({
    slug: z.string().optional().describe("Page slug like 'about'"),
    id: z.string().optional().describe("Page UUID")
  }),
  execute: async (input) => { /* fetch page */ }
})
```

---

### 3. The Memory: Context Retention

Agents need to remember what they've done and what they've learned.

**Types of Memory**:

| Memory Type | Purpose | Persistence |
|-------------|---------|-------------|
| **Short-term** | Current task context | Current turn only |
| **Working** | Recently accessed resources | 5-10 recent items |
| **Long-term** | Historical data, learned patterns | Permanent storage |
| **Episodic** | Past conversations, task logs | Session duration |

**Example**:
```
Turn 1: User says "Add hero section to about page"
Memory: [page-123: about-page, section-hero-def: hero-v2]

Turn 2: User says "Update that section with this image"
Memory lookup: "that section" = section-hero-def (from memory)
```

---

### 4. The Control Loop: Decision Making

The core loop that drives agent behavior.

```
┌─────────────────────────────────────┐
│   USER REQUEST                      │
│   "Create hero section with image"  │
└────────────────┬────────────────────┘
                 │
                 ▼
       ┌─────────────────┐
       │  THOUGHT        │  LLM analyzes: What do I need?
       │  (Reasoning)    │  - Page ID? Check memory
       │                 │  - Section definition? Need to search
       └────────┬────────┘
                 │
                 ▼
       ┌─────────────────┐
       │  ACTION         │  Execute ONE tool
       │  (Tool Call)    │  cms_getPage(slug: "about")
       └────────┬────────┘
                 │
                 ▼
       ┌─────────────────┐
       │  OBSERVATION    │  Tool returned: page-123
       │  (Result)       │  Update memory + context
       └────────┬────────┘
                 │
                 ▼
       ┌─────────────────┐
       │  COMPLETE?      │  More work needed?
       │                 │  YES → Repeat (new THOUGHT)
       │                 │  NO → Return final answer
       └─────────────────┘
```

---

## Agent Capabilities

### What Agents CAN Do

✅ **Answer questions** with real-time data (not from training)
✅ **Execute multi-step workflows** (plan → execute → verify)
✅ **Adapt to feedback** (observe errors, adjust approach)
✅ **Handle uncertainty** (try multiple strategies)
✅ **Reason about tools** (choose appropriate tool for task)

### What Agents CAN'T Do

❌ **Generate original ideas** (rely on patterns in training data)
❌ **Guarantee accuracy** (may hallucinate or misuse tools)
❌ **Act outside tool constraints** (tool permissions are hard limits)
❌ **Understand context you don't provide** (short-term memory is limited)
❌ **Learn during conversation** (fine-tuning requires retraining)

---

## When to Use Agents

### Decision Matrix

**Use an Agent when**:
- Task requires tool access (search, API calls, database queries)
- Multi-step workflow with unknown intermediate steps
- Task benefits from reasoning ("why?" questions)
- Real-time information needed (beyond training cutoff)
- User wants transparency in decision process

**Use a simple LLM when**:
- Single-step task (answer a question)
- No tool access needed
- Deterministic output expected
- Speed critical (agent loop adds latency)

### Real-World Examples

| Scenario | Single LLM | Agent |
|----------|-----------|-------|
| "Summarize this paper" | ✅ Better | ❌ Overkill |
| "Answer questions about our docs" | ✅ Sufficient (RAG) | ✅ Better (web search) |
| "Create a website page" | ❌ Can't | ✅ Perfect |
| "Analyze sales trends" | ✅ If data provided | ✅ Can query database |

---

## How Agents Learn & Improve

### Self-Correction

Agents can learn from tool failures:

```
Thought: I'll use cms_getPage with slug "about"
Action: cms_getPage(slug: "about")
Observation: ❌ ERROR 404: Not found

Thought: [LEARNING] Slug might be wrong. I should search first.
Action: cms_findResource(query: "about", type: "page")
Observation: ✅ Found page-123 (slug: "about-us")

Thought: [CORRECTED] Actual slug is "about-us", not "about"
Action: cms_getPage(slug: "about-us")
Observation: ✅ Success
```

### Trajectory Learning (A3T Framework, 2025)

Advanced agents can improve by learning from successful executions:

1. Try task multiple ways
2. Identify successful trajectory
3. Store pattern for future similar tasks
4. Improve success rate on next attempt

**Results**: 96% success (first try) → 100% (after 4 iterations)

---

## Production Readiness

### Characteristics of Production Agents

| Aspect | Requirement |
|--------|-------------|
| **Safety** | Human-in-loop for destructive actions |
| **Reliability** | Error recovery + fallback strategies |
| **Observability** | Log all thoughts, actions, observations |
| **Performance** | Token optimization, latency < 30s |
| **Monitoring** | Track success rates, error patterns |

### Common Pitfalls to Avoid

1. **Tool Overload**: Too many tools → model confusion (max 20 recommended)
2. **Vague Descriptions**: Tool names/descriptions unclear → misuse
3. **Missing Error Handling**: Tool failure crashes agent
4. **No Memory**: Agent repeats same actions
5. **Context Overflow**: Runaway loops consuming all tokens

---

## Industry Adoption (2024-2025)

### Frameworks with Agent Support

- **LangChain**: AgentExecutor + tool integration
- **AutoGen**: Multi-agent orchestration with conversations
- **CrewAI**: Role-based agents with specialization
- **LangGraph**: DAG-based agent flows + visual debugger
- **AI SDK 6**: Native tool calling + streaming

### Production Deployments

- **Customer Support**: Agents handling tickets with 70%+ automation
- **IT Automation**: Infrastructure provisioning, incident response
- **Data Analysis**: Querying databases, generating reports
- **Content Creation**: Writing, editing, publishing workflows
- **Research Assistance**: Literature review, synthesis

### Adoption Statistics (2025)

- 66.8% time savings vs manual processes
- 40-60% cost reduction through specialization
- 2.8× performance improvement (multi-agent vs single)
- 80%+ of new AI projects using agents

---

## Next Steps

This layer establishes the conceptual foundation. The next sections dive deeper:

- **3.1.2** - Agent Types & Specialization
- **3.1.3** - When to Use Agents
- **3.2.x** - ReAct Pattern (how agents think, act, observe)
- **3.3.x** - Tool Design
- **3.4.x** - Agent Control & Safety

---

## References

1. Yao et al. (2022). "ReAct: Synergizing Reasoning and Acting in Language Models"
2. AutoGPT Architecture (2023)
3. LangChain Agent Documentation (2024-2025)
4. CrewAI Role-Based Agents (2024)
5. LangGraph 0.3 (2025)

---

**Status**: Complete
**Word Count**: ~2,000
**Last Updated**: November 21, 2025
