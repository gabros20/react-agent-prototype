# 3.4.1 - Max Steps Limits

> **Layer**: Agent Architecture | **Topic**: Loop Control
> **Version**: 2.0 | **Date Verified**: December 2025

---

## TL;DR

**Max steps limits prevent runaway agents from consuming excessive API costs while stuck in unproductive loops.** AI SDK v6 uses `stopWhen: stepCountIs(N)` to set hard upper bounds on agent iterations, forcing termination when limits are reached.

### Key Takeaways

- **85% of agent failures** are due to unclear goals and ambiguous stopping conditions
- **Default limits**: 5-10 for simple tasks, 15-30 for complex, 50+ for research
- **AI SDK v6** uses `stopWhen: stepCountIs(N)` instead of deprecated `maxSteps`
- **Progressive limits** (soft + hard) provide graceful degradation
- **Checkpointing** saves partial results when limits are hit

---

## Why It Matters

### The Problem

Without step limits, agents can run indefinitely:

```typescript
// ❌ WITHOUT LIMITS
// User request: "Find the population of Tokyo"

// Agent execution:
// Step 1: web_search("Tokyo population")
// Step 2: open_page("https://en.wikipedia.org/wiki/Tokyo")
// Step 3: scroll_down() → No population found yet
// Step 4: scroll_down() → Still looking...
// Step 5: scroll_down() → Keep scrolling...
// ... (continues indefinitely until manual cancellation)

// Cost: $0.05 per step × 100+ steps = $5+ wasted
// Time: 300 seconds (5 minutes) of stuck behavior
```

**Root causes:**
1. **Unclear success criteria** - Agent doesn't know what "done" looks like
2. **Missing validation** - No checks if action achieved its goal
3. **Tool confusion** - Agent doesn't understand tool's actual effect
4. **Reasoning loops** - Agent repeats same thought pattern

### Research Evidence

| Finding | Source | Year |
|---------|--------|------|
| **85%** of agent failures due to unclear stopping conditions | Doinamerica | Sep 2025 |
| **REFRAIN** reduces tokens by 20-55% through dynamic stopping | arXiv | Oct 2025 |
| Default limits: 10-25 steps across major frameworks | Industry survey | 2025 |
| Without limits, stuck agents can consume $10-100+ per loop | Production metrics | 2025 |

---

## Core Concepts

### Limit Types

```
┌─────────────────────────────────────────────────────────────┐
│                    STEP LIMIT TYPES                          │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. HARD LIMIT                                              │
│     └─ Absolute cap, forces immediate termination           │
│                                                              │
│  2. SOFT LIMIT                                              │
│     └─ Warning threshold, allows continuation               │
│                                                              │
│  3. ADAPTIVE LIMIT                                          │
│     └─ Dynamic based on task complexity                     │
│                                                              │
│  4. PROGRESSIVE LIMIT                                       │
│     └─ Soft + hard with checkpointing                       │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Limit Selection Guide

```
Task Type                    Recommended Steps
─────────────────────────────────────────────
Simple Q&A                   3-5 steps
Data retrieval               5-10 steps
CMS operations               8-15 steps
Debugging                    15-25 steps
Research                     25-50 steps
Code generation              30-60 steps
```

---

## Implementation Guide

### Step-by-Step

#### 1. Hard Limit (AI SDK v6)

```typescript
// server/agent/orchestrator.ts
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

export async function runAgentWithLimit(
  prompt: string,
  context: AgentContext,
  maxSteps: number = 15
): Promise<AgentResult> {
  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),

    // v6: Use stopWhen instead of maxSteps
    stopWhen: stepCountIs(maxSteps),

    experimental_context: context,
  });

  // Log completion stats
  console.log(`Completed in ${result.steps.length}/${maxSteps} steps`);

  // Warn if approaching limit
  if (result.steps.length >= maxSteps * 0.8) {
    console.warn(`Agent used ${result.steps.length} steps, close to limit`);
  }

  return {
    text: result.text,
    steps: result.steps.length,
    hitLimit: result.steps.length >= maxSteps,
  };
}
```

**Characteristics:**
- ✅ Simple to implement (one parameter)
- ✅ Guaranteed termination
- ✅ Cost protection
- ❌ Fixed limit may not fit all tasks
- ❌ Abrupt failure with no partial results

#### 2. Task-Based Adaptive Limits

```typescript
// server/agent/adaptive-limits.ts
import { generateObject, generateText, stepCountIs } from 'ai';
import { z } from 'zod';

interface TaskConfig {
  maxSteps: number;
  taskType: 'simple' | 'medium' | 'complex' | 'research';
  description: string;
}

const TASK_CONFIGS: Record<string, TaskConfig> = {
  simple: {
    maxSteps: 5,
    taskType: 'simple',
    description: 'Single API call or database query',
  },
  medium: {
    maxSteps: 15,
    taskType: 'medium',
    description: 'Multi-step operations with 2-5 tools',
  },
  complex: {
    maxSteps: 30,
    taskType: 'complex',
    description: 'Complex workflows with branching logic',
  },
  research: {
    maxSteps: 50,
    taskType: 'research',
    description: 'Open-ended research with exploration',
  },
};

async function classifyTask(prompt: string): Promise<TaskConfig> {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: z.object({
      taskType: z.enum(['simple', 'medium', 'complex', 'research']),
      reasoning: z.string(),
    }),
    prompt: `Classify the complexity of this task: "${prompt}"

             Simple: Single lookup or query
             Medium: 2-5 steps with clear path
             Complex: Multi-step with branching
             Research: Open-ended exploration`,
  });

  return TASK_CONFIGS[object.taskType];
}

export async function runAdaptiveAgent(
  prompt: string,
  context: AgentContext
): Promise<AgentResult> {
  // Classify task to determine appropriate limit
  const config = await classifyTask(prompt);

  console.log(`Task classified as ${config.taskType}, using ${config.maxSteps} max steps`);

  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),
    stopWhen: stepCountIs(config.maxSteps),
    experimental_context: context,
  });

  return {
    text: result.text,
    steps: result.steps.length,
    taskType: config.taskType,
    hitLimit: result.steps.length >= config.maxSteps,
  };
}
```

#### 3. Progressive Limits with Checkpoints

```typescript
// server/agent/progressive-agent.ts
interface ProgressiveConfig {
  softLimit: number;   // Warn user, allow continuation
  hardLimit: number;   // Force stop
  checkpointEvery: number;
}

export async function runProgressiveAgent(
  prompt: string,
  context: AgentContext,
  config: ProgressiveConfig = {
    softLimit: 10,
    hardLimit: 20,
    checkpointEvery: 5,
  }
): Promise<ProgressiveResult> {
  const checkpoints: string[] = [];
  let currentStep = 0;
  let softLimitReached = false;

  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),
    stopWhen: stepCountIs(config.hardLimit),
    experimental_context: context,

    // Track progress with step callbacks
    experimental_onStepFinish: async (step) => {
      currentStep++;

      // Save checkpoint
      if (currentStep % config.checkpointEvery === 0) {
        checkpoints.push(summarizeStep(step));
        context.logger?.info(`Checkpoint ${currentStep}: Saved progress`);
      }

      // Soft limit warning
      if (currentStep === config.softLimit && !softLimitReached) {
        softLimitReached = true;
        context.logger?.warn(`Soft limit reached (${config.softLimit} steps)`);
        // In production: could notify user here
      }
    },
  });

  return {
    success: true,
    text: result.text,
    steps: currentStep,
    checkpoints,
    hitSoftLimit: softLimitReached,
    hitHardLimit: currentStep >= config.hardLimit,
  };
}

function summarizeStep(step: any): string {
  const toolCalls = step.toolCalls?.map((tc: any) => tc.toolName).join(', ') || 'none';
  return `Step ${step.stepNumber}: ${toolCalls}`;
}
```

---

## Framework Integration

### AI SDK v6 Pattern

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';

// Production agent configuration
export const AGENT_CONFIG = {
  defaultSteps: 15,        // Production default
  model: 'gpt-4o',
  temperature: 0.2,        // Lower for consistent reasoning
};

const result = await generateText({
  model: openai(AGENT_CONFIG.model),
  temperature: AGENT_CONFIG.temperature,
  prompt: userMessage,
  tools: {
    cms_getPage,
    cms_updatePage,
    cms_createPage,
  },

  // v6: stopWhen replaces maxSteps
  stopWhen: stepCountIs(AGENT_CONFIG.defaultSteps),

  experimental_context: context,
});

// Check if limit was hit
if (result.steps.length >= AGENT_CONFIG.defaultSteps) {
  console.warn('Agent reached step limit - task may be incomplete');
}
```

### Custom Stop Conditions (v6)

```typescript
import { generateText, stepCountIs, hasToolCall, textContains } from 'ai';

// Combine multiple stop conditions
const result = await generateText({
  model: openai('gpt-4o'),
  prompt,
  tools,

  // Stop when any condition is met
  stopWhen: stepCountIs(20)
    .or(hasToolCall('task_complete'))
    .or(textContains('[DONE]')),

  experimental_context: context,
});
```

### Framework Comparison

| Framework | Default Steps | v6 Pattern |
|-----------|---------------|------------|
| **AI SDK v6** | 10 | `stopWhen: stepCountIs(N)` |
| **LangChain** | 15 | `max_iterations` |
| **AutoGen** | 25 | `max_consecutive_auto_reply` |
| **CrewAI** | 20 | `max_iter` |

---

## Testing Strategy

### Unit Testing Step Limits

```typescript
// server/agent/__tests__/step-limits.test.ts
import { describe, it, expect, vi } from 'vitest';
import { runAgentWithLimit } from '../orchestrator';

describe('Step Limits', () => {
  const createMockContext = () => ({
    cmsService: {
      getPage: vi.fn().mockResolvedValue({ id: 'page-1' }),
    },
    logger: { info: vi.fn(), warn: vi.fn() },
  });

  it('respects hard step limit', async () => {
    const ctx = createMockContext();

    // Mock a task that would naturally take many steps
    const result = await runAgentWithLimit(
      'Do an infinitely complex task',
      ctx as any,
      5 // Low limit
    );

    expect(result.steps).toBeLessThanOrEqual(5);
    expect(result.hitLimit).toBe(true);
  });

  it('completes simple tasks within limit', async () => {
    const ctx = createMockContext();

    const result = await runAgentWithLimit(
      'Get page with ID page-1',
      ctx as any,
      10
    );

    expect(result.steps).toBeLessThan(10);
    expect(result.hitLimit).toBe(false);
  });

  it('logs warning when approaching limit', async () => {
    const ctx = createMockContext();

    await runAgentWithLimit('Medium complexity task', ctx as any, 10);

    // Check if warning was logged when > 80% of limit used
    const warnCalls = ctx.logger.warn.mock.calls;
    const approachingLimitWarning = warnCalls.some(
      (call: any[]) => call[0].includes('close to limit')
    );

    // This depends on actual task behavior
    // expect(approachingLimitWarning).toBe(true);
  });
});
```

### Testing Adaptive Limits

```typescript
describe('Adaptive Limits', () => {
  it('classifies simple tasks correctly', async () => {
    const config = await classifyTask('What is 2+2?');
    expect(config.taskType).toBe('simple');
    expect(config.maxSteps).toBe(5);
  });

  it('classifies research tasks correctly', async () => {
    const config = await classifyTask(
      'Research and compare the top 5 AI frameworks, including pros/cons and use cases'
    );
    expect(config.taskType).toBe('research');
    expect(config.maxSteps).toBe(50);
  });
});
```

---

## Common Pitfalls

### ❌ Avoid

| Pitfall | Problem | Solution |
|---------|---------|----------|
| Arbitrarily high limits | "1000 steps just to be safe" = $50+ costs | Start with 15, increase based on data |
| Ignoring limit hits | Masks deeper problems | Investigate why agent needed so many steps |
| One-size-fits-all | Simple tasks waste budget | Use adaptive limits by task type |
| No checkpointing | Hitting limit = total loss | Save progress every N steps |
| Hiding limit errors | User doesn't know task incomplete | Always report partial results |
| Disabling in production | "Trusted" users still cause runaway | Keep limits on for everyone |

### ✅ Best Practices

1. **Set conservative defaults** - Start with 10-15 steps, increase based on telemetry
2. **Monitor utilization** - Track how often limits are hit (target: <5%)
3. **Provide partial results** - Return checkpoint data even if limit is hit
4. **Task-specific limits** - Different limits for different task types
5. **Two-tier limits** - Soft warning + hard stop
6. **User feedback** - Tell users when their task exceeded limits

---

## Summary

### Quick Reference

```typescript
// AI SDK v6 Step Limits
import { generateText, stepCountIs } from 'ai';

// Simple hard limit
const result = await generateText({
  model: openai('gpt-4o'),
  prompt,
  tools,
  stopWhen: stepCountIs(15),  // v6 pattern
});

// Limit guidelines
const STEP_LIMITS = {
  simple: 5,        // Single action
  standard: 10,     // Default for most tasks
  medium: 15,       // Multi-step with some branching
  complex: 25,      // Workflows with many steps
  research: 40,     // Open-ended exploration
  maximum: 60,      // Absolute cap
};
```

### Monitoring Checklist

| Metric | Target | Action if Exceeded |
|--------|--------|-------------------|
| Limit Hit Rate | <5% | Increase limits or improve task clarity |
| Avg Utilization | 40-70% | If <30% limits too high, >80% too tight |
| Cost per Task | Budget-dependent | Review high-cost task types |

---

## Related Topics

- [3.4.2 - Convergence Detection](./3.4.2-convergence.md) - Identifying task completion
- [3.4.3 - Stuck Detection](./3.4.3-stuck-detection.md) - Preventing infinite loops
- [3.4.5 - Early Exit Strategies](./3.4.5-early-exit.md) - Optimizing step usage

---

## Research Citations

1. **Doinamerica** - "Agent stopped due to max iterations: fixes that work" (Sep 2025)
   https://doinamerica.com/fr/agent-stopped-max-iterations-fix/

2. **REFRAIN Paper** - "Stop When Enough: Adaptive Early-Stopping for Chain-of-Thought" (Oct 2025)
   https://arxiv.org/html/2510.10103v1

3. **AI SDK v6** - "Multi-Step Calls and Stop Conditions" (2025)
   https://v6.ai-sdk.dev/docs/ai-sdk-core/generating-text#multi-step-calls

4. **LangChain** - "Max Iterations Documentation" (2025)
   https://js.langchain.com/v0.1/docs/modules/agents/how_to/max_iterations/

5. **MetricCoders** - "Defining Stopping Criteria in Large Language Models" (Mar 2025)
   https://www.metriccoders.com/post/defining-stopping-criteria-in-large-language-models
