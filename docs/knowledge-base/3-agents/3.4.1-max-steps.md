# 3.4.1 - Max Steps Limits

> **Layer**: Agent Architecture | **Topic**: Loop Control
> **Status**: Verified | **Last Updated**: December 2025
> **Prerequisites**: [3.1 Agent Patterns Overview](./3.1-agent-patterns.md)
> **Grounded In**: AI SDK v6 `stopWhen`, REFRAIN, production cost analysis

## TL;DR

**Max steps limits prevent runaway agents from consuming excessive API costs while stuck in unproductive loops.** AI SDK v6 uses `stopWhen: stepCountIs(N)` to set hard upper bounds on agent iterations, forcing termination when limits are reached.

**Key Takeaways**
- **85% of agent failures** are due to unclear goals and ambiguous stopping conditions
- **Default limits**: 5-10 for simple tasks, 15-30 for complex, 50+ for research
- **AI SDK v6** uses `stopWhen: stepCountIs(N)` instead of deprecated `maxSteps`
- **Progressive limits** (soft + hard) provide graceful degradation
- **Checkpointing** saves partial results when limits are hit

## Why It Matters

**The Problem**

Without step limits, agents can run indefinitely:

```typescript
// ❌ WITHOUT LIMITS
// User request: "Find the population of Tokyo"

// Agent execution:
// Step 1: web_search("Tokyo population")
// Step 2: open_page("https://en.wikipedia.org/wiki/Tokyo")
// Step 3: scroll_down() → No population found yet
// Step 4: scroll_down() → Still looking...
// Step 5: scroll_down() → Keep scrolling...
// ... (continues indefinitely until manual cancellation)

// Cost: $0.05 per step × 100+ steps = $5+ wasted
// Time: 300 seconds (5 minutes) of stuck behavior
```

**Root causes:**
1. **Unclear success criteria** - Agent doesn't know what "done" looks like
2. **Missing validation** - No checks if action achieved its goal
3. **Tool confusion** - Agent doesn't understand tool's actual effect
4. **Reasoning loops** - Agent repeats same thought pattern

**Research Evidence**

| Finding | Source | Year |
|---------|--------|------|
| **85%** of agent failures due to unclear stopping conditions | Doinamerica | Sep 2025 |
| **REFRAIN** reduces tokens by 20-55% through dynamic stopping | arXiv | Oct 2025 |
| Default limits: 10-25 steps across major frameworks | Industry survey | 2025 |
| Without limits, stuck agents can consume $10-100+ per loop | Production metrics | 2025 |

## Core Concepts

### Limit Types

```
┌─────────────────────────────────────────────────────────────┐
│                    STEP LIMIT TYPES                          │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. HARD LIMIT                                              │
│     └─ Absolute cap, forces immediate termination           │
│                                                              │
│  2. SOFT LIMIT                                              │
│     └─ Warning threshold, allows continuation               │
│                                                              │
│  3. ADAPTIVE LIMIT                                          │
│     └─ Dynamic based on task complexity                     │
│                                                              │
│  4. PROGRESSIVE LIMIT                                       │
│     └─ Soft + hard with checkpointing                       │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Limit Selection Guide

```
Task Type                    Recommended Steps
─────────────────────────────────────────────
Simple Q&A                   3-5 steps
Data retrieval               5-10 steps
CMS operations               8-15 steps
Debugging                    15-25 steps
Research                     25-50 steps
Code generation              30-60 steps
```

## Implementation Patterns

### Hard Limit (AI SDK v6)

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';

export async function runAgentWithLimit(
  prompt: string,
  context: AgentContext,
  maxSteps: number = 15
): Promise<AgentResult> {
  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),

    // v6: Use stopWhen instead of maxSteps
    stopWhen: stepCountIs(maxSteps),

    experimental_context: context,
  });

  // Log completion stats
  console.log(`Completed in ${result.steps.length}/${maxSteps} steps`);

  // Warn if approaching limit
  if (result.steps.length >= maxSteps * 0.8) {
    console.warn(`Agent used ${result.steps.length} steps, close to limit`);
  }

  return {
    text: result.text,
    steps: result.steps.length,
    hitLimit: result.steps.length >= maxSteps,
  };
}
```

**Characteristics:**
- ✅ Simple to implement (one parameter)
- ✅ Guaranteed termination
- ✅ Cost protection
- ❌ Fixed limit may not fit all tasks
- ❌ Abrupt failure with no partial results

### Task-Based Adaptive Limits

```typescript
import { generateObject, generateText, stepCountIs } from 'ai';
import { z } from 'zod';

const TASK_CONFIGS = {
  simple: { maxSteps: 5, description: 'Single API call or database query' },
  medium: { maxSteps: 15, description: 'Multi-step operations with 2-5 tools' },
  complex: { maxSteps: 30, description: 'Complex workflows with branching' },
  research: { maxSteps: 50, description: 'Open-ended exploration' },
};

async function classifyTask(prompt: string) {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: z.object({
      taskType: z.enum(['simple', 'medium', 'complex', 'research']),
      reasoning: z.string(),
    }),
    prompt: `Classify the complexity of this task: "${prompt}"`,
  });

  return TASK_CONFIGS[object.taskType];
}

export async function runAdaptiveAgent(prompt: string, context: AgentContext) {
  const config = await classifyTask(prompt);

  console.log(`Task classified, using ${config.maxSteps} max steps`);

  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),
    stopWhen: stepCountIs(config.maxSteps),
    experimental_context: context,
  });

  return {
    text: result.text,
    steps: result.steps.length,
    hitLimit: result.steps.length >= config.maxSteps,
  };
}
```

### Progressive Limits with Checkpoints

```typescript
interface ProgressiveConfig {
  softLimit: number;
  hardLimit: number;
  checkpointEvery: number;
}

export async function runProgressiveAgent(
  prompt: string,
  context: AgentContext,
  config: ProgressiveConfig = { softLimit: 10, hardLimit: 20, checkpointEvery: 5 }
): Promise<ProgressiveResult> {
  const checkpoints: string[] = [];
  let currentStep = 0;
  let softLimitReached = false;

  const result = await generateText({
    model: openai('gpt-4o'),
    prompt,
    tools: getAllTools(),
    stopWhen: stepCountIs(config.hardLimit),
    experimental_context: context,

    experimental_onStepFinish: async (step) => {
      currentStep++;

      // Save checkpoint
      if (currentStep % config.checkpointEvery === 0) {
        checkpoints.push(summarizeStep(step));
        context.logger?.info(`Checkpoint ${currentStep}: Saved progress`);
      }

      // Soft limit warning
      if (currentStep === config.softLimit && !softLimitReached) {
        softLimitReached = true;
        context.logger?.warn(`Soft limit reached (${config.softLimit} steps)`);
      }
    },
  });

  return {
    success: true,
    text: result.text,
    steps: currentStep,
    checkpoints,
    hitSoftLimit: softLimitReached,
    hitHardLimit: currentStep >= config.hardLimit,
  };
}
```

## Framework Integration

### AI SDK v6 Pattern

```typescript
import { generateText, tool, stepCountIs, hasToolCall } from 'ai';
import { openai } from '@ai-sdk/openai';

// Production agent configuration
export const AGENT_CONFIG = {
  defaultSteps: 15,
  model: 'gpt-4o',
  temperature: 0.2,
};

const result = await generateText({
  model: openai(AGENT_CONFIG.model),
  temperature: AGENT_CONFIG.temperature,
  prompt: userMessage,
  tools: { getPage, updatePage, createPage },

  // v6: stopWhen replaces maxSteps
  stopWhen: stepCountIs(AGENT_CONFIG.defaultSteps),

  experimental_context: context,
});

// Check if limit was hit
if (result.steps.length >= AGENT_CONFIG.defaultSteps) {
  console.warn('Agent reached step limit - task may be incomplete');
}
```

### Custom Stop Conditions (v6)

```typescript
import { generateText, stepCountIs, hasToolCall } from 'ai';

// Combine multiple stop conditions
const result = await generateText({
  model: openai('gpt-4o'),
  prompt,
  tools,

  // Stop when any condition is met
  stopWhen: [
    stepCountIs(20),
    hasToolCall('task_finish'),
  ],

  experimental_context: context,
});
```

### Framework Comparison

| Framework | Default Steps | v6 Pattern |
|-----------|---------------|------------|
| **AI SDK v6** | 10 | `stopWhen: stepCountIs(N)` |
| **LangChain** | 15 | `max_iterations` |
| **AutoGen** | 25 | `max_consecutive_auto_reply` |
| **CrewAI** | 20 | `max_iter` |

## Testing Strategy

### Unit Testing Step Limits

```typescript
import { describe, it, expect, vi } from 'vitest';
import { runAgentWithLimit } from '../orchestrator';

describe('Step Limits', () => {
  const createMockContext = () => ({
    cmsService: { getPage: vi.fn().mockResolvedValue({ id: 'page-1' }) },
    logger: { info: vi.fn(), warn: vi.fn() },
  });

  it('respects hard step limit', async () => {
    const ctx = createMockContext();

    const result = await runAgentWithLimit('Complex task', ctx as any, 5);

    expect(result.steps).toBeLessThanOrEqual(5);
    expect(result.hitLimit).toBe(true);
  });

  it('completes simple tasks within limit', async () => {
    const ctx = createMockContext();

    const result = await runAgentWithLimit('Get page page-1', ctx as any, 10);

    expect(result.steps).toBeLessThan(10);
    expect(result.hitLimit).toBe(false);
  });
});
```

## Common Pitfalls

### ❌ Avoid

| Pitfall | Problem | Solution |
|---------|---------|----------|
| Arbitrarily high limits | "1000 steps just to be safe" = $50+ costs | Start with 15, increase based on data |
| Ignoring limit hits | Masks deeper problems | Investigate why agent needed so many steps |
| One-size-fits-all | Simple tasks waste budget | Use adaptive limits by task type |
| No checkpointing | Hitting limit = total loss | Save progress every N steps |
| Hiding limit errors | User doesn't know task incomplete | Always report partial results |
| Disabling in production | "Trusted" users still cause runaway | Keep limits on for everyone |

### ✅ Best Practices

1. **Set conservative defaults** - Start with 10-15 steps, increase based on telemetry
2. **Monitor utilization** - Track how often limits are hit (target: <5%)
3. **Provide partial results** - Return checkpoint data even if limit is hit
4. **Task-specific limits** - Different limits for different task types
5. **Two-tier limits** - Soft warning + hard stop
6. **User feedback** - Tell users when their task exceeded limits

## Quick Reference

### Step Limit Configuration

```typescript
// AI SDK v6 Step Limits
import { generateText, stepCountIs } from 'ai';

// Simple hard limit
const result = await generateText({
  model: openai('gpt-4o'),
  prompt,
  tools,
  stopWhen: stepCountIs(15),  // v6 pattern
});

// Limit guidelines
const STEP_LIMITS = {
  simple: 5,        // Single action
  standard: 10,     // Default for most tasks
  medium: 15,       // Multi-step with some branching
  complex: 25,      // Workflows with many steps
  research: 40,     // Open-ended exploration
  maximum: 60,      // Absolute cap
};
```

### Monitoring Checklist

| Metric | Target | Action if Exceeded |
|--------|--------|-------------------|
| Limit Hit Rate | <5% | Increase limits or improve task clarity |
| Avg Utilization | 40-70% | If <30% limits too high, >80% too tight |
| Cost per Task | Budget-dependent | Review high-cost task types |

## Related Topics

- [3.4.2 - Convergence Detection](./3.4.2-convergence.md) - Identifying task completion
- [3.4.3 - Stuck Detection](./3.4.3-stuck-detection.md) - Preventing infinite loops
- [3.4.5 - Early Exit Strategies](./3.4.5-early-exit.md) - Optimizing step usage

## Research & Resources

**Academic Papers**
- REFRAIN - "Stop When Enough: Adaptive Early-Stopping for Chain-of-Thought" (Oct 2025) - [arxiv.org](https://arxiv.org/html/2510.10103v1)
- MetricCoders - "Defining Stopping Criteria in Large Language Models" (Mar 2025) - [metriccoders.com](https://www.metriccoders.com/post/defining-stopping-criteria-in-large-language-models)

**Framework Documentation**
- AI SDK v6 - "Multi-Step Calls and Stop Conditions" (2025) - [v6.ai-sdk.dev](https://v6.ai-sdk.dev/docs/ai-sdk-core/generating-text#multi-step-calls)
- LangChain - "Max Iterations Documentation" (2025) - [js.langchain.com](https://js.langchain.com/v0.1/docs/modules/agents/how_to/max_iterations/)

**Industry Resources**
- Doinamerica - "Agent stopped due to max iterations: fixes" (Sep 2025) - [doinamerica.com](https://doinamerica.com/fr/agent-stopped-max-iterations-fix/)
