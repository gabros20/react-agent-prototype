# 3.2.1 - The ReAct Loop: Think → Act → Observe

## TL;DR

The ReAct (Reasoning + Acting) pattern interleaves LLM reasoning with tool execution in a loop: Think about what to do, Act by calling a tool, Observe the result, and Repeat until the task is complete. This transparency makes agents debuggable and self-correcting.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-03
- **Prerequisites**: [3.1.1 Agent Definition](./3.1.1-agent-definition.md)
- **Grounded In**: ReAct (Yao et al., 2022), AI SDK 6 ToolLoopAgent (2025)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-black-box-agents)
- [Core Concept](#core-concept)
- [The Three Phases](#the-three-phases)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Loop Control](#loop-control)
- [Observability & Debugging](#observability--debugging)
- [Trade-offs & Considerations](#trade-offs--considerations)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

The ReAct pattern is the dominant approach for building AI agents that reason about tasks and execute actions. Unlike pure chain-of-thought (reasoning only) or pure tool-calling (acting only), ReAct combines both—producing reasoning traces that explain each action and observations that feed into subsequent reasoning.

**Key Research Findings** (2022-2025):

- **Outperforms pure approaches**: ReAct beats chain-of-thought AND pure acting on knowledge-intensive tasks (Yao et al., 2022)
- **Interpretable execution**: Reasoning traces explain agent decisions
- **Self-correction**: Agents can recognize errors and change strategy
- **Foundation for modern agents**: AI SDK 6, LangChain, AutoGPT all implement variants

**Date Verified**: December 2025

## The Problem: Black-Box Agents

### The Opacity Challenge

Traditional tool-calling agents make decisions invisibly:

```
User: "Create an about page with hero section"
Agent: [calls createPage]
Agent: [calls addSection]
Agent: "Done!"

# What happened?
# Why did it choose those tools?
# What if it made a wrong decision?
```

This leads to:

- **Undebuggable failures**: Can't understand why agent went wrong
- **Unverifiable success**: Can't confirm agent's approach was correct
- **No self-correction**: Agent can't recognize and fix its own mistakes
- **User distrust**: Opaque systems feel unreliable

### The Research Solution

Yao et al. (2022) proposed ReAct: make the agent's reasoning explicit by interleaving thought traces with actions.

**Before (Pure Acting)**:

```
Agent: call(createPage)
Agent: call(addSection)
```

**After (ReAct)**:

```
Thought: User wants an about page with hero. First I need to create the page.
Action: createPage(slug: "about", name: "About Us")
Observation: Page created with ID page-123

Thought: Page created. Now I need to add the hero section.
Action: addSection(pageId: "page-123", type: "hero")
Observation: Section added with ID section-456

Thought: Task complete. About page now has hero section.
Final Answer: Created about page with hero section.
```

## Core Concept

### Visual Representation

```
┌─────────────────────────────────────────────────────────────┐
│                    THE REACT LOOP                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   User Request                                              │
│        │                                                    │
│        ▼                                                    │
│   ┌──────────────────────────────────────────────────────┐  │
│   │                                                      │  │
│   │   ┌─────────┐                                        │  │
│   │   │  THINK  │  "What do I know? What do I need?"     │  │
│   │   │         │  "Which tool should I use?"            │  │
│   │   └────┬────┘                                        │  │
│   │        │                                             │  │
│   │        ▼                                             │  │
│   │   ┌─────────┐                                        │  │
│   │   │   ACT   │  Execute tool with parameters          │  │
│   │   │         │  e.g., createPage(slug: "about")       │  │
│   │   └────┬────┘                                        │  │
│   │        │                                             │  │
│   │        ▼                                             │  │
│   │   ┌─────────┐                                        │  │
│   │   │ OBSERVE │  Receive and interpret result          │  │
│   │   │         │  e.g., {id: "page-123", success: true} │  │
│   │   └────┬────┘                                        │  │
│   │        │                                             │  │
│   │        ▼                                             │  │
│   │   ┌─────────────────────────────────────────────┐    │  │
│   │   │  Task Complete?                             │    │  │
│   │   │  ├─ NO → Loop back to THINK                 │    │  │
│   │   │  └─ YES → Return Final Answer               │    │  │
│   │   └─────────────────────────────────────────────┘    │  │
│   │                                                      │  │
│   └──────────────────────────────────────────────────────┘  │
│        │                                                    │
│        ▼                                                    │
│   Final Answer                                              │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Key Principles

1. **Explicit Reasoning**: Every action is preceded by a thought explaining why
2. **Single Action per Step**: Execute one tool at a time for clear attribution
3. **Observation Integration**: Results feed into the next thinking phase
4. **Termination Detection**: Agent determines when task is complete
5. **Error Visibility**: Failures are observed and can trigger recovery

## The Three Phases

### Phase 1: THINK (Reasoning)

The LLM analyzes the current state and decides what to do.

**What happens**:

- Assess current context (user request, previous observations)
- Identify gaps in knowledge or incomplete actions
- Decide whether to use a tool or provide final answer
- If using tool, select which one and why

**Example**:

```
Thought: User asked to add hero section to about page.
Current state: I don't know if about page exists.
Gap: Need to find/verify the about page first.
Plan: Search for "about" page to get its ID.
Decision: Use findResource tool with query "about".
```

**See**: [3.2.2 Reasoning Phase](./3.2.2-reasoning-phase.md) for detailed patterns

### Phase 2: ACT (Execution)

The agent calls a tool with specific parameters.

**What happens**:

- Generate tool call with validated parameters
- Execute the tool (API call, database query, etc.)
- Handle execution errors if they occur

**Example**:

```
Action: findResource
Action Input: {
  "query": "about",
  "type": "page"
}
```

**See**: [3.2.3 Acting Phase](./3.2.3-acting-phase.md) for tool execution details

### Phase 3: OBSERVE (Interpretation)

The agent receives and interprets the tool result.

**What happens**:

- Receive tool output (success data or error)
- Extract key information for next step
- Update working memory with new context
- Decide whether to continue or complete

**Example**:

```
Observation: Found 1 page matching "about"
  - ID: page-123
  - Slug: about-us
  - Name: About Us
  - Sections: [hero, features]

Interpretation: Page exists and already has hero section.
Decision: Task may already be complete. Verify with user.
```

**See**: [3.2.4 Observation Phase](./3.2.4-observation-phase.md) for observation patterns

## Implementation Patterns

### Pattern 1: Simple ReAct (Sequential)

**Best for**: Most use cases, clear debugging

```typescript
import { ToolLoopAgent, stepCountIs, tool } from 'ai';
import { z } from 'zod';

const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: `You solve problems step by step.

For each step:
1. THINK: Analyze what you know and what you need
2. ACT: Execute exactly ONE tool
3. OBSERVE: Interpret the result

Continue until the task is complete.`,
  tools: {
    findResource: tool({
      description: 'Search for pages, sections, or other resources',
      inputSchema: z.object({
        query: z.string().describe('Search query'),
        type: z.enum(['page', 'section', 'image']).describe('Resource type'),
      }),
      execute: async ({ query, type }) => {
        // Search implementation
        return { results: [...] };
      },
    }),
    getPage: tool({
      description: 'Get page details by ID',
      inputSchema: z.object({
        id: z.string().describe('Page ID'),
      }),
      execute: async ({ id }) => {
        // Fetch page
        return { page: {...} };
      },
    }),
    addSection: tool({
      description: 'Add a section to a page',
      inputSchema: z.object({
        pageId: z.string().describe('Page ID'),
        sectionType: z.string().describe('Section type (hero, features, etc.)'),
      }),
      execute: async ({ pageId, sectionType }) => {
        // Add section
        return { section: {...} };
      },
    }),
  },
  stopWhen: stepCountIs(10),
});
```

### Pattern 2: ReAct with Memory

**Best for**: Multi-turn conversations, reference resolution

```typescript
const agentWithMemory = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: `You are a CMS assistant with access to working memory.

WORKING MEMORY (recently accessed resources):
{workingMemory}

When user says "this page" or "that section", check working memory
for the most recent resource of that type.

Think step by step, use one tool at a time.`,
  tools: { /* ... */ },
  prepareStep: async ({ context }) => {
    // Inject current memory state into prompt
    return {
      instructions: instructions.replace(
        '{workingMemory}',
        context.workingMemory.toString()
      ),
    };
  },
});
```

### Pattern 3: ReAct with Structured Output

**Best for**: Tasks requiring formatted results

```typescript
import { Output } from 'ai';

const structuredAgent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: 'Research the topic and provide structured findings.',
  tools: {
    search: searchTool,
    fetchUrl: fetchUrlTool,
  },
  output: Output.object({
    schema: z.object({
      summary: z.string(),
      keyFindings: z.array(z.string()),
      sources: z.array(z.object({
        title: z.string(),
        url: z.string(),
      })),
    }),
  }),
  stopWhen: stepCountIs(15),
});

const { output } = await structuredAgent.generate({
  prompt: 'Research the latest developments in quantum computing',
});
// output: { summary: "...", keyFindings: [...], sources: [...] }
```

## Framework Integration

### AI SDK 6 ToolLoopAgent

AI SDK v6 provides native ReAct implementation through `ToolLoopAgent`.

**Full Example**:

```typescript
import { ToolLoopAgent, stepCountIs, hasToolCall, tool } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

// Define tools
const tools = {
  getWeather: tool({
    description: 'Get current weather for a location',
    inputSchema: z.object({
      location: z.string().describe('City name'),
    }),
    execute: async ({ location }) => {
      // API call
      return { location, temperature: 72, condition: 'sunny' };
    },
  }),
  convertTemperature: tool({
    description: 'Convert temperature between Fahrenheit and Celsius',
    inputSchema: z.object({
      temperature: z.number(),
      from: z.enum(['F', 'C']),
      to: z.enum(['F', 'C']),
    }),
    execute: async ({ temperature, from, to }) => {
      if (from === to) return { temperature };
      if (from === 'F') return { temperature: Math.round((temperature - 32) * 5/9) };
      return { temperature: Math.round(temperature * 9/5 + 32) };
    },
  }),
};

// Create agent
const weatherAgent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: 'You help users with weather information. Think step by step.',
  tools,
  stopWhen: stepCountIs(10),
});

// Execute
const result = await weatherAgent.generate({
  prompt: 'What is the weather in San Francisco in Celsius?',
});

console.log(result.text);   // "The weather in San Francisco is 22°C and sunny."
console.log(result.steps);  // Array of all ReAct steps taken
```

**Streaming Example**:

```typescript
// Stream agent execution in real-time
const stream = weatherAgent.stream({
  prompt: 'What is the weather in Tokyo?',
});

for await (const chunk of stream.textStream) {
  process.stdout.write(chunk);
}

// Access steps after streaming
const result = await stream;
console.log(result.steps);
```

### Route Handler Integration

```typescript
// app/api/agent/route.ts
import { createAgentUIStreamResponse } from 'ai';

export async function POST(request: Request) {
  const { messages } = await request.json();

  return createAgentUIStreamResponse({
    agent: weatherAgent,
    messages,
    onStepFinish: ({ step }) => {
      console.log('Step completed:', step.toolCalls);
    },
  });
}
```

## Loop Control

### Stop Conditions

**Step Count**: Stop after N steps (prevent infinite loops)

```typescript
import { stepCountIs } from 'ai';

const agent = new ToolLoopAgent({
  // ...
  stopWhen: stepCountIs(10), // Maximum 10 steps
});
```

**Tool Call**: Stop when specific tool is called

```typescript
import { hasToolCall } from 'ai';

const agent = new ToolLoopAgent({
  // ...
  tools: {
    search: searchTool,
    analyze: analyzeTool,
    finalAnswer: finalAnswerTool, // Special "done" tool
  },
  stopWhen: hasToolCall('finalAnswer'),
});
```

**Multiple Conditions**: Combine conditions

```typescript
const agent = new ToolLoopAgent({
  // ...
  stopWhen: [
    stepCountIs(20),           // Safety limit
    hasToolCall('complete'),   // Normal completion
    hasToolCall('needsHuman'), // Escalation
  ],
});
```

### Iteration Monitoring

```typescript
const agent = new ToolLoopAgent({
  // ...
  onStepFinish: ({ step, stepNumber }) => {
    console.log(`Step ${stepNumber}:`, {
      toolCalls: step.toolCalls?.map(t => t.toolName),
      text: step.text?.substring(0, 100),
    });

    // Custom termination logic
    if (step.toolResults?.some(r => r.error)) {
      console.warn('Tool error detected');
    }
  },
});
```

## Observability & Debugging

### What to Log

```typescript
interface ReActStep {
  stepNumber: number;
  phase: 'think' | 'act' | 'observe';

  // Think phase
  thought?: string;

  // Act phase
  toolName?: string;
  toolInput?: object;

  // Observe phase
  toolResult?: object;
  toolError?: string;

  // Metrics
  tokensUsed: number;
  durationMs: number;
}
```

### Debugging Tips

1. **Log every step**: Capture thought, action, and observation separately
2. **Track token usage**: Identify expensive reasoning patterns
3. **Monitor step counts**: High counts may indicate confusion
4. **Check for loops**: Same tool called repeatedly with same params = problem
5. **Verify observations**: Ensure agent correctly interprets tool results

### Common Issues

| Symptom | Likely Cause | Fix |
| ------- | ------------ | --- |
| Agent loops forever | No clear completion criteria | Add termination prompts |
| Wrong tool selected | Poor tool descriptions | Improve descriptions |
| Same action repeated | Observation not integrated | Check memory updates |
| Random exploration | Unclear goal | Strengthen system prompt |
| Early termination | Over-aggressive stop conditions | Adjust step limits |

## Trade-offs & Considerations

### Advantages

1. **Transparency**: Every decision is explained
2. **Debuggability**: Can trace exactly where things went wrong
3. **Self-correction**: Agent sees errors and can adjust
4. **Flexibility**: Handles novel situations by reasoning

### Disadvantages

1. **Latency**: Multiple LLM calls (one per step)
2. **Cost**: Reasoning tokens add up
3. **Verbosity**: Thought traces consume context
4. **Fragility**: Parsing reasoning traces can fail

### Performance Characteristics

| Metric            | Simple Task | Complex Task |
| ----------------- | ----------- | ------------ |
| **Steps**         | 2-3         | 5-10         |
| **Latency**       | 3-8s        | 15-45s       |
| **Cost**          | $0.01-0.03  | $0.05-0.20   |
| **Success Rate**  | 90-95%      | 75-85%       |

### When to Use ReAct vs Alternatives

| Approach | Best For | Avoid When |
| -------- | -------- | ---------- |
| **ReAct** | Multi-step reasoning, debugging matters | Speed critical |
| **Pure Acting** | Simple tool chains, latency matters | Complex decisions |
| **Plan-Execute** | Long workflows, upfront planning | Dynamic adaptation |
| **Parallel** | Independent subtasks | Sequential dependencies |

## Key Takeaways

1. **ReAct = Reason + Act**: Interleave thinking with action for transparency
2. **One action per step**: Makes debugging and error attribution clear
3. **Observations feed reasoning**: Each result informs the next decision
4. **Stop conditions matter**: Prevent infinite loops with explicit limits
5. **Log everything**: Capture each phase for debugging

**Quick Implementation Checklist**:

- [ ] Define tools with clear descriptions
- [ ] Set reasonable step limits (10-20 max)
- [ ] Include termination guidance in system prompt
- [ ] Log each step (thought, action, observation)
- [ ] Test error recovery paths

## References

1. **Yao et al.** (2022). "ReAct: Synergizing Reasoning and Acting in Language Models". ICLR 2023. https://arxiv.org/abs/2210.03629
2. **AI SDK 6 Documentation** (2025). "ToolLoopAgent". Vercel. https://v6.ai-sdk.dev/docs/reference/ai-sdk-core/tool-loop-agent
3. **Anthropic** (2024). "Building Effective Agents". https://www.anthropic.com/research/building-effective-agents
4. **LangChain ReAct Agent** (2024). LangChain Docs.

**Related Topics**:

- [3.2.2 Reasoning Phase](./3.2.2-reasoning-phase.md) - Deep dive into THINK
- [3.2.3 Acting Phase](./3.2.3-acting-phase.md) - Deep dive into ACT
- [3.2.4 Observation Phase](./3.2.4-observation-phase.md) - Deep dive into OBSERVE
- [3.2.5 AI SDK Implementation](./3.2.5-ai-sdk-implementation.md) - Full implementation

**Layer Index**: [Layer 3: Agent Architecture](../AI_KNOWLEDGE_BASE_TOC.md#layer-3)
