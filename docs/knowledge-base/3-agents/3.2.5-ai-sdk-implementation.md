# 3.2.5 - Implementation with AI SDK v6

## TL;DR

AI SDK v6 provides native ReAct implementation through `ToolLoopAgent`, which handles the reasoning-action-observation cycle, tool orchestration, and streaming without manual loop management. This document covers production-ready patterns for building agents with the Vercel AI SDK.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-03
- **Prerequisites**: [3.2.1-3.2.4 ReAct Phases](./3.2.1-react-loop.md)
- **SDK Version**: AI SDK 6.0+
- **Documentation**: https://v6.ai-sdk.dev/docs/foundations/agents

## Table of Contents

- [Overview](#overview)
- [Core API](#core-api)
- [Tool Definition](#tool-definition)
- [Agent Configuration](#agent-configuration)
- [Execution Methods](#execution-methods)
- [Streaming Integration](#streaming-integration)
- [Context Injection](#context-injection)
- [Production Patterns](#production-patterns)
- [Common Pitfalls](#common-pitfalls)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

AI SDK v6 introduces `ToolLoopAgent` as the primary abstraction for building agentic applications. It manages the complete ReAct cycle internally.

### Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     ToolLoopAgent                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐       │
│  │   Model     │   │   Tools     │   │ Instructions│       │
│  │  (LLM)      │   │  (Actions)  │   │  (System)   │       │
│  └──────┬──────┘   └──────┬──────┘   └──────┬──────┘       │
│         │                 │                 │               │
│         └────────────┬────┴─────────────────┘               │
│                      ▼                                      │
│         ┌─────────────────────────┐                        │
│         │     ReAct Loop          │                        │
│         │  Think → Act → Observe  │                        │
│         └───────────┬─────────────┘                        │
│                     │                                       │
│         ┌───────────┴───────────┐                          │
│         ▼                       ▼                          │
│  ┌─────────────┐         ┌─────────────┐                   │
│  │ .generate() │         │  .stream()  │                   │
│  │  (Batch)    │         │ (Real-time) │                   │
│  └─────────────┘         └─────────────┘                   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### What's New in v6

| Feature | AI SDK 5 | AI SDK 6 |
|---------|----------|----------|
| Tool definition | Manual JSON Schema | Native `tool()` with Zod |
| Loop management | Manual implementation | Built-in `ToolLoopAgent` |
| Context passing | Global state | `experimental_context` |
| Stop conditions | Manual check | `stopWhen` predicates |
| Streaming | Limited support | Full streaming API |
| Step hooks | Not available | `onStepFinish`, `prepareStep` |

## Core API

### ToolLoopAgent Constructor

```typescript
import { ToolLoopAgent, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';

const agent = new ToolLoopAgent({
  // Required
  model: openai('gpt-4o'),

  // Instructions (system prompt)
  instructions: `You are a helpful assistant.
    Think step-by-step before taking action.
    Use tools to accomplish tasks.`,

  // Tools the agent can use
  tools: {
    getWeather: weatherTool,
    searchDatabase: searchTool,
    createRecord: createTool,
  },

  // Stop conditions
  stopWhen: stepCountIs(10), // Max 10 iterations

  // Optional hooks
  prepareStep: async ({ messages }) => {
    // Modify messages before each step
    return { messages };
  },

  onStepFinish: async ({ step }) => {
    // Called after each completed step
    console.log('Step completed:', step.toolCalls);
  },

  // Structured output (optional)
  output: z.object({
    answer: z.string(),
    confidence: z.number(),
  }),
});
```

### Key Configuration Options

| Option | Type | Description |
|--------|------|-------------|
| `model` | `LanguageModel` | LLM to use (OpenAI, Anthropic, etc.) |
| `instructions` | `string` | System prompt for agent behavior |
| `tools` | `Record<string, Tool>` | Available tools |
| `stopWhen` | `StopCondition` | When to terminate loop |
| `prepareStep` | `Function` | Hook before each step |
| `onStepFinish` | `Function` | Hook after each step |
| `experimental_context` | `unknown` | Injected context for tools |
| `output` | `ZodSchema` | Structured output schema |

## Tool Definition

### Basic Tool with Zod Schema

```typescript
import { tool } from 'ai';
import { z } from 'zod';

export const getPage = tool({
  description: 'Retrieve a page by slug or ID',

  inputSchema: z.object({
    slug: z.string().optional().describe('Page slug (e.g., "home")'),
    id: z.string().uuid().optional().describe('Page ID'),
    includeContent: z.boolean()
      .optional()
      .default(false)
      .describe('Include full section content'),
  }).refine(
    data => data.slug || data.id,
    { message: 'Either slug or id is required' }
  ),

  execute: async (input, { experimental_context }) => {
    const ctx = experimental_context as AppContext;

    const page = await ctx.db.pages.findFirst({
      where: input.slug ? { slug: input.slug } : { id: input.id },
      include: input.includeContent ? { sections: true } : undefined,
    });

    if (!page) {
      throw new Error(`Page not found: ${input.slug || input.id}`);
    }

    return {
      success: true,
      data: page,
    };
  },
});
```

### Tool with Context Injection

```typescript
interface AgentContext {
  db: Database;
  services: ServiceContainer;
  session: { userId: string; sessionId: string };
  logger: Logger;
}

export const createPage = tool({
  description: 'Create a new page with the given properties',

  inputSchema: z.object({
    name: z.string().min(1).describe('Page display name'),
    slug: z.string().regex(/^[a-z0-9-]+$/).describe('URL-friendly slug'),
    template: z.enum(['blank', 'landing', 'blog']).default('blank'),
  }),

  execute: async (input, { experimental_context }) => {
    const ctx = experimental_context as AgentContext;

    // Use injected services
    const page = await ctx.services.pages.create({
      ...input,
      createdBy: ctx.session.userId,
    });

    // Log the action
    ctx.logger.info('Page created', { pageId: page.id, slug: input.slug });

    return {
      success: true,
      data: { id: page.id, slug: page.slug, name: page.name },
    };
  },
});
```

### Tool Description Best Practices

```typescript
// ❌ BAD: Vague description
const badTool = tool({
  description: 'Gets data',
  // ...
});

// ✅ GOOD: Specific, actionable description
const goodTool = tool({
  description: `Search for pages matching a query.
    Returns up to 10 results sorted by relevance.
    Use this when the exact slug/ID is unknown.
    For exact lookups, use getPage instead.`,
  // ...
});
```

## Agent Configuration

### Building an Agent

```typescript
import { ToolLoopAgent, stepCountIs, hasToolCall } from 'ai';
import { anthropic } from '@ai-sdk/anthropic';
import * as tools from './tools';

export function createAgent(context: AgentContext) {
  return new ToolLoopAgent({
    model: anthropic('claude-3-5-sonnet-20241022'),

    instructions: loadPromptTemplate('react.xml'),

    tools: {
      // Page operations
      getPage: tools.getPage,
      createPage: tools.createPage,
      updatePage: tools.updatePage,
      deletePage: tools.deletePage,

      // Section operations
      addSection: tools.addSection,
      updateSection: tools.updateSection,

      // Search
      findResource: tools.findResource,
    },

    // Stop after 10 steps OR when specific tool called
    stopWhen: (step) =>
      stepCountIs(10)(step) ||
      hasToolCall('confirmDone')(step),

    // Inject context for all tools
    experimental_context: context,

    // Step lifecycle hooks
    onStepFinish: async ({ step }) => {
      // Update working memory after each step
      for (const call of step.toolCalls || []) {
        const result = step.toolResults?.find(r => r.toolCallId === call.id);
        if (result?.success) {
          context.workingMemory.addFromToolResult(call.toolName, result.data);
        }
      }
    },
  });
}
```

### Stop Conditions

```typescript
import { stepCountIs, hasToolCall, or, and } from 'ai';

// Stop after N steps
stopWhen: stepCountIs(10)

// Stop when specific tool is called
stopWhen: hasToolCall('submitAnswer')

// Combine conditions
stopWhen: or(
  stepCountIs(15),
  hasToolCall('confirmComplete')
)

// Custom condition
stopWhen: (step) => {
  // Stop if agent says "DONE" in output
  return step.text?.includes('TASK COMPLETE');
}
```

### PrepareStep Hook

Modify messages before each LLM call:

```typescript
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },

  prepareStep: async ({ messages, context }) => {
    // Inject fresh working memory into each step
    const memoryContext = context.workingMemory.toContextString();

    // Add as system message
    const enhancedMessages = [
      ...messages,
      {
        role: 'system',
        content: `Current working memory:\n${memoryContext}`,
      },
    ];

    return { messages: enhancedMessages };
  },
});
```

## Execution Methods

### Generate (Batch)

Wait for complete result:

```typescript
const agent = createAgent(context);

const result = await agent.generate({
  prompt: 'Create a landing page with hero and features sections',
});

// Access results
console.log(result.text);           // Final answer text
console.log(result.steps);          // Array of all steps taken
console.log(result.toolCalls);      // All tool calls made
console.log(result.toolResults);    // All tool results
console.log(result.output);         // Structured output (if configured)
```

### Stream (Real-time)

Process events as they happen:

```typescript
const stream = await agent.stream({
  prompt: 'Update the hero section with new content',
});

for await (const event of stream) {
  switch (event.type) {
    case 'step-start':
      console.log('Starting step', event.stepNumber);
      break;

    case 'text-delta':
      // Agent is generating text
      process.stdout.write(event.text);
      break;

    case 'tool-call':
      // Agent is calling a tool
      console.log(`Calling ${event.toolName}`, event.input);
      break;

    case 'tool-result':
      // Tool returned result
      console.log(`Result:`, event.result);
      break;

    case 'step-finish':
      console.log('Step completed');
      break;

    case 'finish':
      console.log('Agent finished:', event.text);
      break;
  }
}
```

### Result Structure

```typescript
interface AgentResult {
  // Final text output
  text: string;

  // All steps taken during execution
  steps: Step[];

  // All tool calls across all steps
  toolCalls: ToolCall[];

  // All tool results across all steps
  toolResults: ToolResult[];

  // Structured output (if schema provided)
  output?: T;

  // Usage statistics
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

interface Step {
  stepNumber: number;
  text: string;
  toolCalls: ToolCall[];
  toolResults: ToolResult[];
}
```

## Streaming Integration

### Server-Sent Events (SSE)

```typescript
// Route handler
export async function POST(request: Request) {
  const { prompt, sessionId } = await request.json();

  const agent = createAgent(getContext(sessionId));
  const stream = await agent.stream({ prompt });

  // Convert to SSE format
  const encoder = new TextEncoder();
  const readable = new ReadableStream({
    async start(controller) {
      for await (const event of stream) {
        const data = JSON.stringify(event);
        controller.enqueue(encoder.encode(`data: ${data}\n\n`));
      }
      controller.enqueue(encoder.encode('data: [DONE]\n\n'));
      controller.close();
    },
  });

  return new Response(readable, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}
```

### UI Stream Helper

```typescript
import { createAgentUIStreamResponse } from 'ai';

export async function POST(request: Request) {
  const { prompt, sessionId } = await request.json();

  const agent = createAgent(getContext(sessionId));

  // Built-in helper for UI-friendly streaming
  return createAgentUIStreamResponse({
    agent,
    prompt,
    onStepStart: (step) => {
      console.log('Step started:', step.number);
    },
    onToolCall: (call) => {
      console.log('Tool called:', call.toolName);
    },
    onFinish: (result) => {
      console.log('Completed in', result.steps.length, 'steps');
    },
  });
}
```

### Client-Side Consumption

```typescript
// React hook
function useAgentStream() {
  const [events, setEvents] = useState<AgentEvent[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);

  const execute = async (prompt: string) => {
    setIsStreaming(true);
    setEvents([]);

    const response = await fetch('/api/agent', {
      method: 'POST',
      body: JSON.stringify({ prompt }),
    });

    const reader = response.body!.getReader();
    const decoder = new TextDecoder();

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const text = decoder.decode(value);
      const lines = text.split('\n\n').filter(Boolean);

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          if (data === '[DONE]') continue;

          const event = JSON.parse(data);
          setEvents(prev => [...prev, event]);
        }
      }
    }

    setIsStreaming(false);
  };

  return { events, isStreaming, execute };
}
```

## Context Injection

### Pattern: Service Container

```typescript
interface AgentContext {
  // Database access
  db: DrizzleDB;

  // Business logic services
  services: {
    pages: PageService;
    sections: SectionService;
    images: ImageService;
  };

  // Session info
  session: {
    userId: string;
    sessionId: string;
    permissions: string[];
  };

  // Working memory for reference resolution
  workingMemory: WorkingMemoryStore;

  // Logging
  logger: Logger;
}

// Create context for each request
function createContext(sessionId: string): AgentContext {
  return {
    db: getDatabase(),
    services: getServiceContainer(),
    session: getSession(sessionId),
    workingMemory: new WorkingMemoryStore(),
    logger: createLogger({ sessionId }),
  };
}

// Use in agent
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },
  experimental_context: createContext(sessionId),
});
```

### Accessing Context in Tools

```typescript
export const updateSection = tool({
  description: 'Update section content',
  inputSchema: z.object({
    sectionId: z.string(),
    content: z.record(z.unknown()),
  }),

  execute: async (input, { experimental_context }) => {
    // Type assertion for context
    const ctx = experimental_context as AgentContext;

    // Check permissions
    if (!ctx.session.permissions.includes('edit:sections')) {
      throw new Error('Permission denied: cannot edit sections');
    }

    // Use service
    const section = await ctx.services.sections.update(
      input.sectionId,
      input.content
    );

    // Update working memory
    ctx.workingMemory.add({
      type: 'section',
      id: section.id,
      name: section.name,
    });

    // Log action
    ctx.logger.info('Section updated', {
      sectionId: input.sectionId,
      userId: ctx.session.userId,
    });

    return { success: true, data: section };
  },
});
```

## Production Patterns

### Timeout Protection

```typescript
async function executeWithTimeout(
  agent: ToolLoopAgent,
  prompt: string,
  timeoutMs: number = 30000
): Promise<AgentResult> {
  const controller = new AbortController();
  const timeout = setTimeout(() => controller.abort(), timeoutMs);

  try {
    const result = await agent.generate({
      prompt,
      signal: controller.signal,
    });
    return result;
  } catch (error) {
    if (error.name === 'AbortError') {
      throw new Error(`Agent timed out after ${timeoutMs}ms`);
    }
    throw error;
  } finally {
    clearTimeout(timeout);
  }
}
```

### Metrics & Logging

```typescript
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },

  onStepFinish: async ({ step }) => {
    // Track metrics
    await metrics.increment('agent.steps.completed', {
      stepNumber: step.stepNumber,
      toolsCalled: step.toolCalls.length,
    });

    // Log for debugging
    logger.debug('Step completed', {
      step: step.stepNumber,
      tools: step.toolCalls.map(c => c.toolName),
      textLength: step.text?.length || 0,
    });

    // Store trace for observability
    await traceStore.addStep({
      stepNumber: step.stepNumber,
      thought: step.text,
      toolCalls: step.toolCalls,
      results: step.toolResults,
      timestamp: Date.now(),
    });
  },
});
```

### Error Recovery

```typescript
async function executeWithRetry(
  agent: ToolLoopAgent,
  prompt: string,
  maxRetries: number = 3
): Promise<AgentResult> {
  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await agent.generate({ prompt });
    } catch (error) {
      lastError = error;

      // Only retry on transient errors
      if (!isTransientError(error)) {
        throw error;
      }

      // Exponential backoff
      const delay = Math.min(1000 * Math.pow(2, attempt), 10000);
      await sleep(delay);

      logger.warn('Retrying agent execution', {
        attempt,
        error: error.message,
        delay,
      });
    }
  }

  throw new Error(`Agent failed after ${maxRetries} attempts: ${lastError?.message}`);
}

function isTransientError(error: Error): boolean {
  return (
    error.message.includes('rate limit') ||
    error.message.includes('timeout') ||
    error.message.includes('network')
  );
}
```

## Common Pitfalls

### Pitfall 1: Missing Tool Descriptions

```typescript
// ❌ BAD: No description
const tool = tool({
  inputSchema: z.object({ id: z.string() }),
  execute: async (input) => { /* ... */ },
});

// ✅ GOOD: Clear description helps LLM choose correctly
const tool = tool({
  description: 'Retrieve a page by its unique identifier. Use when you have the exact page ID.',
  inputSchema: z.object({
    id: z.string().uuid().describe('The page UUID'),
  }),
  execute: async (input) => { /* ... */ },
});
```

### Pitfall 2: No Stop Condition

```typescript
// ❌ BAD: Could loop forever
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },
  // No stopWhen!
});

// ✅ GOOD: Always set a limit
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },
  stopWhen: stepCountIs(10),
});
```

### Pitfall 3: Swallowing Errors

```typescript
// ❌ BAD: Errors disappear
execute: async (input) => {
  try {
    return await db.query(input);
  } catch {
    return null; // Error info lost!
  }
}

// ✅ GOOD: Return structured error
execute: async (input) => {
  try {
    const data = await db.query(input);
    return { success: true, data };
  } catch (error) {
    return {
      success: false,
      error: {
        code: 'QUERY_FAILED',
        message: error.message
      }
    };
  }
}
```

### Pitfall 4: Blocking Context Updates

```typescript
// ❌ BAD: Memory not available in same step
onStepFinish: async ({ step }) => {
  // This runs AFTER the step is complete
  // Agent can't use this info in the same step
  workingMemory.add(extractEntities(step));
}

// ✅ GOOD: Use prepareStep for real-time context
prepareStep: async ({ messages, context }) => {
  // Inject current memory before each step
  return {
    messages: [
      ...messages,
      { role: 'system', content: context.workingMemory.toContextString() },
    ],
  };
}
```

## Key Takeaways

1. **Use ToolLoopAgent** - Don't build manual ReAct loops
2. **Always set stopWhen** - Prevent infinite loops
3. **Inject context** - Use `experimental_context` for services
4. **Write clear descriptions** - Help the LLM choose the right tool
5. **Stream for UX** - Use `.stream()` for real-time feedback
6. **Handle errors structurally** - Return `{ success, data/error }` from tools
7. **Use lifecycle hooks** - `onStepFinish` for logging, `prepareStep` for context

**Production Checklist**:

- [ ] All tools have descriptions and typed schemas
- [ ] Stop condition set with reasonable limit
- [ ] Timeout protection for long-running requests
- [ ] Error handling in all tool executes
- [ ] Logging and metrics in onStepFinish
- [ ] Context injection for services/DB access
- [ ] Streaming for user-facing applications

## References

1. **AI SDK 6 Documentation** (2025). Vercel. https://v6.ai-sdk.dev/docs/foundations/agents
2. **AI SDK 6 API Reference** (2025). Vercel. https://v6.ai-sdk.dev/docs/reference/agents/tool-loop-agent
3. **Zod Documentation** (2024). https://zod.dev
4. **Yao et al.** (2022). "ReAct: Synergizing Reasoning and Acting". https://arxiv.org/abs/2210.03629

**Related Topics**:

- [3.2.1 ReAct Loop](./3.2.1-react-loop.md) - Conceptual foundation
- [3.2.3 Acting Phase](./3.2.3-acting-phase.md) - Tool execution patterns
- [3.2.4 Observation Phase](./3.2.4-observation-phase.md) - Result handling

**Layer Index**: [Layer 3: Agent Architecture](../AI_KNOWLEDGE_BASE_TOC.md#layer-3)
