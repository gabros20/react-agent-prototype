# 3.1.2 - Agent Types & Specialization

## TL;DR

Agents exist on a spectrum from simple reflexive systems (fixed responses) to complex learning agents (self-improving). Choose agent type based on task complexity, required autonomy, and acceptable cost—start simple and increase complexity only when necessary.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-03
- **Prerequisites**: [3.1.1 Agent Definition](./3.1.1-agent-definition.md)
- **Grounded In**: Russell & Norvig (2020), Autonomous Agents Framework (2024), A3T (2025)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-one-size-doesnt-fit-all)
- [Core Concept](#core-concept)
- [Type 1: Reflexive Agents](#type-1-reflexive-agents)
- [Type 2: Goal-Based Agents](#type-2-goal-based-agents)
- [Type 3: Utility-Based Agents](#type-3-utility-based-agents)
- [Type 4: Learning Agents](#type-4-learning-agents)
- [Hybrid Approaches](#hybrid-approaches)
- [Framework Integration](#framework-integration)
- [When to Use Each Type](#when-to-use-each-type)
- [Trade-offs & Considerations](#trade-offs--considerations)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

Not all agents are created equal. The AI and robotics literature distinguishes several agent types, each with different capabilities, costs, and use cases. Understanding this spectrum helps you choose the right level of complexity for your task.

**Key Research Findings** (2024-2025):

- **96% success rate**: Learning agents after self-training (A3T, 2025)
- **5-20× cost difference**: Reflexive vs utility-based agents per request
- **15× latency difference**: Simple vs complex agent patterns
- **70% of use cases**: Solvable with simpler approaches (Anthropic, 2024)

**Date Verified**: December 2025

## The Problem: One Size Doesn't Fit All

### The Complexity Trap

Developers often reach for the most sophisticated agent pattern without considering simpler alternatives:

- **Over-engineering**: Using a learning agent for FAQ responses
- **Under-engineering**: Using reflexive rules for research tasks
- **Mismatched costs**: Paying for utility optimization on simple lookups

**Example**: A support system receives both simple greetings and complex debugging requests. Using the same agent architecture for both wastes resources on trivial tasks and may under-serve complex ones.

## Core Concept

### The Agent Complexity Spectrum

```
Increasing Complexity, Cost, and Capability
─────────────────────────────────────────────►

┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│  REFLEXIVE   │ │  GOAL-BASED  │ │   UTILITY    │ │   LEARNING   │
│              │ │              │ │              │ │              │
│ IF-THEN      │ │ Plan toward  │ │ Optimize for │ │ Improve from │
│ rules        │ │ objectives   │ │ best outcome │ │ experience   │
│              │ │              │ │              │ │              │
│ No LLM       │ │ LLM for      │ │ LLM for      │ │ LLM + self-  │
│ needed       │ │ planning     │ │ evaluation   │ │ training     │
└──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘
    Simple           Moderate          Complex          Adaptive
    <$0.001          $0.01-0.05        $0.05-0.20       $0.10-1.00
    <10ms            5-15s             10-30s           Variable
```

### Key Principles

1. **Match complexity to task**: Don't use a sledgehammer for a nail
2. **Cost scales with capability**: Each tier adds overhead
3. **Composability**: Types can be layered (reflexive front, agent back)
4. **Progression**: Start simple, graduate complexity as needed

## Type 1: Reflexive Agents

### Definition

**Reflexive agents** respond to inputs using predetermined if-then rules without internal state, planning, or reasoning.

### Visual Representation

```
┌─────────────────────────────────────┐
│         REFLEXIVE AGENT             │
├─────────────────────────────────────┤
│                                     │
│   Input ──► Rule Matching ──► Output│
│                                     │
│   "hello" → IF greeting → "Hi!"     │
│   "help"  → IF help → "How can I?"  │
│   "bye"   → IF farewell → "Goodbye!"│
│                                     │
│   No reasoning, no state, no LLM    │
│                                     │
└─────────────────────────────────────┘
```

### Characteristics

| Aspect          | Value                        |
| --------------- | ---------------------------- |
| **Autonomy**    | None - predetermined paths   |
| **Complexity**  | Very Low                     |
| **Cost**        | Minimal (<$0.001/request)    |
| **Latency**     | <10ms                        |
| **Setup Time**  | Hours                        |
| **Flexibility** | Very Limited                 |

### Implementation

```typescript
interface ReflexiveAgent {
  rules: Array<{
    pattern: RegExp;
    response: string | (() => string);
  }>;
}

const supportBot: ReflexiveAgent = {
  rules: [
    { pattern: /hello|hi|hey/i, response: 'Hello! How can I help?' },
    { pattern: /password|reset/i, response: 'Visit /reset to reset your password.' },
    { pattern: /pricing|cost/i, response: 'See our pricing at /pricing' },
    { pattern: /bye|thanks/i, response: 'Goodbye! Have a great day!' },
  ],
};

function processReflexive(input: string, agent: ReflexiveAgent): string {
  for (const rule of agent.rules) {
    if (rule.pattern.test(input)) {
      return typeof rule.response === 'function'
        ? rule.response()
        : rule.response;
    }
  }
  return "I didn't understand. Please try again or contact support.";
}
```

### Use Cases

**✅ Good for**:

- Chatbot quick replies and greetings
- FAQ keyword matching
- Simple command routing
- Content moderation filters
- Intent classification (first-pass)

**❌ Not for**:

- Multi-step tasks
- Anything requiring reasoning
- Novel situations
- Context-dependent responses

## Type 2: Goal-Based Agents

### Definition

**Goal-based agents** can plan toward specified objectives using available tools. They decompose goals into steps but don't evaluate success quality.

### Visual Representation

```
┌─────────────────────────────────────────┐
│           GOAL-BASED AGENT              │
├─────────────────────────────────────────┤
│                                         │
│   User: "Create a page called About"    │
│              │                          │
│              ▼                          │
│   ┌─────────────────┐                   │
│   │   GOAL PARSER   │                   │
│   │   Goal: Create  │                   │
│   │   page "About"  │                   │
│   └────────┬────────┘                   │
│            │                            │
│            ▼                            │
│   ┌─────────────────┐                   │
│   │    PLANNER      │                   │
│   │   1. Find       │                   │
│   │      template   │                   │
│   │   2. Create     │                   │
│   │      page       │                   │
│   │   3. Set name   │                   │
│   └────────┬────────┘                   │
│            │                            │
│            ▼                            │
│   ┌─────────────────┐                   │
│   │   EXECUTOR      │ ──► Tools         │
│   │   (Sequential)  │                   │
│   └────────┬────────┘                   │
│            │                            │
│            ▼                            │
│        "Done"                           │
│                                         │
└─────────────────────────────────────────┘
```

### Characteristics

| Aspect          | Value                             |
| --------------- | --------------------------------- |
| **Autonomy**    | Moderate - plans but doesn't eval |
| **Complexity**  | Medium                            |
| **Cost**        | $0.01-0.05/request                |
| **Latency**     | 5-15s (planning + execution)      |
| **Setup Time**  | Days                              |
| **Flexibility** | Good for known goal types         |

### Implementation

```typescript
import { ToolLoopAgent, stepCountIs, tool } from 'ai';
import { z } from 'zod';

const goalBasedAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  instructions: `You accomplish goals by planning and executing steps.

When given a goal:
1. Break it into concrete steps
2. Execute each step using tools
3. Report completion

Do not evaluate quality - just complete the plan.`,
  tools: {
    createPage: tool({
      description: 'Create a new page',
      inputSchema: z.object({
        name: z.string(),
        slug: z.string(),
      }),
      execute: async ({ name, slug }) => {
        // Create page in CMS
        return { id: 'page-123', name, slug };
      },
    }),
    addSection: tool({
      description: 'Add a section to a page',
      inputSchema: z.object({
        pageId: z.string(),
        sectionType: z.string(),
      }),
      execute: async ({ pageId, sectionType }) => {
        // Add section
        return { id: 'section-456', type: sectionType };
      },
    }),
  },
  stopWhen: stepCountIs(10),
});
```

### Use Cases

**✅ Good for**:

- Structured workflows (known steps)
- Multi-tool orchestration
- Tasks with clear, achievable goals
- Cost optimization (plan once, execute)

**❌ Not for**:

- Uncertain workflows
- Tasks requiring quality evaluation
- Real-time adaptation
- Handling unexpected outcomes

## Type 3: Utility-Based Agents

### Definition

**Utility-based agents** evaluate multiple options and choose actions that maximize a utility function (optimizing for cost, time, quality, or other metrics).

### Visual Representation

```
┌─────────────────────────────────────────────┐
│           UTILITY-BASED AGENT               │
├─────────────────────────────────────────────┤
│                                             │
│   User: "Summarize these 100 articles"      │
│              │                              │
│              ▼                              │
│   ┌───────────────────────────────┐         │
│   │      OPTION GENERATOR         │         │
│   │                               │         │
│   │  Option A: API ($5, 30s)      │         │
│   │  Option B: Local ($0, 5min)   │         │
│   │  Option C: Hybrid ($1, 2min)  │         │
│   └──────────────┬────────────────┘         │
│                  │                          │
│                  ▼                          │
│   ┌───────────────────────────────┐         │
│   │      UTILITY EVALUATOR        │         │
│   │                               │         │
│   │  U(A) = 0.3×cost + 0.3×speed  │         │
│   │       + 0.4×quality = 0.6     │         │
│   │  U(B) = ... = 0.3             │         │
│   │  U(C) = ... = 0.8 ◄── BEST    │         │
│   └──────────────┬────────────────┘         │
│                  │                          │
│                  ▼                          │
│   ┌───────────────────────────────┐         │
│   │      EXECUTE OPTION C         │         │
│   └──────────────┬────────────────┘         │
│                  │                          │
│                  ▼                          │
│            Optimal Result                   │
│                                             │
└─────────────────────────────────────────────┘
```

### Characteristics

| Aspect          | Value                         |
| --------------- | ----------------------------- |
| **Autonomy**    | High - decides best approach  |
| **Complexity**  | High                          |
| **Cost**        | $0.05-0.20/request            |
| **Latency**     | 10-30s (includes evaluation)  |
| **Setup Time**  | Weeks                         |
| **Flexibility** | Excellent - adapts to context |

### Implementation

```typescript
interface UtilityFunction {
  cost: { weight: number; inverse: boolean };
  speed: { weight: number; inverse: boolean };
  quality: { weight: number; inverse: boolean };
}

interface ActionOption {
  name: string;
  metrics: { cost: number; speed: number; quality: number };
  execute: () => Promise<unknown>;
}

function calculateUtility(
  option: ActionOption,
  utility: UtilityFunction
): number {
  let score = 0;
  for (const [dimension, config] of Object.entries(utility)) {
    const value = option.metrics[dimension as keyof typeof option.metrics];
    const normalized = config.inverse ? 1 / (value + 0.001) : value;
    score += normalized * config.weight;
  }
  return score;
}

async function selectBestAction(
  options: ActionOption[],
  utility: UtilityFunction
): Promise<ActionOption> {
  let best = options[0];
  let bestScore = calculateUtility(best, utility);

  for (const option of options.slice(1)) {
    const score = calculateUtility(option, utility);
    if (score > bestScore) {
      best = option;
      bestScore = score;
    }
  }

  return best;
}
```

### Use Cases

**✅ Good for**:

- Cost optimization across methods
- Resource-constrained systems
- Complex trade-offs (speed vs quality)
- Real-time decision making with options

**❌ Not for**:

- Simple tasks (overkill)
- When one option is always best
- Uncertain utility weights
- Systems requiring full explainability

## Type 4: Learning Agents

### Definition

**Learning agents** improve their decision-making over time by observing outcomes and updating their models or strategies.

### Visual Representation

```
┌─────────────────────────────────────────────┐
│            LEARNING AGENT                   │
├─────────────────────────────────────────────┤
│                                             │
│   Iteration 1:                              │
│   ┌─────────────┐                           │
│   │ Try Path A  │ ──► FAIL                  │
│   └─────────────┘                           │
│         │                                   │
│         ▼                                   │
│   ┌─────────────────────────────────────┐   │
│   │  LEARNING: "Path A doesn't work"    │   │
│   │  Update: Avoid A for similar tasks  │   │
│   └─────────────────────────────────────┘   │
│                                             │
│   Iteration 2:                              │
│   ┌─────────────┐                           │
│   │ Try Path B  │ ──► SUCCESS               │
│   └─────────────┘                           │
│         │                                   │
│         ▼                                   │
│   ┌─────────────────────────────────────┐   │
│   │  LEARNING: "Path B works well"      │   │
│   │  Store: Successful trajectory       │   │
│   └─────────────────────────────────────┘   │
│                                             │
│   Iteration 3 (similar task):               │
│   ┌─────────────────────────────────────┐   │
│   │  Recall: Path B worked before       │   │
│   │  Apply: Use Path B again            │   │
│   │  Result: Faster success             │   │
│   └─────────────────────────────────────┘   │
│                                             │
└─────────────────────────────────────────────┘
```

### Characteristics

| Aspect          | Value                             |
| --------------- | --------------------------------- |
| **Autonomy**    | Very High - self-improving        |
| **Complexity**  | Very High                         |
| **Cost**        | $0.10-1.00/request (+ training)   |
| **Latency**     | First slow, subsequent fast       |
| **Setup Time**  | Months                            |
| **Flexibility** | Excellent - adapts dynamically    |

### Research: A3T Framework (2025)

The Autonomous Annotation of Agent Trajectories (A3T) framework demonstrates:

- **96% success** on first attempt (with fine-tuned prompts)
- **100% success** after 4 iterations
- Self-training without human annotation
- Trajectory-based learning from execution history

### Use Cases

**✅ Good for**:

- High-volume, repetitive tasks
- Systems needing continuous improvement
- Research/exploration scenarios
- Tasks where finding optimal paths is expensive initially

**❌ Not for**:

- One-off tasks
- Real-time requirements (initially)
- Safety-critical systems (need explainability)
- When training infrastructure unavailable

## Hybrid Approaches

### Layered Agent Architecture

Real systems often combine multiple types in layers:

```
┌──────────────────────────────────────────┐
│            HYBRID SYSTEM                 │
├──────────────────────────────────────────┤
│                                          │
│   Incoming Request                       │
│         │                                │
│         ▼                                │
│   ┌──────────────┐                       │
│   │  REFLEXIVE   │ ──► Quick replies     │
│   │   (Layer 1)  │     FAQs, greetings   │
│   └──────┬───────┘                       │
│          │ (complex)                     │
│          ▼                               │
│   ┌──────────────┐                       │
│   │  GOAL-BASED  │ ──► Multi-step tasks  │
│   │   (Layer 2)  │     Known workflows   │
│   └──────┬───────┘                       │
│          │ (uncertain)                   │
│          ▼                               │
│   ┌──────────────┐                       │
│   │   LEARNING   │ ──► Improve over time │
│   │   (Layer 3)  │     Novel situations  │
│   └──────────────┘                       │
│                                          │
└──────────────────────────────────────────┘
```

### Example: E-Commerce Support System

```typescript
// Layer 1: Reflexive classification
function classifyQuery(query: string): 'simple' | 'workflow' | 'complex' {
  if (/hello|hi|thanks|bye/i.test(query)) return 'simple';
  if (/order|refund|exchange/i.test(query)) return 'workflow';
  return 'complex';
}

// Layer 2: Goal-based for known workflows
const workflowAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o-mini', // Cheaper model for known paths
  tools: { checkOrder, processRefund, initiateExchange },
  stopWhen: stepCountIs(5),
});

// Layer 3: Full agent for complex queries
const complexAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o', // Smarter model for complex reasoning
  tools: { /* full tool suite */ },
  stopWhen: stepCountIs(15),
});

// Router
async function handleQuery(query: string) {
  const type = classifyQuery(query);

  switch (type) {
    case 'simple':
      return getReflexiveResponse(query);
    case 'workflow':
      return workflowAgent.generate({ prompt: query });
    case 'complex':
      return complexAgent.generate({ prompt: query });
  }
}
```

## Framework Integration

### AI SDK 6 Stop Conditions

Control agent behavior based on type with stop conditions:

```typescript
import { ToolLoopAgent, stepCountIs, hasToolCall } from 'ai';

// Simple agent: stop after 3 steps (goal-based)
const simpleAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o-mini',
  tools: { /* ... */ },
  stopWhen: stepCountIs(3),
});

// Complex agent: stop when specific tool called (utility-like)
const complexAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  tools: {
    analyze: analyzeTool,
    finalAnswer: finalAnswerTool,
  },
  stopWhen: hasToolCall('finalAnswer'),
});

// Flexible agent: multiple conditions
const flexibleAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  tools: { /* ... */ },
  stopWhen: [
    stepCountIs(15),
    hasToolCall('taskComplete'),
  ],
});
```

### Tool Choice Strategies

```typescript
// Auto: Model decides (default)
const autoAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  tools: { a, b, c },
  toolChoice: 'auto',
});

// Force first tool (goal-based behavior)
const forcedAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  tools: { getContext, analyze, respond },
  toolChoice: { type: 'tool', toolName: 'getContext' },
});

// Required: Must use tools before text
const requiredAgent = new ToolLoopAgent({
  model: 'openai/gpt-4o',
  tools: { search, calculate },
  toolChoice: 'required',
});
```

## When to Use Each Type

### Decision Matrix

| Factor                 | Reflexive    | Goal-Based   | Utility      | Learning     |
| ---------------------- | ------------ | ------------ | ------------ | ------------ |
| **Complexity**         | ⭐           | ⭐⭐         | ⭐⭐⭐       | ⭐⭐⭐⭐⭐   |
| **Cost per Request**   | <$0.001      | $0.01-0.05   | $0.05-0.20   | $0.10-1.00   |
| **Latency**            | <10ms        | 5-15s        | 10-30s       | Variable     |
| **Flexibility**        | ❌           | ✅✅         | ✅✅✅       | ✅✅✅✅     |
| **Setup Time**         | Hours        | Days         | Weeks        | Months       |
| **Success Rate**       | 70%          | 80%          | 85%          | 96%+         |
| **Explainability**     | ✅✅✅✅     | ✅✅✅       | ✅✅         | ✅           |

### Quick Selection Guide

```
START
  │
  ├─ Simple, repetitive, fast? ──────────► REFLEXIVE
  │
  ├─ Clear multi-step workflow? ─────────► GOAL-BASED
  │
  ├─ Need to optimize trade-offs? ───────► UTILITY-BASED
  │
  ├─ High volume, needs improvement? ────► LEARNING
  │
  └─ Combination of above? ──────────────► HYBRID
```

## Trade-offs & Considerations

### Comparison Summary

| Type          | Pros                                   | Cons                                   |
| ------------- | -------------------------------------- | -------------------------------------- |
| **Reflexive** | Fast, cheap, deterministic             | Inflexible, no reasoning               |
| **Goal-Based**| Handles multi-step, moderate cost      | No quality evaluation, rigid plans     |
| **Utility**   | Optimizes outcomes, adaptable          | Complex setup, expensive               |
| **Learning**  | Self-improving, highest success        | Slow initially, needs infrastructure   |

### Migration Paths

**Upgrading complexity** (when simple fails):

1. Add more rules → still failing? → goal-based
2. Plans don't adapt → utility-based
3. Need continuous improvement → learning

**Downgrading complexity** (when overkill):

1. Learning agent always same path → goal-based
2. Goal agent always same 2 steps → reflexive
3. Utility evaluation always picks same option → remove evaluation

## Key Takeaways

1. **Start with the simplest type that works** - Reflexive → Goal → Utility → Learning
2. **Match cost to value** - Don't spend $0.20 on a $0.01 task
3. **Hybrid systems often win** - Layer types for different query complexity
4. **Learning agents require investment** - But pay off at scale
5. **Explainability decreases with complexity** - Consider audit requirements

**Quick Checklist**:

- [ ] What's the simplest type that could work?
- [ ] What's the acceptable cost per request?
- [ ] How important is explainability?
- [ ] Will the same tasks repeat at scale?
- [ ] Is real-time response required?

## References

1. **Russell, S. & Norvig, P.** (2020). "Artificial Intelligence: A Modern Approach" (4th Edition). Pearson.
2. **A3T Framework** (2025). "Autonomous Annotation of Agent Trajectories". arXiv.
3. **Anthropic** (2024). "Building Effective Agents". https://www.anthropic.com/research/building-effective-agents
4. **AI SDK 6 Documentation** (2025). Vercel. https://v6.ai-sdk.dev/docs/foundations/agents
5. **LangChain Agent Types** (2024). LangChain Docs. https://docs.langchain.com/docs/expression_language/agents

**Related Topics**:

- [3.1.1 Agent Definition](./3.1.1-agent-definition.md) - Core concepts
- [3.1.3 When to Use Agents](./3.1.3-when-agents.md) - Decision framework
- [3.2.1 ReAct Loop](./3.2.1-react-loop.md) - Goal-based implementation

**Layer Index**: [Layer 3: Agent Architecture](../AI_KNOWLEDGE_BASE_TOC.md#layer-3)
