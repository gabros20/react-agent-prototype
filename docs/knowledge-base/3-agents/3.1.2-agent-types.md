# 3.1.2 - Agent Types & Specialization

## TL;DR
Agents range from simple reflexive systems (fixed responses to stimuli) to complex utility-based agents (optimizing outcomes). Each type trades off between simplicity, flexibility, and computational cost. Choose based on task complexity and required autonomy.

**Prerequisites**: [3.1.1 Agent Definition]
**Key Research**: Autonomous Agents Framework (2022-2025)

---

## Agent Type Spectrum

Agents exist on a spectrum from rigid to adaptive:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Agent Complexity Spectrum                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Reflexive  â†’  Goal-Based  â†’  Utility-Based  â†’  Learning  â”‚
â”‚  Simple         Moderate        Complex          Adaptive   â”‚
â”‚  Cheap          Medium          Expensive        Expensive  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Type 1: Reflexive Agents

### Definition
**Reflexive agents** follow simple if-then rules without internal state or planning.

### How It Works

```
Input â†’ Rule Matching â†’ Output
"User typed 'hello'" â†’ Rule: IF greeting THEN respond
                     â†’ "Hello! How can I help?"
```

### Characteristics

| Aspect | Value |
|--------|-------|
| **Autonomy** | None - predetermined responses |
| **Complexity** | Very Low |
| **Cost** | Minimal (no LLM needed) |
| **Latency** | <10ms |
| **Setup Time** | Hours |
| **Flexibility** | Very Limited |

### Example Implementation

```typescript
const reflexiveAgent = {
  rules: [
    { trigger: "greeting", response: "Hello!" },
    { trigger: "goodbye", response: "Goodbye!" },
    { trigger: "help", response: "How can I help?" }
  ],

  process(input: string): string {
    for (const rule of this.rules) {
      if (input.toLowerCase().includes(rule.trigger)) {
        return rule.response;
      }
    }
    return "I didn't understand that.";
  }
}
```

### When to Use

âœ… **Good for**:
- Chatbot quick replies
- FAQ matching
- Simple command routing
- Content moderation filters

âŒ **Not for**:
- Multi-step tasks
- Reasoning required
- Handling novel situations
- Anything requiring context understanding

---

## Type 2: Goal-Based Agents

### Definition
**Goal-based agents** can plan towards a specified objective using available tools.

### How It Works

```
User: "Create a page called 'About'"
                    â†“
        Goal: Create page with name "About"
                    â†“
            Plan: 1) Find page template
                  2) Create page
                  3) Set name
                    â†“
         Execute plan with tools
                    â†“
           Return result to user
```

### Characteristics

| Aspect | Value |
|--------|-------|
| **Autonomy** | Moderate - plans but doesn't evaluate success |
| **Complexity** | Medium |
| **Cost** | LLM calls for planning + execution |
| **Latency** | 5-15s (includes planning) |
| **Setup Time** | Days (design tools, prompts) |
| **Flexibility** | Good for known goal types |

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Goal      â”‚
â”‚   Input     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Planner  â”‚ - Breaks goal into steps
   â”‚  (LLM)    â”‚ - Outputs: Step 1, 2, 3...
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Executor    â”‚ - Runs each step
   â”‚  (Tool Loop) â”‚ - Returns results
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Result     â”‚
   â”‚   Delivery   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Implementation

```typescript
class GoalBasedAgent {
  async execute(goal: string): Promise<string> {
    // Step 1: Create plan
    const plan = await this.llm.generatePlan(goal);
    // plan: ["Step 1: Find template", "Step 2: Create page", ...]

    // Step 2: Execute each step
    for (const step of plan.steps) {
      const tool = this.selectTool(step);
      const result = await this.tools.execute(tool);
      // Don't evaluate - just do what the plan says
    }

    return "Plan executed";
  }
}
```

### When to Use

âœ… **Good for**:
- Structured workflows (known steps)
- Multi-tool orchestration
- Tasks with clear goals
- When you want to optimize cost (plan once, execute)

âŒ **Not for**:
- Uncertain workflows
- Tasks requiring adaptation
- Real-time decision making
- Handling unexpected outcomes

---

## Type 3: Utility-Based Agents

### Definition
**Utility-based agents** evaluate options and choose actions that maximize a utility function (e.g., cost, time, quality).

### How It Works

```
User: "Summarize these 100 articles efficiently"
              â†“
    Options:
    1. Use search + summarization API (Cost: $5, Speed: 30s)
    2. Download all locally + LLM process (Cost: $0, Speed: 5min)
    3. Hybrid: Search for key ones + local process (Cost: $1, Speed: 2min)
              â†“
    Evaluate utility of each option
              â†“
    Choose: Option 3 (best balance)
              â†“
    Execute chosen strategy
```

### Characteristics

| Aspect | Value |
|--------|-------|
| **Autonomy** | High - decides best approach |
| **Complexity** | High |
| **Cost** | Multiple LLM calls for evaluation |
| **Latency** | 10-30s (includes decision making) |
| **Setup Time** | Weeks (define utility, weights) |
| **Flexibility** | Excellent - adapts to constraints |

### Decision Matrix Example

```
Action                    Cost   Speed   Quality   UTILITY
â”œâ”€ Option 1: API only     $5    30s     0.8       0.6
â”œâ”€ Option 2: Local only   $0    300s    1.0       0.3
â”œâ”€ Option 3: Hybrid       $1    120s    0.95      0.8  â† Choose
â””â”€ Option 4: Cache hit    $0    1s      0.7       0.7
```

### Example Implementation

```typescript
class UtilityBasedAgent {
  // Define utility function
  private utilityFunction = {
    cost: { weight: 0.3, inverse: true },      // Lower cost is better
    speed: { weight: 0.3, inverse: true },     // Faster is better
    quality: { weight: 0.4, inverse: false }   // Higher quality is better
  };

  async selectBestAction(options: Action[]): Promise<Action> {
    let bestAction = null;
    let bestUtility = -Infinity;

    for (const action of options) {
      // Evaluate each option
      const utility = this.calculateUtility(action);

      if (utility > bestUtility) {
        bestUtility = utility;
        bestAction = action;
      }
    }

    return bestAction;
  }

  private calculateUtility(action: Action): number {
    let utility = 0;

    for (const [dimension, config] of Object.entries(this.utilityFunction)) {
      const value = action.metrics[dimension];
      const normalized = config.inverse ? 1 / value : value;
      utility += normalized * config.weight;
    }

    return utility;
  }
}
```

### When to Use

âœ… **Good for**:
- Cost optimization
- Resource-constrained systems
- Complex trade-offs (speed vs quality)
- Real-time decision making

âŒ **Not for**:
- Simple tasks (overkill)
- When one option is always best
- Uncertain utility weights
- Systems requiring explainability

---

## Type 4: Learning Agents

### Definition
**Learning agents** improve their decision-making over time by observing outcomes and updating their models.

### How It Works

```
Iteration 1:
  Action: Try approach A
  Outcome: Fails
  Learning: Don't use A

Iteration 2:
  Action: Try approach B
  Outcome: Success
  Learning: B works well

Iteration 3:
  Action: Similar task - choose B again
  Outcome: Success
  Result: Agent learned which approach works
```

### Characteristics

| Aspect | Value |
|--------|-------|
| **Autonomy** | Very High - self-improving |
| **Complexity** | Very High |
| **Cost** | Multiple trials required |
| **Latency** | First attempt slow, subsequent fast |
| **Setup Time** | Months (training infrastructure) |
| **Flexibility** | Excellent - adapts dynamically |

### Research: A3T Framework (2025)

Recent research (A3T - Autonomous Annotation of Agent Trajectories) shows learning agents achieving:

- **96% success** on first attempt (with fine-tuned prompts)
- **100% success** after 4 iterations
- Self-training without human annotation

### Simplified Learning Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Task: Summarize 100 articles          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼                         â–¼
    Path A:              Path B:
    Local LLM            API call
    [Success: 0.6]       [Success: 0.9]
        â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            [Store successful
             trajectory B]
                    â”‚
         (Next similar task:
          Agent learns to
          prefer Path B)
```

### When to Use

âœ… **Good for**:
- High-volume, repetitive tasks
- Systems that need continuous improvement
- Research/exploration scenarios
- Tasks where finding optimal solution is expensive

âŒ **Not for**:
- One-off tasks
- Real-time requirements
- Safety-critical systems (need explainability)
- When training infrastructure unavailable

---

## Agent Type Comparison Matrix

| Factor | Reflexive | Goal-Based | Utility | Learning |
|--------|-----------|-----------|--------|----------|
| **Complexity** | â­ | â­â­ | â­â­â­ | â­â­â­â­â­ |
| **Cost** | â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **Flexibility** | âŒ | âœ…âœ… | âœ…âœ…âœ… | âœ…âœ…âœ…âœ… |
| **Time to implement** | Hours | Days | Weeks | Months |
| **Success rate** | 70% | 80% | 85% | 96%+ |
| **Explainability** | âœ…âœ…âœ…âœ… | âœ…âœ…âœ… | âœ…âœ… | âœ… |

---

## Hybrid Approaches

Modern systems often combine multiple types:

### Example: E-Commerce Support System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Customer Query                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Reflexive     â”‚   Quick replies
        â”‚  Layer         â”‚   FAQ matches
        â”‚  (Rules)       â”‚   â†“ if simple
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ (if complex)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Goal-Based    â”‚   Multi-step
        â”‚  Layer         â”‚   workflow
        â”‚  (Planner)     â”‚   â†“ if known goal
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ (if uncertain)
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Learning      â”‚   Improve over
        â”‚  Layer         â”‚   time from
        â”‚  (Continuous)  â”‚   interactions
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Choosing Your Agent Type

### Decision Tree

```
START
  â”‚
  â”œâ”€ Simple, repetitive? â†’ Reflexive (rule-based)
  â”‚
  â”œâ”€ Clear multi-step workflow? â†’ Goal-Based (planning)
  â”‚
  â”œâ”€ Need to optimize trade-offs? â†’ Utility-Based
  â”‚
  â”œâ”€ High volume, need improvement? â†’ Learning
  â”‚
  â””â”€ Combination of above? â†’ Hybrid (most real systems)
```

### Real-World Examples

**Reflexive**: Support chatbot quick-reply button "How can I reset my password?"

**Goal-Based**: Content management agent creating pages with multiple sections

**Utility-Based**: Resource optimizer choosing between API, local processing, or cache

**Learning**: Recommendation engine improving suggestions from interaction patterns

---

## Your System (CMS Agent)

Based on `/server/prompts/react.xml`, you're building a **Goal-Based Agent** with **Learning Potential**:

âœ… **Goal-based characteristics**:
- Multi-step workflows (create page â†’ add sections â†’ populate content)
- Clear planning ("identify what actions you need")
- Tool execution (CMS operations)

ğŸ”„ **Learning opportunity**:
- Log successful trajectories
- Use past solutions for similar future tasks
- Improve efficiency over time

---

## References

1. Autonomous Agents Framework (2022-2025)
2. A3T: Autonomous Annotation of Agent Trajectories (2025)
3. LangChain Agent Types (2024)
4. CrewAI Role Specialization (2024)
5. Utility-Based Agent Theory (Russell & Norvig, 2020)

---

**Status**: Complete
**Word Count**: ~2,200
**Last Updated**: November 21, 2025
