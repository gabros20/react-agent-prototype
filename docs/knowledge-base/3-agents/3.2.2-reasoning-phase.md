# 3.2.2 - Reasoning Phase: Think Before Acting

## TL;DR

The reasoning phase is where the LLM analyzes context, identifies gaps, evaluates tool options, and forms a plan before acting. This "thinking out loud" produces visible reasoning traces that make agents debuggable and self-correcting—leading to 15-25% higher accuracy than pure tool-calling approaches.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-03
- **Prerequisites**: [3.2.1 ReAct Loop](./3.2.1-react-loop.md)
- **Grounded In**: ReAct (Yao et al., 2022), Chain-of-Thought (Wei et al., 2022)

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-impulsive-tool-calling)
- [Core Concept](#core-concept)
- [Reasoning Patterns](#reasoning-patterns)
- [Tool Selection Strategies](#tool-selection-strategies)
- [Framework Integration](#framework-integration)
- [Common Reasoning Failures](#common-reasoning-failures)
- [Trade-offs & Considerations](#trade-offs--considerations)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

The reasoning phase is the "THINK" step in the ReAct loop where the agent pauses to analyze the situation before taking action. This explicit deliberation produces reasoning traces that explain why the agent chose a particular tool or approach.

**Key Research Findings**:

- **15-25% accuracy improvement**: Explicit reasoning vs pure acting (ReAct, 2022)
- **20-60% improvement on complex tasks**: Chain-of-Thought prompting (Wei et al., 2022)
- **Error recovery**: Visible traces enable course correction
- **Token trade-off**: ~100-300 tokens per reasoning step

**Date Verified**: December 2025

## The Problem: Impulsive Tool-Calling

### The Reactionary Agent

Agents without explicit reasoning often:

1. **Jump to the first tool that seems relevant**
2. **Miss context from previous steps**
3. **Fail to consider alternatives**
4. **Can't explain their decisions**

**Example: Impulsive Agent**

```
User: "Update the hero section on the about page"

Agent: [immediately calls updateSection("hero", {...})]
       → ERROR: Section ID not provided

Agent: [calls updateSection("hero-section", {...})]
       → ERROR: Page context missing

Agent: [gives up or hallucinates]
```

**Example: Reasoning Agent**

```
User: "Update the hero section on the about page"

Thought: User wants to update hero section on about page.
         I need: 1) About page ID, 2) Hero section ID
         I don't have either yet.
         First, I'll find the about page.

Action: findResource(query: "about", type: "page")
Observation: Found page-123 (about-us)

Thought: Got the page. Now I need the hero section ID.
         I'll get the page details including sections.

Action: getPage(id: "page-123")
Observation: Page has sections: [hero-456, features-789]

Thought: Found hero section ID (hero-456).
         Now I can update it with user's changes.

Action: updateSection(id: "hero-456", content: {...})
Observation: Successfully updated
```

## Core Concept

### What Happens in Reasoning

```
┌─────────────────────────────────────────────────────────────┐
│                   REASONING PHASE                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. CONTEXT ASSESSMENT                                      │
│     ├─ What did the user ask?                               │
│     ├─ What do I already know? (working memory)             │
│     └─ What observations do I have from previous steps?     │
│                                                             │
│  2. GAP IDENTIFICATION                                      │
│     ├─ What information am I missing?                       │
│     ├─ What hasn't been done yet?                           │
│     └─ Are there any blockers?                              │
│                                                             │
│  3. TOOL EVALUATION                                         │
│     ├─ Which tools could help?                              │
│     ├─ Which is most efficient?                             │
│     └─ What parameters do I need?                           │
│                                                             │
│  4. DECISION                                                │
│     ├─ Choose ONE action                                    │
│     └─ OR provide final answer if complete                  │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Reasoning Trace Structure

A good reasoning trace includes:

1. **State summary**: "I have X, user wants Y"
2. **Gap analysis**: "I'm missing Z"
3. **Plan**: "I'll do A to get Z"
4. **Tool selection**: "Using tool T because..."

**Example Trace**:

```
Thought: User wants to add a CTA section to the services page.

Current state:
- I have the services page ID from earlier (page-789)
- I found the CTA section definition (cta-def-1)
- I haven't added the section yet

Gap: Need to actually add the section to the page.

Plan: Use addSectionToPage to add cta-def-1 to page-789.

Decision: Call addSectionToPage with pageId and sectionDefId.
```

## Reasoning Patterns

### Pattern 1: Goal Decomposition

Break complex goals into actionable steps.

**Prompt Enhancement**:

```typescript
const instructions = `When given a task:

1. Break it into specific, achievable steps
2. Identify what information you need for each step
3. Execute one step at a time
4. After each step, reassess remaining work

Example:
Task: "Create a landing page with hero and features"

Decomposition:
- Step 1: Create the page (need: slug, name)
- Step 2: Add hero section (need: page ID, hero definition)
- Step 3: Add features section (need: page ID, features definition)

Start with Step 1...`;
```

**Visual**:

```
Goal: "Create landing page with hero and features"
          │
          ▼
    ┌─────────────┐
    │ Decompose   │
    └─────────────┘
          │
    ┌─────┴─────┬─────────────┐
    ▼           ▼             ▼
┌───────┐  ┌───────────┐  ┌──────────┐
│Create │→ │Add Hero   │→ │Add       │
│Page   │  │Section    │  │Features  │
└───────┘  └───────────┘  └──────────┘
```

### Pattern 2: Information Gathering

Identify and fill knowledge gaps before acting.

**Prompt Enhancement**:

```typescript
const instructions = `Before taking action, always verify you have the required information:

REQUIRED INFORMATION CHECK:
- For page operations: Do I have the page ID?
- For section operations: Do I have section ID AND page ID?
- For updates: Do I know current values?

If missing information:
1. Identify what's missing
2. Search for or retrieve it
3. Only then proceed with the main action

DON'T guess IDs or assume context—always verify.`;
```

### Pattern 3: Alternative Evaluation

Consider multiple approaches before committing.

**Prompt Enhancement**:

```typescript
const instructions = `When multiple approaches exist, briefly evaluate:

APPROACH EVALUATION:
- Option A: [approach] → [pros/cons]
- Option B: [approach] → [pros/cons]
- Selected: [choice] because [reason]

Example:
Task: Find a page about our mission

Option A: Search by slug "mission"
  - Pro: Exact if exists
  - Con: Might not exist

Option B: Search pages for "mission" keyword
  - Pro: Finds fuzzy matches
  - Con: Might return multiple

Selected: Option A first (quick), fall back to Option B if not found.`;
```

### Pattern 4: Error Anticipation

Predict and prepare for potential failures.

**Prompt Enhancement**:

```typescript
const instructions = `For each action, consider what could go wrong:

ERROR ANTICIPATION:
- What if the resource doesn't exist?
- What if I get multiple matches?
- What if the operation fails?

Have a backup plan:
- Not found → Try alternative search
- Multiple matches → Pick best match or ask user
- Operation failed → Check error, retry or escalate

Never just fail—always try to recover.`;
```

## Tool Selection Strategies

### Strategy 1: Specificity Matching

Choose the most specific tool for the task.

```
User: "Get the about page"

Available tools:
- findResource(query, type) → General search
- getPage(id) → Direct fetch by ID
- getPageBySlug(slug) → Fetch by slug

Reasoning:
- I don't have the ID → Can't use getPage
- I might know the slug is "about" → Try getPageBySlug
- If that fails → Fall back to findResource

Decision: Start with getPageBySlug("about")
```

### Strategy 2: Efficiency Preference

Choose the approach that minimizes steps.

```
Task: "Add hero section to services page"

Approach A (2 steps):
1. getPage("services") to get ID
2. addSection(pageId, "hero")

Approach B (1 step):
1. addSectionBySlug(pageSlug: "services", sectionType: "hero")

If Approach B tool exists, use it.
Otherwise, use Approach A.
```

### Strategy 3: Token Efficiency

Consider response size when choosing tools.

```
Task: "What's the title of the about page?"

Option A: getPage(id) with includeContent: true
  → Returns ~2000 tokens (full content)

Option B: getPage(id) with includeContent: false
  → Returns ~200 tokens (metadata only)

Reasoning: I only need the title (metadata).
Decision: Use includeContent: false to save tokens.
```

## Framework Integration

### AI SDK 6: Reasoning via System Prompt

```typescript
import { ToolLoopAgent, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';

const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: `You are a careful, methodical assistant.

BEFORE EACH ACTION:
1. State what you're trying to accomplish
2. Identify what information you have/need
3. Explain why you're choosing this specific tool
4. Consider what could go wrong

EXAMPLE THOUGHT:
"User wants to update the hero section. I need the section ID.
I have the page slug 'about'. First I'll get the page to find
the hero section ID. Using getPage because I need section details."

After your thought, take ONE action.`,
  tools: { /* ... */ },
  stopWhen: stepCountIs(10),
});
```

### Structured Reasoning with prepareStep

```typescript
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  instructions: baseInstructions,
  tools: { /* ... */ },
  prepareStep: async ({ messages, context }) => {
    // Add reasoning template to each step
    const reasoningPrompt = `
Before your next action, think through:
- Current goal: ${context.currentGoal}
- Known information: ${context.workingMemory.summary()}
- Missing information: [identify gaps]
- Next action: [choose tool and explain why]
`;
    return {
      messages: [
        ...messages,
        { role: 'system', content: reasoningPrompt },
      ],
    };
  },
});
```

### Reasoning Extraction for Logging

```typescript
const agent = new ToolLoopAgent({
  model: openai('gpt-4o'),
  tools: { /* ... */ },
  onStepFinish: ({ step }) => {
    // Extract reasoning from model output
    const thought = extractThought(step.text);
    const action = step.toolCalls?.[0];

    // Log for debugging
    console.log({
      stepNumber: step.number,
      thought: thought,
      action: action?.toolName,
      input: action?.input,
    });

    // Store for observability
    traceStore.addStep({
      type: 'reasoning',
      content: thought,
      toolCall: action,
    });
  },
});

function extractThought(text: string): string | null {
  const match = text.match(/Thought:\s*(.+?)(?=Action:|$)/s);
  return match ? match[1].trim() : null;
}
```

## Common Reasoning Failures

### Failure 1: Skipping Context Check

**Symptom**: Agent uses wrong resource IDs

```
❌ BAD:
User: "Update the hero section"
Agent: updateSection("hero", {...})  // Assumed ID

✅ GOOD:
User: "Update the hero section"
Thought: I need to find which hero section the user means.
         Checking working memory... page-123 was most recent.
         I'll get its sections first.
Action: getPageSections(pageId: "page-123")
```

**Fix**: Always verify context before acting

### Failure 2: Not Updating Mental Model

**Symptom**: Agent repeats same failed action

```
❌ BAD:
Action: getPage(slug: "about")
Observation: Not found

Action: getPage(slug: "about")  // Same thing again!

✅ GOOD:
Action: getPage(slug: "about")
Observation: Not found

Thought: Exact slug "about" doesn't exist.
         Maybe it's "about-us" or similar.
         I'll do a fuzzy search instead.

Action: findResource(query: "about", type: "page")
```

**Fix**: Update reasoning based on observations

### Failure 3: Overthinking Simple Tasks

**Symptom**: Agent takes 10 steps for a 2-step task

```
❌ BAD:
Thought: I need to understand the full page structure...
Action: listAllPages()
Thought: Now I need to analyze which page is about...
Action: getPage(id: "page-1")
Action: getPage(id: "page-2")
...

✅ GOOD:
Thought: User wants the about page. I'll search for it directly.
Action: findResource(query: "about", type: "page")
```

**Fix**: Match reasoning depth to task complexity

### Failure 4: Not Knowing When to Stop

**Symptom**: Agent continues after task is complete

```
❌ BAD:
Observation: Page created successfully

Thought: Let me verify the page was created...
Action: getPage(id: "page-123")

Thought: Good, it exists. Let me verify again...
Action: getPage(id: "page-123")

✅ GOOD:
Observation: Page created successfully with ID page-123

Thought: Task complete. Page "Services" created successfully.
         I have all the information to confirm to the user.

Final Answer: Created the Services page (ID: page-123).
```

**Fix**: Include clear completion criteria in prompts

## Trade-offs & Considerations

### Token Cost of Reasoning

```
Without reasoning:
  Tool call: ~50 tokens
  Response: ~50 tokens
  Total: ~100 tokens/step

With reasoning:
  Thought: ~100-200 tokens
  Tool call: ~50 tokens
  Response: ~50 tokens
  Total: ~200-300 tokens/step

Trade-off: 2-3× more tokens for significantly better accuracy
```

### Reasoning Depth Guidelines

| Task Complexity | Reasoning Depth | Example |
| --------------- | --------------- | ------- |
| **Simple** | 1-2 sentences | "Need page ID, searching for about page" |
| **Medium** | 3-5 sentences | Full context, gap analysis, tool choice |
| **Complex** | Full paragraph | Alternative evaluation, error anticipation |

### When to Skip Reasoning

Some scenarios don't need explicit reasoning:

1. **Single obvious tool**: Only one tool matches the task
2. **Direct commands**: "List all pages" → just call listPages()
3. **Continuation**: Clearly following established pattern
4. **Simple queries**: "What's the page title?" → single lookup

### Performance Impact

| Reasoning Format | Accuracy | Latency | Token Cost |
| ---------------- | -------- | ------- | ---------- |
| **None (Direct)** | 60% | <1s | Low |
| **Freeform** | 75% | 2-5s | Medium |
| **Structured** | 85% | 5-10s | Higher |
| **Self-Ask** | 88% | 10-15s | Highest |

## Key Takeaways

1. **Think before acting**: Explicit reasoning improves accuracy 15-25%
2. **Check context first**: Verify you have required information
3. **Consider alternatives**: Evaluate multiple approaches when relevant
4. **Plan for errors**: Anticipate what could go wrong
5. **Match depth to task**: Don't overthink simple tasks

**Reasoning Checklist**:

- [ ] What is the user's actual goal?
- [ ] What information do I already have?
- [ ] What information am I missing?
- [ ] Which tool best fills this gap?
- [ ] What could go wrong?
- [ ] Am I done, or do I need more steps?

## References

1. **Yao et al.** (2022). "ReAct: Synergizing Reasoning and Acting in Language Models". https://arxiv.org/abs/2210.03629
2. **Wei et al.** (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models". https://arxiv.org/abs/2201.11903
3. **Press et al.** (2023). "Measuring and Narrowing the Compositionality Gap in Language Models". https://arxiv.org/abs/2210.03350
4. **AI SDK 6 Documentation** (2025). Vercel. https://v6.ai-sdk.dev/docs/foundations/agents

**Related Topics**:

- [3.2.1 ReAct Loop](./3.2.1-react-loop.md) - The full Think→Act→Observe cycle
- [3.2.3 Acting Phase](./3.2.3-acting-phase.md) - Tool execution details
- [3.2.4 Observation Phase](./3.2.4-observation-phase.md) - Interpreting results

**Layer Index**: [Layer 3: Agent Architecture](../AI_KNOWLEDGE_BASE_TOC.md#layer-3)
