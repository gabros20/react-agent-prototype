# 4.1.2 - Entity Extraction

## TL;DR

**Entity extraction transforms raw tool results into structured, minimal representations stored in working memory—extracting only IDs, labels, and key attributes instead of entire JSON blobs.** This reduces memory usage by 96%, enables fast reference resolution, and provides clean context for the LLM.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-11
- **Prerequisites**: [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- **Grounded In**: PARSE (Amazon, 2025), Mem0 (2025), GPT-NER (2025)

## Overview

When AI agents execute tools, they receive rich data—full page content, nested metadata, timestamps, analytics. Storing all of this in working memory is wasteful and pollutes LLM context. Entity extraction solves this by identifying and preserving only the information needed for reference resolution and task continuity.

The field has evolved from rule-based pattern matching to sophisticated LLM-assisted extraction that can handle unstructured text and novel entity types.

**Key Research Findings (2024-2025)**:

- **PARSE (Amazon)**: 64.7% accuracy on SWDE dataset using schema-optimized extraction
- **Mem0**: 26% accuracy boost with entity-based memory vs raw storage
- **GPT-NER**: First time LLMs match supervised NER baselines without fine-tuning
- **Memory savings**: 96% reduction (200 bytes vs 5KB per entity)

## The Problem: Burying Information

### The Classic Challenge

Tool results contain far more data than working memory needs:

```
Tool: cms_getPage(42)
Result: {
  id: 42,
  title: "Home Page",
  slug: "home",
  status: "published",
  content: "<p>Welcome to our website...</p>",  // 4KB HTML
  metadata: { seo: {...}, analytics: {...} },   // 2KB JSON
  tags: ["homepage", "featured"],
  categories: [...],
  // ... 50 more fields
}
Total: ~5KB per page
```

**Problems**:

- ❌ **5KB per entity** → 20 entities = 100KB in memory
- ❌ **Token explosion** → Costs $0.15/1M tokens for context
- ❌ **Slow retrieval** → Must parse 100KB to find "pageId: 42"
- ❌ **Context pollution** → LLM sees irrelevant metadata

### Why This Matters

Working memory should be fast and focused. Storing full tool results defeats both purposes:
- Reference resolution becomes expensive (JSON parsing)
- LLM context fills with irrelevant data
- Memory limits hit faster, forcing eviction of useful entities

## Core Concept

### What is Entity Extraction?

Entity extraction identifies and extracts key information elements from tool results into a standardized structure containing:

| Field | Purpose | Example |
|-------|---------|---------|
| **type** | Entity category | 'page', 'entry', 'user' |
| **id** | Unique identifier | 42 |
| **label** | Human-readable name | "Home Page" |
| **attributes** | Key properties | { slug: 'home', status: 'published' } |
| **timestamp** | When extracted | 1731937200000 |

### Extraction Flow

```
┌────────────────────────────────────────────────────────────┐
│                   ENTITY EXTRACTION                         │
├────────────────────────────────────────────────────────────┤
│                                                             │
│  Tool Result (5KB)                                          │
│  { id: 42, title: "Home", content: "...", metadata: {...} } │
│                     ↓                                       │
│             ┌─────────────┐                                 │
│             │  Extractor  │                                 │
│             │  (Rule/LLM) │                                 │
│             └──────┬──────┘                                 │
│                    ↓                                        │
│  Entity (200 bytes)                                         │
│  { type: 'page', id: 42, label: 'Home', attrs: {...} }      │
│                    ↓                                        │
│  Working Memory                                             │
│  [page:42] [entry:7] [user:123]                             │
│                                                             │
└────────────────────────────────────────────────────────────┘
```

### What to Extract vs Ignore

| Extract ✅ | Ignore ❌ |
|------------|-----------|
| Unique identifiers (id, slug) | Full content (HTML, markdown) |
| Display names (title, name) | Timestamps (createdAt, updatedAt) |
| Status indicators (published, draft) | Analytics data (views, clicks) |
| Type discriminators (page, post) | Nested metadata objects |
| Current state (active, completed) | Historical data |

## Implementation Patterns

### Pattern 1: Rule-Based Extraction (Fastest)

**Use Case**: Known tool schemas, structured JSON responses

Define extraction rules for each tool type:

```typescript
function extractFromPage(result: PageResult): Entity {
  return {
    type: 'page',
    id: result.id,
    label: result.title,
    attributes: {
      slug: result.slug,
      status: result.status,
    },
    timestamp: Date.now(),
  };
}
```

**Pros**:
- ✅ Zero latency (no LLM calls)
- ✅ Zero cost
- ✅ Predictable, deterministic

**Cons**:
- ❌ Requires rule per tool type
- ❌ Breaks if schema changes
- ❌ Can't handle unstructured text

**When to Use**: Production systems with stable tool schemas, high-volume extraction

### Pattern 2: Schema-Based LLM Extraction (PARSE)

**Use Case**: Dynamic schemas, unstructured text, novel entity types

Use JSON schemas to guide LLM extraction:

```typescript
const EntitySchema = z.object({
  type: z.enum(['page', 'entry', 'user']),
  id: z.number(),
  label: z.string(),
  attributes: z.record(z.unknown()).optional(),
});

async function extractWithLLM(result: unknown): Promise<Entity> {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: EntitySchema,
    prompt: `Extract entity from: ${JSON.stringify(result)}`,
  });
  return { ...object, timestamp: Date.now() };
}
```

**Pros**:
- ✅ Handles schema changes automatically
- ✅ Works with unstructured text
- ✅ Can discover novel entity types

**Cons**:
- ❌ 50-100ms latency per extraction
- ❌ Token costs (~$0.001 per extraction)
- ❌ May hallucinate if schema ambiguous

**PARSE Results (Amazon, 2025)**:
- 64.7% accuracy on SWDE dataset (vs 40% baseline)
- ARCHITECT component optimizes schemas automatically
- SCOPE component adds reflection-based guardrails

### Pattern 3: Hybrid (Production Best Practice)

**Use Case**: Production systems balancing speed, cost, and flexibility

Try rules first, fall back to LLM when rules fail:

```
┌─────────────────────────────────────────────────────────────┐
│                    HYBRID EXTRACTION                         │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Tool Result                                                 │
│       ↓                                                      │
│  ┌─────────────────┐                                        │
│  │   Rule-Based    │ ← Fast path (0.2ms, free)              │
│  │   Extractor     │                                        │
│  └────────┬────────┘                                        │
│           │                                                  │
│       Success?                                               │
│      ↙        ↘                                             │
│    Yes         No                                            │
│     ↓           ↓                                            │
│  Entity   ┌─────────────────┐                               │
│           │   LLM-Based     │ ← Slow path (100ms, $0.001)   │
│           │   Extractor     │                               │
│           └────────┬────────┘                               │
│                    ↓                                         │
│                 Entity                                       │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

**Pros**:
- ✅ Fast path for common cases (99% of extractions)
- ✅ Handles edge cases with LLM
- ✅ Cost-efficient

**Cons**:
- ❌ More complex implementation
- ❌ Must maintain both extractors

**When to Use**: Any production system

## Framework Integration

### AI SDK v6 with Automatic Extraction

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

interface Entity {
  type: string;
  id: number | string;
  label?: string;
  attributes?: Record<string, unknown>;
  timestamp: number;
}

// Create tool with built-in extraction
function createExtractingTool<T, R>(config: {
  name: string;
  description: string;
  inputSchema: z.ZodType<T>;
  execute: (input: T) => Promise<R>;
  extract: (result: R) => Entity | null;
}) {
  return tool({
    description: config.description,
    inputSchema: config.inputSchema,
    execute: async (input, { experimental_context }) => {
      const ctx = experimental_context as AgentContext;
      const result = await config.execute(input);

      // Automatic extraction
      const entity = config.extract(result);
      if (entity) {
        ctx.memory.add(entity);
      }

      return result;
    },
  });
}

// Usage
const getPage = createExtractingTool({
  name: 'getPage',
  description: 'Get a page by ID',
  inputSchema: z.object({ pageId: z.number() }),
  execute: async ({ pageId }) => db.pages.findUnique({ where: { id: pageId } }),
  extract: (page) => ({
    type: 'page',
    id: page.id,
    label: page.title,
    attributes: { slug: page.slug, status: page.status },
    timestamp: Date.now(),
  }),
});

const result = await generateText({
  model: openai('gpt-4o'),
  tools: { getPage },
  stopWhen: stepCountIs(10),
  experimental_context: { memory: workingMemory },
  prompt: 'Show me page 42',
});
```

### Mem0-Style Two-Phase Extraction

```typescript
class EntityExtractor {
  private ruleExtractors: Map<string, (result: unknown) => Entity | null>;
  private llm: LLMClient;

  constructor(llm: LLMClient) {
    this.llm = llm;
    this.ruleExtractors = new Map([
      ['cms_getPage', this.extractPage],
      ['cms_getEntry', this.extractEntry],
      ['cms_listPages', this.extractPageList],
    ]);
  }

  async extract(toolName: string, result: unknown): Promise<Entity[]> {
    // Phase 1: Rule-based extraction
    const ruleExtractor = this.ruleExtractors.get(toolName);
    if (ruleExtractor) {
      const entity = ruleExtractor(result);
      if (entity) return [entity];
    }

    // Phase 2: LLM-based extraction (fallback)
    return this.llmExtract(toolName, result);
  }

  private extractPage(result: unknown): Entity | null {
    const page = result as { id: number; title: string; slug: string; status: string };
    return {
      type: 'page',
      id: page.id,
      label: page.title,
      attributes: { slug: page.slug, status: page.status },
      timestamp: Date.now(),
    };
  }

  private async llmExtract(toolName: string, result: unknown): Promise<Entity[]> {
    const { object } = await generateObject({
      model: this.llm,
      schema: z.array(EntitySchema),
      prompt: `Extract entities from ${toolName} result: ${JSON.stringify(result)}`,
    });
    return object.map(e => ({ ...e, timestamp: Date.now() }));
  }
}
```

## Research & Benchmarks

### PARSE (Amazon, 2025)

**Paper**: "PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction"

| Metric | Baseline | With PARSE | Improvement |
|--------|----------|------------|-------------|
| **SWDE Accuracy** | 40.0% | 64.7% | **+62%** |
| **Hallucination Rate** | 15% | 7% | **-53%** |
| **Schema Compatibility** | Manual | Automatic | N/A |

**Key Components**:
- **ARCHITECT**: Optimizes JSON schemas for extraction
- **SCOPE**: Reflection-based extraction with guardrails

### Mem0 Entity Extraction (2025)

Two-phase pipeline: Extract → Update → Retrieve

| Phase | Purpose | Method |
|-------|---------|--------|
| **Extract** | Identify entities from conversation | LLM with few-shot examples |
| **Update** | Merge with existing memories | ADD/UPDATE/DELETE/NOOP |
| **Retrieve** | Find relevant entities | Vector similarity + recency |

**Performance**: 26% accuracy improvement over storing raw results

### Memory Efficiency Comparison

| Approach | Size per Entity | 20 Entities | Token Cost |
|----------|-----------------|-------------|------------|
| Raw JSON | 5KB | 100KB | $0.015 |
| Extracted Entity | 200 bytes | 4KB | $0.0006 |
| **Savings** | **96%** | **96%** | **96%** |

## When to Use This Pattern

### ✅ Use Entity Extraction When:

1. **Tool results are large** (>500 bytes)
   - Page content, nested metadata
   - Reduces memory footprint by 90%+

2. **Reference resolution needed**
   - "this page", "that entry"
   - Fast entity lookup required

3. **Context efficiency matters**
   - High token costs
   - Limited context window

4. **Multiple tools return same entity type**
   - Consistent entity format across tools
   - Easier working memory management

### ❌ Don't Use When:

1. **Results already minimal**
   - Simple ID/name pairs
   - Extraction overhead not worth it

2. **Full data needed later**
   - Audit trails, compliance
   - Store raw results separately

3. **One-shot queries**
   - No subsequent references
   - Entity won't be reused

### Decision Matrix

| Tool Result Size | Reference Frequency | Recommendation |
|------------------|---------------------|----------------|
| <500 bytes | Any | Store raw |
| >500 bytes | Low | Store raw + optional extraction |
| >500 bytes | High | Extract entities |
| Any | Audit required | Store raw + extract |

## Production Best Practices

### 1. Define Entity Schemas Per Domain

```typescript
// CMS domain entities
const CMSEntityTypes = {
  page: z.object({
    type: z.literal('page'),
    id: z.number(),
    label: z.string(),
    attributes: z.object({
      slug: z.string(),
      status: z.enum(['draft', 'published', 'archived']),
    }),
  }),
  entry: z.object({
    type: z.literal('entry'),
    id: z.number(),
    label: z.string(),
    attributes: z.object({ status: z.string() }),
  }),
};
```

### 2. Handle Extraction Failures Gracefully

```typescript
async function safeExtract(toolName: string, result: unknown): Promise<Entity | null> {
  try {
    return await extractor.extract(toolName, result);
  } catch (error) {
    console.warn(`Extraction failed for ${toolName}:`, error);
    // Return null, don't crash agent
    return null;
  }
}
```

### 3. Track Extraction Metrics

| Metric | Target | Alert |
|--------|--------|-------|
| Rule extraction success rate | >95% | <90% |
| LLM fallback rate | <5% | >10% |
| Average extraction latency | <10ms | >50ms |
| Extraction cost per session | <$0.01 | >$0.05 |

### 4. Batch Extraction for List Results

```typescript
// When tool returns multiple items
const listPages = tool({
  description: 'List pages',
  inputSchema: z.object({}),
  execute: async (_, { experimental_context }) => {
    const ctx = experimental_context as AgentContext;
    const pages = await db.pages.findMany({ take: 10 });

    // Batch extract all entities
    for (const page of pages) {
      ctx.memory.add({
        type: 'page',
        id: page.id,
        label: page.title,
        attributes: { slug: page.slug, status: page.status },
        timestamp: Date.now(),
      });
    }

    return pages;
  },
});
```

## Key Takeaways

1. **Extract, don't store raw** - 200 bytes vs 5KB per entity (96% savings)
2. **Rule-based first** - Fast path for 99% of extractions, LLM fallback for edge cases
3. **Standardize entity structure** - type, id, label, attributes, timestamp
4. **Integrate with tools** - Automatic extraction on every tool execution
5. **Track metrics** - Monitor extraction success rate and LLM fallback usage

**Quick Implementation Checklist**:

- [ ] Define entity schemas for your domain
- [ ] Create rule-based extractors for known tool types
- [ ] Add LLM fallback for unknown/complex results
- [ ] Integrate extraction into tool execution pipeline
- [ ] Monitor extraction success rate and costs
- [ ] Handle extraction failures gracefully

## References

1. **Amazon Research** (2025). "PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction". arXiv. https://arxiv.org/abs/2510.08623
2. **Mem0 Team** (2025). "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory". arXiv. https://arxiv.org/abs/2504.19413
3. **GPT-NER** (2025). "Named Entity Recognition via Large Language Models". ACL Findings. https://aclanthology.org/2025.findings-naacl.239
4. **CascadeNER** (2024). "Named Entity Recognition via LLMs". arXiv. https://arxiv.org/abs/2409.11022
5. **Vercel AI SDK** (2025). "Generating Structured Data". https://v6.ai-sdk.dev/docs/ai-sdk-core/generating-structured-data
6. **OpenAI** (2024). "Structured Outputs". https://platform.openai.com/docs/guides/structured-outputs

**Related Topics**:

- [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- [4.1.3 Sliding Window Management](./4.1.3-sliding-window.md)
- [4.1.4 Reference Resolution](./4.1.4-reference-resolution.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
