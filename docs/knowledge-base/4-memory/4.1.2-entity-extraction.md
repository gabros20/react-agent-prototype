# 4.1.2 Entity Extraction from Tool Results

**Status**: ✅ Complete  
**Last Updated**: 2025-11-18  
**Grounded In**: PARSE (Amazon, 2025), Mem0 (2025), GPT-NER (2025), production frameworks

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [The Problem: Burying Information](#the-problem-burying-information)
3. [What is Entity Extraction?](#what-is-entity-extraction)
4. [Why Extract Entities from Tool Results?](#why-extract-entities-from-tool-results)
5. [Extraction Techniques](#extraction-techniques)
6. [Implementation in JavaScript/TypeScript](#implementation-in-javascripttypescript)
7. [Schema Design for Structured Extraction](#schema-design-for-structured-extraction)
8. [Production Patterns](#production-patterns)
9. [When to Extract vs Store Raw Results](#when-to-extract-vs-store-raw-results)
10. [References](#references)

---

## Executive Summary

**Entity extraction** is the process of identifying and extracting key information (entities) from unstructured text—like tool results, API responses, or conversation messages. In AI agents, this enables **working memory** to store only what matters, not raw JSON blobs.

### Key Metrics (Industry Benchmarks, 2025)
- **PARSE (Amazon)**: 64.7% accuracy improvement on SWDE dataset
- **Mem0**: 26% accuracy boost with entity-based memory
- **GPT-NER**: First time LLMs match supervised NER baselines

### Why It Matters
- **Memory Efficiency**: Store 10-20 entities instead of 10KB tool results
- **Fast Reference Resolution**: "this page" → pageId lookup in 0.2ms
- **Better Context**: LLM sees "pageId: 42, title: Home" vs raw JSON
- **Cost Reduction**: 90% fewer tokens in working memory

---

## The Problem: Burying Information

### Scenario: CMS Agent Gets Page Data

```typescript
// Tool call
const result = await cms_getPage(42, { includeContent: true });

// Raw tool result (5KB JSON)
{
  "id": 42,
  "title": "Home Page",
  "slug": "home",
  "status": "published",
  "type": "page",
  "createdAt": "2023-01-15T10:30:00Z",
  "updatedAt": "2025-11-18T14:22:00Z",
  "content": "<p>Welcome to our website...</p>",  // 4KB of HTML
  "metadata": {
    "seo": { "title": "...", "description": "..." },
    "analytics": { "views": 12543, "lastViewed": "..." }
  },
  "tags": ["homepage", "featured"],
  "categories": [{ "id": 1, "name": "Marketing" }],
  // ... 50 more fields
}
```

**Problem**: If we add this **entire object** to working memory:
- ❌ **5KB per page** → 20 pages = 100KB in memory
- ❌ **Token explosion** → Costs $0.15/1M tokens (GPT-4o-mini)
- ❌ **Slow retrieval** → Agent must parse 100KB JSON to find "pageId: 42"
- ❌ **Context pollution** → LLM sees irrelevant metadata, analytics, timestamps

### Solution: Extract Only What Matters

```typescript
// ✅ GOOD: Extract entities (200 bytes)
{
  type: 'page',
  id: 42,
  label: 'Home Page',
  attributes: {
    slug: 'home',
    status: 'published',
    type: 'page'
  },
  timestamp: 1731937200000
}
```

**Result**:
- ✅ **200 bytes** vs 5KB (96% reduction)
- ✅ **Fast lookup**: `memory.get('page', 42)` in 0.2ms
- ✅ **Clean context**: LLM sees "pageId: 42, title: Home" only
- ✅ **Scalable**: 20 entities = 4KB (vs 100KB raw)

---

## What is Entity Extraction?

### Definition

**Entity extraction** (also called Named Entity Recognition or NER) is the process of identifying and classifying key information elements from text into predefined categories like:

- **Person** ("John Doe")
- **Location** ("San Francisco")
- **Organization** ("Acme Corp")
- **Date** ("2025-11-18")
- **Custom Entities** ("Page", "Entry", "Task")

### Entity Structure

```typescript
interface Entity {
  type: string;          // 'page' | 'entry' | 'user' | 'task'
  id: number | string;   // Unique identifier
  label?: string;        // Human-readable name
  attributes?: Record<string, unknown>;  // Optional metadata
  timestamp: number;     // When extracted (for eviction)
}
```

### Example: From Tool Result → Entity

```typescript
// Tool result
const pageResult = {
  id: 42,
  title: "Getting Started",
  slug: "getting-started",
  status: "published",
  content: "<h1>Welcome...</h1>", // 4KB
  metadata: { ... }  // 2KB
};

// Extracted entity
const pageEntity: Entity = {
  type: 'page',
  id: 42,
  label: 'Getting Started',
  attributes: {
    slug: 'getting-started',
    status: 'published'
  },
  timestamp: Date.now()
};
```

---

## Why Extract Entities from Tool Results?

### 1. Memory Efficiency

**Raw storage** grows unbounded; **entity storage** is fixed-size.

```typescript
// ❌ BAD: Store all tool results
const toolResults: string[] = [];
toolResults.push(JSON.stringify(page1)); // 5KB
toolResults.push(JSON.stringify(page2)); // 5KB
toolResults.push(JSON.stringify(page3)); // 5KB
// ... after 20 calls → 100KB in memory

// ✅ GOOD: Store extracted entities
const entities: Entity[] = [];
entities.push({ type: 'page', id: 1, label: 'Home' });       // 200 bytes
entities.push({ type: 'page', id: 2, label: 'About' });      // 200 bytes
entities.push({ type: 'page', id: 3, label: 'Contact' });    // 200 bytes
// ... after 20 calls → 4KB in memory (96% reduction)
```

### 2. Fast Reference Resolution

```typescript
// User: "Update this page's title"
// Agent needs to resolve "this page" → pageId

// ❌ SLOW: Parse all tool results
const lastPage = JSON.parse(toolResults[toolResults.length - 1]);
const pageId = lastPage.id;  // Requires JSON parsing

// ✅ FAST: Lookup entity
const lastPage = workingMemory.getRecent(1)[0];
const pageId = lastPage.id;  // Direct property access (0.2ms)
```

### 3. Better LLM Context

**Raw JSON** is noisy; **extracted entities** are clean.

```typescript
// ❌ BAD: LLM sees entire tool result
const context = `
Tool result: ${JSON.stringify(page, null, 2)}
`;
// LLM must parse 5KB JSON to find pageId

// ✅ GOOD: LLM sees entity summary
const context = `
Working Memory:
- Page 42 "Home" (published)
- Page 57 "About" (draft)
- Entry 123 "Welcome Post"
`;
// LLM immediately understands context
```

### 4. Pronoun Resolution

```typescript
// User: "Show me page 42"
// Agent calls cms_getPage(42)
// Extract: { type: 'page', id: 42, label: 'Home' }

// User: "Update this page's title to 'Welcome'"
//       ^^^^^^^^^ resolves to pageId: 42 from working memory
```

---

## Extraction Techniques

### 1. Rule-Based Extraction (Simplest)

**Manually define rules** for each entity type.

```typescript
function extractEntityFromToolResult(
  toolName: string,
  result: unknown
): Entity | null {
  if (toolName === 'cms_getPage' && typeof result === 'object' && result !== null) {
    const page = result as { id: number; title: string; slug: string; status: string };
    return {
      type: 'page',
      id: page.id,
      label: page.title,
      attributes: {
        slug: page.slug,
        status: page.status
      },
      timestamp: Date.now()
    };
  }

  if (toolName === 'cms_getEntry' && typeof result === 'object' && result !== null) {
    const entry = result as { id: number; title: string };
    return {
      type: 'entry',
      id: entry.id,
      label: entry.title,
      timestamp: Date.now()
    };
  }

  return null;
}
```

**Pros**:
- ✅ Simple and fast
- ✅ Predictable results
- ✅ No LLM calls (zero cost)

**Cons**:
- ❌ Requires manual rules for each tool
- ❌ Brittle (breaks if tool result schema changes)
- ❌ Can't handle unstructured text

### 2. Schema-Based Extraction (PARSE, Amazon 2025)

**Define JSON schema** for LLM to extract structured data.

```typescript
import { z } from 'zod';

// Define entity schema
const PageEntitySchema = z.object({
  type: z.literal('page'),
  id: z.number(),
  label: z.string(),
  attributes: z.object({
    slug: z.string(),
    status: z.enum(['draft', 'published', 'archived'])
  })
});

// Extract using LLM
async function extractEntityWithSchema(
  toolResult: unknown
): Promise<Entity> {
  const prompt = `
Extract page entity from this tool result:
${JSON.stringify(toolResult, null, 2)}

Return JSON matching this schema:
{
  "type": "page",
  "id": <number>,
  "label": <string>,
  "attributes": { "slug": <string>, "status": <enum> }
}
  `.trim();

  const response = await llm.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' }
  });

  const json = JSON.parse(response.choices[0].message.content || '{}');
  return PageEntitySchema.parse(json);  // Validates against schema
}
```

**Pros**:
- ✅ Handles schema changes automatically
- ✅ Works with unstructured text (if LLM extracts correctly)
- ✅ Type-safe with Zod validation

**Cons**:
- ❌ Requires LLM call (~50-100ms latency)
- ❌ Costs tokens ($0.15/1M input tokens)
- ❌ May hallucinate if schema is ambiguous

**PARSE Results** (Amazon, 2025):
- **64.7% accuracy** on SWDE dataset (vs 40% baseline)
- **Optimizes schemas** automatically using ARCHITECT component
- **Reduces hallucinations** with SCOPE reflection-based extraction

### 3. LLM Function Calling (OpenAI, Anthropic, Gemini)

**Use structured outputs** with function calling.

```typescript
import { openai } from '@ai-sdk/openai';
import { generateText, tool } from 'ai';
import { z } from 'zod';

// Define extraction tool
const extractPageEntityTool = tool({
  description: 'Extract page entity from tool result',
  parameters: z.object({
    toolResult: z.string()
  }),
  execute: async ({ toolResult }) => {
    // Parse tool result
    const result = JSON.parse(toolResult);
    
    // Extract entity
    return {
      type: 'page',
      id: result.id,
      label: result.title,
      attributes: {
        slug: result.slug,
        status: result.status
      }
    };
  }
});

// Use in agent
const result = await generateText({
  model: openai('gpt-4o-mini'),
  tools: { extractPageEntity: extractPageEntityTool },
  prompt: `
Extract page entity from this tool result:
${JSON.stringify(pageResult, null, 2)}
  `
});
```

**Pros**:
- ✅ Leverages native LLM capabilities
- ✅ High accuracy with good schemas
- ✅ Handles edge cases gracefully

**Cons**:
- ❌ Slower than rule-based (50-200ms)
- ❌ Costs tokens
- ❌ Overkill for simple extractions

### 4. Hybrid: Rules + LLM Fallback (Production Best Practice)

**Try rules first**, fallback to LLM if rules fail.

```typescript
async function extractEntity(
  toolName: string,
  toolResult: unknown
): Promise<Entity | null> {
  // Try rule-based first (fast, free)
  const entity = extractEntityFromToolResult(toolName, toolResult);
  if (entity) {
    return entity;
  }

  // Fallback to LLM (slow, costs tokens)
  try {
    return await extractEntityWithLLM(toolName, toolResult);
  } catch (error) {
    console.error('Entity extraction failed:', error);
    return null;
  }
}
```

**Pros**:
- ✅ Fast path for common cases
- ✅ Handles edge cases with LLM
- ✅ Cost-efficient (only pays for LLM when needed)

**Cons**:
- ❌ More complex to implement
- ❌ Requires maintaining both rules and LLM logic

---

## Implementation in JavaScript/TypeScript

### Basic Entity Extractor

```typescript
// entity-extractor.ts
export interface Entity {
  type: string;
  id: number | string;
  label?: string;
  attributes?: Record<string, unknown>;
  timestamp: number;
}

export interface ToolResult {
  toolName: string;
  result: unknown;
}

export class EntityExtractor {
  // Rule-based extraction map
  private extractors = new Map<string, (result: unknown) => Entity | null>([
    ['cms_getPage', this.extractPage.bind(this)],
    ['cms_getEntry', this.extractEntry.bind(this)],
    ['cms_getUser', this.extractUser.bind(this)],
  ]);

  extract(toolResult: ToolResult): Entity | null {
    const extractor = this.extractors.get(toolResult.toolName);
    if (!extractor) {
      return null;
    }
    return extractor(toolResult.result);
  }

  private extractPage(result: unknown): Entity | null {
    if (typeof result !== 'object' || result === null) {
      return null;
    }

    const page = result as Record<string, unknown>;
    
    // Validate required fields
    if (typeof page.id !== 'number' || typeof page.title !== 'string') {
      return null;
    }

    return {
      type: 'page',
      id: page.id,
      label: page.title,
      attributes: {
        slug: page.slug ?? '',
        status: page.status ?? 'unknown',
        type: page.type ?? 'page'
      },
      timestamp: Date.now()
    };
  }

  private extractEntry(result: unknown): Entity | null {
    if (typeof result !== 'object' || result === null) {
      return null;
    }

    const entry = result as Record<string, unknown>;
    
    if (typeof entry.id !== 'number' || typeof entry.title !== 'string') {
      return null;
    }

    return {
      type: 'entry',
      id: entry.id,
      label: entry.title,
      attributes: {
        status: entry.status ?? 'unknown'
      },
      timestamp: Date.now()
    };
  }

  private extractUser(result: unknown): Entity | null {
    if (typeof result !== 'object' || result === null) {
      return null;
    }

    const user = result as Record<string, unknown>;
    
    if (typeof user.id !== 'number' || typeof user.name !== 'string') {
      return null;
    }

    return {
      type: 'user',
      id: user.id,
      label: user.name,
      attributes: {
        email: user.email ?? ''
      },
      timestamp: Date.now()
    };
  }
}
```

### Integration with Working Memory

```typescript
// agent-context.ts
import { WorkingMemory } from './working-memory';
import { EntityExtractor, type ToolResult } from './entity-extractor';

export interface AgentContext {
  workingMemory: WorkingMemory;
  entityExtractor: EntityExtractor;
  userId: string;
  sessionId: string;
}

// Tool wrapper with automatic extraction
export async function executeTool(
  toolName: string,
  params: unknown,
  context: AgentContext
): Promise<unknown> {
  // Execute tool
  const result = await tools[toolName](params, context);

  // Extract entity
  const entity = context.entityExtractor.extract({
    toolName,
    result
  });

  // Add to working memory
  if (entity) {
    context.workingMemory.add(entity);
  }

  return result;
}
```

### LLM-Based Extractor (Fallback)

```typescript
import { openai } from '@ai-sdk/openai';
import { generateObject } from 'ai';
import { z } from 'zod';

const EntitySchema = z.object({
  type: z.string(),
  id: z.union([z.number(), z.string()]),
  label: z.string().optional(),
  attributes: z.record(z.unknown()).optional()
});

export class LLMEntityExtractor {
  async extract(toolName: string, toolResult: unknown): Promise<Entity | null> {
    try {
      const { object } = await generateObject({
        model: openai('gpt-4o-mini'),
        schema: EntitySchema,
        prompt: `
Extract the main entity from this ${toolName} tool result:
${JSON.stringify(toolResult, null, 2)}

Focus on:
- Type: 'page', 'entry', 'user', etc.
- ID: Unique identifier
- Label: Human-readable name
- Attributes: Key properties (status, slug, etc.)
        `.trim()
      });

      return {
        ...object,
        timestamp: Date.now()
      };
    } catch (error) {
      console.error('LLM extraction failed:', error);
      return null;
    }
  }
}
```

---

## Schema Design for Structured Extraction

### PARSE Principles (Amazon, 2025)

**Good schemas** have these properties:

1. **Unambiguous field names**
   ```typescript
   // ❌ BAD: Ambiguous
   { name: string }  // What kind of name? User? Page?

   // ✅ GOOD: Specific
   { pageTitle: string }
   ```

2. **Clear type constraints**
   ```typescript
   // ❌ BAD: Loose
   { status: string }  // Any string? What values?

   // ✅ GOOD: Enum
   { status: 'draft' | 'published' | 'archived' }
   ```

3. **Required vs optional**
   ```typescript
   // ❌ BAD: Everything optional
   { id?: number; title?: string }

   // ✅ GOOD: Required fields marked
   { id: number; title: string; slug?: string }
   ```

4. **Descriptive field names**
   ```typescript
   // ❌ BAD: Cryptic
   { pg: number; tl: string }

   // ✅ GOOD: Descriptive
   { pageId: number; title: string }
   ```

### Example: Optimized Entity Schema

```typescript
import { z } from 'zod';

// Page entity schema
export const PageEntitySchema = z.object({
  type: z.literal('page').describe('Entity type (always "page")'),
  id: z.number().int().positive().describe('Unique page ID from database'),
  label: z.string().min(1).describe('Page title for display'),
  attributes: z.object({
    slug: z.string().regex(/^[a-z0-9-]+$/).describe('URL slug (lowercase, hyphens)'),
    status: z.enum(['draft', 'published', 'archived']).describe('Publication status'),
    pageType: z.enum(['page', 'post', 'landing']).optional().describe('Page type')
  }).describe('Key page properties')
});

// Generate TypeScript type from schema
export type PageEntity = z.infer<typeof PageEntitySchema>;
```

### PARSE ARCHITECT Optimization

```typescript
// Automatic schema optimization (conceptual example)
function optimizeSchema(schema: z.ZodObject): z.ZodObject {
  // 1. Add descriptions to all fields
  // 2. Make constraints explicit (min, max, regex)
  // 3. Replace unions with enums where possible
  // 4. Add backward compatibility transformations
  
  return schema;
}
```

**PARSE Results**:
- **64.7% extraction accuracy** on SWDE (vs 40% baseline)
- **Reduces hallucinations** by 50%
- **Maintains backward compatibility** with existing schemas

---

## Production Patterns

### Pattern 1: Automatic Extraction in Tool Middleware

```typescript
import { tool } from 'ai';
import { z } from 'zod';

function createToolWithExtraction<P extends z.ZodType, R>(
  definition: {
    description: string;
    parameters: P;
    execute: (params: z.infer<P>, context: AgentContext) => Promise<R>;
    extractEntity?: (result: R) => Entity | null;
  }
) {
  return tool({
    description: definition.description,
    parameters: definition.parameters,
    execute: async (params, context) => {
      // Execute tool
      const result = await definition.execute(params, context);

      // Extract entity if extractor provided
      if (definition.extractEntity) {
        const entity = definition.extractEntity(result);
        if (entity) {
          context.workingMemory.add(entity);
        }
      }

      return result;
    }
  });
}

// Usage
const cms_getPage = createToolWithExtraction({
  description: 'Get page by ID',
  parameters: z.object({ pageId: z.number() }),
  execute: async ({ pageId }, context) => {
    return await db.pages.findUnique({ where: { id: pageId } });
  },
  extractEntity: (page) => ({
    type: 'page',
    id: page.id,
    label: page.title,
    attributes: { slug: page.slug, status: page.status },
    timestamp: Date.now()
  })
});
```

### Pattern 2: Batch Extraction for List Results

```typescript
// Tool that returns multiple items
const cms_listPages = tool({
  description: 'List all pages',
  parameters: z.object({}),
  execute: async (_, context) => {
    const pages = await db.pages.findMany({ take: 10 });

    // Extract entity for each page
    for (const page of pages) {
      context.workingMemory.add({
        type: 'page',
        id: page.id,
        label: page.title,
        attributes: { slug: page.slug, status: page.status },
        timestamp: Date.now()
      });
    }

    return pages;
  }
});
```

### Pattern 3: Mem0-Style Extraction Pipeline

```typescript
class Mem0Extractor {
  async extract(
    userMessage: string,
    assistantResponse: string,
    toolResults: ToolResult[]
  ): Promise<Entity[]> {
    const entities: Entity[] = [];

    // Extract from each tool result
    for (const toolResult of toolResults) {
      const entity = await this.extractFromToolResult(toolResult);
      if (entity) {
        entities.push(entity);
      }
    }

    // Extract from conversation (optional)
    const conversationEntities = await this.extractFromConversation(
      userMessage,
      assistantResponse
    );
    entities.push(...conversationEntities);

    return entities;
  }

  private async extractFromToolResult(toolResult: ToolResult): Promise<Entity | null> {
    // Rule-based extraction first
    const entity = this.ruleBasedExtract(toolResult);
    if (entity) {
      return entity;
    }

    // Fallback to LLM
    return await this.llmBasedExtract(toolResult);
  }

  private async extractFromConversation(
    user: string,
    assistant: string
  ): Promise<Entity[]> {
    // Use LLM to extract facts from conversation
    const prompt = `
Extract key entities mentioned in this exchange:
User: ${user}
Assistant: ${assistant}

Return JSON array of entities:
[{ "type": "page", "id": 42, "label": "Home" }]
    `.trim();

    const response = await llm.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      response_format: { type: 'json_object' }
    });

    const result = JSON.parse(response.choices[0].message.content || '[]');
    return result.map(e => ({ ...e, timestamp: Date.now() }));
  }
}
```

---

## When to Extract vs Store Raw Results

### Decision Matrix

| Scenario | Extract Entities | Store Raw Results |
|----------|------------------|-------------------|
| **Small result** (<500 bytes) | ❌ Not worth it | ✅ Store raw |
| **Large result** (>5KB) | ✅ Extract key info | ❌ Too big |
| **Frequently referenced** | ✅ Extract for fast lookup | ❌ Raw parsing slow |
| **Complex nested data** | ✅ Extract flat entities | ❌ Parsing complex |
| **Need full data later** | ❌ May lose details | ✅ Keep raw |
| **Audit trail required** | ❌ May not be enough | ✅ Full raw data |

### Example: When NOT to Extract

```typescript
// Small, simple result → Just store raw
const userResult = { id: 123, name: 'John' };
// ❌ Don't extract: Result is already small (40 bytes)
// ✅ Store raw: context.lastUserResult = userResult;

// Audit trail → Keep full raw data
const paymentResult = { /* payment details */ };
// ❌ Don't extract: Need full data for compliance
// ✅ Store raw: await db.paymentLogs.create({ data: paymentResult });
```

### Example: When TO Extract

```typescript
// Large result → Extract entities
const pageResult = { id: 42, title: 'Home', content: '<p>...</p>' /* 4KB */ };
// ✅ Extract: { type: 'page', id: 42, label: 'Home' } (200 bytes)

// Frequently referenced → Extract for fast lookup
const projectResult = { id: 5, name: 'Q4 Campaign', team: [...], tasks: [...] };
// ✅ Extract: { type: 'project', id: 5, label: 'Q4 Campaign' }
// → Fast lookup: workingMemory.get('project', 5)
```

---

## References

### Research Papers

1. **PARSE: LLM Driven Schema Optimization for Reliable Entity Extraction** (Amazon, 2025)  
   [https://arxiv.org/abs/2510.08623](https://arxiv.org/abs/2510.08623)  
   - 64.7% accuracy improvement on SWDE dataset
   - ARCHITECT component: Optimizes JSON schemas
   - SCOPE component: Reflection-based extraction with guardrails

2. **Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory** (2025)  
   [https://arxiv.org/abs/2504.19413](https://arxiv.org/abs/2504.19413)  
   - Two-phase extraction pipeline
   - Entity + relationship extraction
   - 26% accuracy boost over OpenAI Memory

3. **GPT-NER: Named Entity Recognition via Large Language Models** (2025)  
   [https://aclanthology.org/2025.findings-naacl.239](https://aclanthology.org/2025.findings-naacl.239)  
   - First time LLMs match supervised NER baselines
   - Self-verification strategy for hallucination reduction
   - Generation-based extraction vs sequence labeling

4. **CascadeNER: Named Entity Recognition via LLMs** (2024)  
   [https://arxiv.org/abs/2409.11022](https://arxiv.org/abs/2409.11022)  
   - Two-stage extraction: Entity detection → Classification
   - State-of-the-art on low-resource scenarios
   - Dynamic categorization system

### Production Frameworks

5. **Instructor: Structured Outputs in Python** (2024-2025)  
   [https://python.useinstructor.com](https://python.useinstructor.com)  
   - Pydantic-based extraction patterns
   - Validation and retry logic
   - Production-ready examples

6. **Structured Outputs by Example** (2025)  
   [https://structuredoutputsbyexamples.com](https://structuredoutputsbyexamples.com)  
   - Hands-on guide to structured extraction
   - Performance optimization tips
   - Advanced validation patterns

7. **Vercel AI SDK: Structured Outputs** (2024-2025)  
   [https://sdk.vercel.ai/docs/ai-sdk-core/generating-structured-data](https://sdk.vercel.ai/docs/ai-sdk-core/generating-structured-data)  
   - `generateObject()` with Zod schemas
   - Tool-based extraction
   - Type-safe implementations

8. **OpenAI Structured Outputs** (2024)  
   [https://platform.openai.com/docs/guides/structured-outputs](https://platform.openai.com/docs/guides/structured-outputs)  
   - JSON Schema mode
   - Function calling for extraction
   - Best practices guide

### Implementation Examples

9. **LangChain Extraction Use Cases** (2024-2025)  
   [https://python.langchain.com/docs/use_cases/extraction/](https://python.langchain.com/docs/use_cases/extraction/)  
   - Extraction chains
   - Schema design patterns
   - Production examples

10. **Cohere Structured Outputs** (2024)  
    [https://docs.cohere.com/docs/structured-outputs](https://docs.cohere.com/docs/structured-outputs)  
    - JSON mode and JSON Schema mode
    - Tool use with structured outputs
    - Command R+ examples

### Tools & Libraries

11. **DSPy Assertions for Structured Extraction** (2025)  
    [https://pub.towardsai.net/structured-data-extraction-from-llms-using-dspy](https://pub.towardsai.net/structured-data-extraction-from-llms-using-dspy)  
    - TypedPredictors
    - Automatic prompt optimization
    - Qdrant integration

12. **LLM Tool: Simon Willison's Schema Support** (2025)  
    [https://simonwillison.net/2025/Feb/28/llm-schemas/](https://simonwillison.net/2025/Feb/28/llm-schemas/)  
    - llm-anthropic and llm-gemini plugins
    - Command-line structured extraction
    - PDF and article extraction

---

**Next Topic**: [4.1.3 Sliding Window (Recent N Entities)](./4.1.3-sliding-window.md)

**Related Topics**:
- [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- [2.1.1 Compression Techniques](../2-context/2.1.1-compression.md)
- [3.1.2 Tool Design Patterns](../3-agents/3.1.2-tool-design.md)
