# 4.2.5 - Compression Ratios

## TL;DR

**Compression ratio measures how much memory is reduced through summarization—HiAgent achieves 10:1 compression by replacing detailed action-observation pairs with concise subgoal summaries, enabling agents to scale to hundreds of steps without context overflow while maintaining or improving task success rates.**

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-11
- **Prerequisites**: [4.2.4 Summarization Strategies](./4.2.4-summarization-strategies.md), [4.2.1 HiAgent Hierarchical Memory](./4.2.1-hiagent-hierarchical-memory.md)
- **Grounded In**: HiAgent (ACL 2025), Dynamic Memory Compression (ICML 2024), Context Engineering Research (2025)

## Table of Contents

- [Overview](#overview)
- [The Problem: Context Limits](#the-problem-context-limits)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

Compression ratio quantifies the effectiveness of memory compression, expressing how many tokens of original content are reduced to a single token of compressed content. A 10:1 ratio means 5,000 tokens of action history compress to just 500 tokens of subgoal summaries—enabling long-horizon tasks that would otherwise exceed context limits.

The key insight from HiAgent research is that high compression (10:1) doesn't sacrifice quality—in fact, task success rates *improve* because cleaner context helps the LLM focus on what matters. The trade-off isn't compression vs quality, it's compression vs unnecessary detail.

**Key Research Findings (2024-2025)**:

- **HiAgent (ACL 2025)**: 10:1 average compression across 5 benchmarks
- **Quality Preservation**: Success rate doubled (42% vs 21%) with compression
- **Scalability**: 100+ action tasks fit in standard context windows
- **Cost Impact**: 90% reduction in token costs for long conversations

## The Problem: Context Limits

### The Classic Challenge

Without compression, context grows linearly with task length until overflow:

```
Task Length     Without Compression     With 10:1 Compression
-----------     -------------------     ---------------------
10 actions      1,000 tokens            100 tokens
50 actions      5,000 tokens            500 tokens
100 actions     10,000 tokens           1,000 tokens
200 actions     20,000 tokens           2,000 tokens
500 actions     50,000 tokens           5,000 tokens
```

**Problems**:

- ❌ **Context Overflow**: Long tasks exceed model limits
- ❌ **Lost in the Middle**: Critical info buried in noise
- ❌ **Cost Explosion**: Linear growth in API costs
- ❌ **Latency Degradation**: Slower inference with large contexts

### Why This Matters

| Context Window | Without Compression | With 10:1 | Tasks Supported |
|----------------|--------------------|-----------:|-----------------|
| 8K tokens | 80 actions | 800 actions | Small → Medium |
| 16K tokens | 160 actions | 1,600 actions | Medium → Large |
| 128K tokens | 1,280 actions | **12,800 actions** | **Long-horizon** |

The math is simple: 10:1 compression effectively gives you a 10× larger context window.

## Core Concept

### What is Compression Ratio?

**Compression Ratio** = Original Tokens / Compressed Tokens

```typescript
const originalTokens = 5000;   // 50 actions × 100 tokens each
const compressedTokens = 500;  // 10 subgoal summaries × 50 tokens each
const ratio = originalTokens / compressedTokens; // 10:1
```

### Visual Representation

```
Before Compression (5000 tokens):
┌────────────────────────────────────────────────────────────┐
│ Action 1 → Observation 1    (100 tokens)                   │
│ Action 2 → Observation 2    (100 tokens)                   │
│ Action 3 → Observation 3    (100 tokens)                   │
│ ... (50 actions total)                                     │
└────────────────────────────────────────────────────────────┘

After Compression (500 tokens):
┌────────────────────────────────────────────────────────────┐
│ Subgoal 1: "Tools retrieved from boot"     (50 tokens)     │
│ Subgoal 2: "All wheel nuts loosened"       (50 tokens)     │
│ Subgoal 3: "Car jacked up safely"          (50 tokens)     │
│ ... (10 subgoals total)                                    │
└────────────────────────────────────────────────────────────┘

Compression: 5000 → 500 tokens (10:1 ratio)
```

### Compression Ratio Spectrum

```
┌─────────────────────────────────────────────────────────────┐
│              COMPRESSION RATIO SPECTRUM                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Conservative        Balanced         Aggressive             │
│  (2-5:1)            (8-12:1)         (15-20:1)              │
│                                                              │
│  ├───────────────────────────────────────────────────────┤  │
│  │                                                       │  │
│  │  High quality      HiAgent target    Quality loss     │  │
│  │  Low savings       Optimal           High savings     │  │
│  │  <5% loss          10-15% loss       >20% loss        │  │
│  │                                                       │  │
│  └───────────────────────────────────────────────────────┘  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Key Factors Affecting Ratio

| Factor | Low Ratio (2-5:1) | High Ratio (10-15:1) |
|--------|-------------------|----------------------|
| **Actions per subgoal** | 2-3 | 5-7 |
| **Summary length** | Detailed | Concise |
| **Information retained** | High detail | Outcomes only |
| **Redundancy** | Low | High (repeated actions) |

## Implementation Patterns

### Pattern 1: Target-Based Compression

**Use Case**: Achieving specific compression ratios consistently

```typescript
class TargetCompressionSystem {
  private targetRatio = 10;
  private maxSummaryTokens = 50;

  async compressToTarget(
    subgoal: string,
    actions: Array<{ action: string; observation: string }>
  ): Promise<{ summary: string; achievedRatio: number }> {
    // Calculate original tokens
    const originalText = actions
      .map(a => `${a.action} ${a.observation}`)
      .join(' ');
    const originalTokens = this.estimateTokens(originalText);

    // Target summary length
    const targetTokens = Math.ceil(originalTokens / this.targetRatio);
    const maxTokens = Math.min(targetTokens, this.maxSummaryTokens);

    // Generate constrained summary
    const summary = await this.generateConstrainedSummary(
      subgoal,
      actions,
      maxTokens
    );

    const summaryTokens = this.estimateTokens(summary);
    const achievedRatio = originalTokens / summaryTokens;

    return { summary, achievedRatio };
  }

  private async generateConstrainedSummary(
    subgoal: string,
    actions: Array<{ action: string; observation: string }>,
    maxTokens: number
  ): Promise<string> {
    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt: `
Subgoal: ${subgoal}
Actions: ${actions.map(a => `${a.action}→${a.observation}`).join('; ')}

Summarize in ${maxTokens * 4} characters or less (about ${maxTokens} tokens).
Focus on OUTCOME, not process.
      `.trim(),
      max_tokens: maxTokens + 10, // Small buffer
    });

    return result.text.trim();
  }

  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4); // ~4 chars per token
  }
}
```

**Pros**:
- ✅ Consistent compression
- ✅ Predictable token usage
- ✅ Quality control

**Cons**:
- ❌ May truncate important info
- ❌ Requires tuning per domain

**When to Use**: When consistent compression is required

### Pattern 2: Multi-Level Compression

**Use Case**: Extremely long tasks (100+ subgoals)

```typescript
class MultiLevelCompressor {
  // Level 1: Actions → Subgoal summaries (10:1)
  // Level 2: Subgoals → Phase summaries (5:1)
  // Level 3: Phases → Task overview (5:1)
  // Overall: 250:1 potential compression

  private level1Summaries: string[] = [];
  private level2Summaries: string[] = [];
  private level3Summary = '';

  async addSubgoalSummary(summary: string): Promise<void> {
    this.level1Summaries.push(summary);

    // Compress to Level 2 every 10 subgoals
    if (this.level1Summaries.length >= 10) {
      const phaseSummary = await this.compressToPhase(this.level1Summaries);
      this.level2Summaries.push(phaseSummary);
      this.level1Summaries = [];
    }

    // Compress to Level 3 every 5 phases
    if (this.level2Summaries.length >= 5) {
      this.level3Summary = await this.compressToOverview(this.level2Summaries);
      this.level2Summaries = [];
    }
  }

  getContext(): string {
    const parts: string[] = [];

    if (this.level3Summary) {
      parts.push(`Overview: ${this.level3Summary}`);
    }

    if (this.level2Summaries.length > 0) {
      parts.push(`Recent phases: ${this.level2Summaries.join('; ')}`);
    }

    if (this.level1Summaries.length > 0) {
      parts.push(`Current phase: ${this.level1Summaries.join('; ')}`);
    }

    return parts.join('\n\n');
  }

  private async compressToPhase(summaries: string[]): Promise<string> {
    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt: `Compress these ${summaries.length} subgoals into ONE sentence:\n${summaries.join('\n')}`,
    });
    return result.text.trim();
  }

  private async compressToOverview(phases: string[]): Promise<string> {
    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt: `Create a brief overview of these phases:\n${phases.join('\n')}`,
    });
    return result.text.trim();
  }
}
```

**Pros**:
- ✅ Handles unlimited task length
- ✅ 50:1+ overall compression
- ✅ Preserves recent detail

**Cons**:
- ❌ Higher information loss
- ❌ More complex
- ❌ Multiple LLM calls

**When to Use**: Very long-running agents, research tasks

### Pattern 3: Adaptive Compression

**Use Case**: Variable task complexity requiring dynamic ratios

```typescript
class AdaptiveCompressor {
  private minRatio = 5;
  private maxRatio = 15;

  async compress(
    subgoal: string,
    actions: Array<{ action: string; observation: string }>
  ): Promise<{ summary: string; ratio: number }> {
    // Determine target ratio based on action patterns
    const targetRatio = this.calculateTargetRatio(actions);

    // Higher ratio for repetitive actions
    if (this.isRepetitive(actions)) {
      return this.compressAggressive(subgoal, actions);
    }

    // Lower ratio for complex, varied actions
    if (this.isComplex(actions)) {
      return this.compressConservative(subgoal, actions);
    }

    // Default balanced compression
    return this.compressBalanced(subgoal, actions);
  }

  private isRepetitive(
    actions: Array<{ action: string; observation: string }>
  ): boolean {
    const baseActions = actions.map(a => a.action.split('_')[0]);
    const uniqueActions = new Set(baseActions);
    return uniqueActions.size === 1; // All same type
  }

  private isComplex(
    actions: Array<{ action: string; observation: string }>
  ): boolean {
    // High variance in observation length suggests complexity
    const lengths = actions.map(a => a.observation.length);
    const variance = this.calculateVariance(lengths);
    return variance > 100;
  }

  private async compressAggressive(subgoal: string, actions: any[]) {
    // Target 15:1 ratio
    const summary = await this.generateSummary(subgoal, actions, 15);
    return { summary, ratio: 15 };
  }

  private async compressConservative(subgoal: string, actions: any[]) {
    // Target 5:1 ratio
    const summary = await this.generateSummary(subgoal, actions, 5);
    return { summary, ratio: 5 };
  }

  private async compressBalanced(subgoal: string, actions: any[]) {
    // Target 10:1 ratio
    const summary = await this.generateSummary(subgoal, actions, 10);
    return { summary, ratio: 10 };
  }
}
```

**Pros**:
- ✅ Optimal ratio per situation
- ✅ Preserves complex context
- ✅ Aggressive on repetitive

**Cons**:
- ❌ Variable output size
- ❌ Pattern detection complexity

**When to Use**: Mixed task complexity, production systems

## Framework Integration

### AI SDK v6 with Compression Metrics

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { z } from 'zod';

const compressor = new TargetCompressionSystem();
const memory = new HiAgentMemoryManager(task, goal);

// Tool that tracks compression
const executeAction = tool({
  description: 'Execute an action',
  inputSchema: z.object({
    action: z.string(),
  }),
  execute: async ({ action }) => {
    const observation = await performAction(action);
    memory.addAction(action, observation);

    // Compress on subgoal completion
    if (await memory.isSubgoalComplete()) {
      const { summary, achievedRatio } = await compressor.compressToTarget(
        memory.getCurrentSubgoal(),
        memory.getCurrentActions()
      );

      memory.archiveSubgoal(summary);
      console.log(`Compressed at ${achievedRatio.toFixed(1)}:1 ratio`);
    }

    return { action, observation };
  },
});

async function runAgent(prompt: string) {
  const result = await generateText({
    model: openai('gpt-4o'),
    prompt: `${memory.getContext()}\n\n${prompt}`,
    tools: { executeAction },
    stopWhen: stepCountIs(10),
  });

  return result.text;
}
```

### Compression Monitor

```typescript
class CompressionMonitor {
  private history: Array<{ original: number; compressed: number; ratio: number }> = [];

  record(original: number, compressed: number): void {
    const ratio = original / compressed;
    this.history.push({ original, compressed, ratio });

    // Alert on low compression
    if (ratio < 5) {
      console.warn(`Low compression: ${ratio.toFixed(1)}:1`);
    }
  }

  getStats(): {
    avgRatio: number;
    totalSaved: number;
    compressionCount: number;
  } {
    const totalOriginal = this.history.reduce((sum, h) => sum + h.original, 0);
    const totalCompressed = this.history.reduce((sum, h) => sum + h.compressed, 0);

    return {
      avgRatio: totalOriginal / totalCompressed,
      totalSaved: totalOriginal - totalCompressed,
      compressionCount: this.history.length,
    };
  }
}
```

## Research & Benchmarks

### HiAgent Compression Results (ACL 2025)

| Task | Actions/Subgoal | Summary Tokens | Original Tokens | Ratio |
|------|-----------------|----------------|-----------------|-------|
| **Blocksworld** | 4.2 | 35 | 420 | 12:1 |
| **Gripper** | 5.8 | 42 | 580 | 13.8:1 |
| **Tyreworld** | 6.1 | 48 | 610 | 12.7:1 |
| **Barman** | 3.9 | 32 | 390 | 12.2:1 |
| **Jericho** | 5.3 | 55 | 530 | 9.6:1 |
| **Average** | **5.1** | **42** | **510** | **10:1** |

### Compression vs Quality Trade-off

| Ratio | Information Loss | Task Success | Recommended Use |
|-------|------------------|--------------|-----------------|
| 2:1 | <5% | 35% | Critical tasks, debugging |
| 5:1 | 5-10% | 38% | Conservative, detailed |
| **10:1** | **10-15%** | **42%** | **Production default** |
| 15:1 | 15-25% | 36% | Simple tasks |
| 20:1+ | >25% | 28% | Not recommended |

**Key Finding**: 10:1 compression actually improves success rates because cleaner context helps the LLM focus.

### Optimal Actions per Subgoal

| Actions | Compression | Quality | Assessment |
|---------|-------------|---------|------------|
| 2-3 | 4-6:1 | 0.8 | Too fine-grained |
| **3-7** | **8-12:1** | **0.85-0.9** | **Optimal** |
| 8-10 | 12-15:1 | 0.75 | Acceptable |
| 10+ | 15:1+ | <0.7 | Too coarse |

## When to Use This Pattern

### ✅ Use When:

1. **Long-horizon tasks**
   - 50+ actions expected
   - Multiple subgoals

2. **Context limits approaching**
   - 70%+ capacity used
   - Need to free space

3. **Cost optimization**
   - High-volume usage
   - Token costs significant

### ❌ Don't Use When:

1. **Short tasks** (<20 actions)
   - Compression overhead exceeds benefit

2. **Debugging required**
   - Need full action trace
   - Use lower compression

3. **Audit requirements**
   - Full history must be preserved
   - Use persistent storage

### Target Ratio by Scenario

| Scenario | Target Ratio | Reasoning |
|----------|--------------|-----------|
| Production agents | 10:1 | Balanced |
| Debugging | 2-5:1 | Preserve detail |
| Very long tasks | 15:1 (multi-level) | Prevent overflow |
| Cost-sensitive | 12:1 | Maximize savings |

## Production Best Practices

### 1. Monitor Compression Quality

Track ratio and quality metrics:

```typescript
function monitorCompression(
  original: number,
  compressed: number,
  targetRatio: number
): { status: 'ok' | 'warning' | 'error'; message: string } {
  const ratio = original / compressed;

  if (ratio < targetRatio * 0.7) {
    return {
      status: 'warning',
      message: `Low compression: ${ratio.toFixed(1)}:1 (target: ${targetRatio}:1)`,
    };
  }

  if (ratio > targetRatio * 1.5) {
    return {
      status: 'warning',
      message: `Over-compressed: ${ratio.toFixed(1)}:1 (may lose info)`,
    };
  }

  return { status: 'ok', message: `Compression on target: ${ratio.toFixed(1)}:1` };
}
```

### 2. Optimize Actions per Subgoal

Target 5 actions for 10:1 compression:

```typescript
const OPTIMAL_ACTIONS_PER_SUBGOAL = 5;

function shouldCreateSubgoal(actionCount: number): boolean {
  return actionCount >= OPTIMAL_ACTIONS_PER_SUBGOAL;
}
```

### 3. Use Extractive Fallback

When LLM unavailable, use heuristic compression:

```typescript
function extractiveFallback(
  actions: Array<{ action: string; observation: string }>
): string {
  if (actions.length === 0) return '';

  // First + last + count
  const first = actions[0].observation;
  const last = actions[actions.length - 1].observation;

  return `${first} → ${last} (${actions.length} steps)`;
}
```

### 4. Common Pitfalls

#### ❌ Pitfall: Targeting Too High Ratio

**Problem**: 20:1+ loses critical information.

**Solution**: Cap at 15:1, use multi-level for more:
```typescript
const MAX_SINGLE_LEVEL_RATIO = 15;
if (targetRatio > MAX_SINGLE_LEVEL_RATIO) {
  useMultiLevelCompression();
}
```

#### ❌ Pitfall: Compressing Too Early

**Problem**: Compressing 2-action subgoals wastes effort.

**Solution**: Minimum action threshold:
```typescript
const MIN_ACTIONS_FOR_COMPRESSION = 3;
if (actions.length < MIN_ACTIONS_FOR_COMPRESSION) {
  return actions.map(a => a.observation).join('; '); // Light merge only
}
```

## Key Takeaways

1. **10:1 is the sweet spot** - Achieves 90% token savings with <15% info loss
2. **Compression improves quality** - Cleaner context → better LLM focus → higher success
3. **Target 5 actions per subgoal** - Optimal granularity for 10:1 compression
4. **Use multi-level for extreme tasks** - 50:1+ possible with hierarchical approach
5. **Monitor compression metrics** - Track ratio, quality, and cost savings

**Quick Implementation Checklist**:

- [ ] Set target compression ratio (default: 10:1)
- [ ] Implement token counting for original and compressed
- [ ] Create length-constrained summarization prompts
- [ ] Add compression monitoring and alerts
- [ ] Test with various task types
- [ ] Implement extractive fallback for reliability

## References

1. **Hu, M. et al.** (2025). "HiAgent: Hierarchical Working Memory Management". *ACL 2025*. https://aclanthology.org/2025.acl-long.1575.pdf
2. **Nawrot, P. et al.** (2024). "Dynamic Memory Compression". *ICML 2024*. https://arxiv.org/abs/2403.09636
3. **LangChain** (2025). "Context Engineering for Agents". https://blog.langchain.dev/context-engineering-for-agents/
4. **Mem0** (2025). "LLM Chat History Summarization Guide 2025". https://mem0.ai/blog/llm-chat-history-summarization-guide-2025
5. **Galileo AI** (2025). "Master LLM Summarization Strategies". https://galileo.ai/blog/llm-summarization-strategies
6. **HiAgent GitHub Repository** (2024). https://github.com/HiAgent2024/HiAgent

**Related Topics**:

- [4.2.1 HiAgent Hierarchical Memory](./4.2.1-hiagent-hierarchical-memory.md)
- [4.2.4 Summarization Strategies](./4.2.4-summarization-strategies.md)
- [4.3.1 Vector Databases](./4.3.1-vector-databases.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
