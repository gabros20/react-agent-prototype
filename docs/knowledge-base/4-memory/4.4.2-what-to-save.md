# 4.4.2 - What to Save in Checkpoints

## TL;DR

**Save just enough state to reconstruct the exact execution context—messages, execution phase, working memory, subgoals, and metadata—but no more.** Over-saving bloats storage and slows recovery; under-saving prevents proper resume. Target 5-50KB per checkpoint with message compression for long conversations.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-12
- **Prerequisites**: [4.4.1 Why Checkpoint](./4.4.1-why-checkpoint.md)
- **Grounded In**: LangGraph state management (2025), OpenAI Agents SDK sessions, Mem0 memory architecture

## Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem-checkpoint-data-selection)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

What you save in a checkpoint determines whether your agent can successfully resume execution. The core principle is **minimal sufficiency**: save exactly what's needed to reconstruct execution context, nothing more.

Essential checkpoint components:
1. **Conversation History**: Messages exchanged (compressed if >20)
2. **Execution State**: Current phase, step number, completion status
3. **Working Memory**: Extracted entities, facts, references
4. **Subgoals**: Task breakdown, dependencies, progress
5. **Metadata**: User context, timestamps, configuration

**Key Research Findings (2024-2025)**:

- **OpenAI Agents SDK**: Session-based memory with automatic context management
- **Mem0**: 10:1 compression ratio with message summarization
- **LangGraph**: Schema versioning for checkpoint migration

## The Problem: Checkpoint Data Selection

### The Classic Challenge

```
Over-saving:
- Full documents (10MB each) stored in every checkpoint
- All LLM responses with reasoning traces
- Complete tool call history with raw responses
→ Result: 500MB checkpoints, 30-second save times, $100/month storage

Under-saving:
- Only current message, no history
- No working memory (entities, references)
- No execution phase tracking
→ Result: Can't resume properly, agent "forgets" context
```

**Problems**:

- ❌ **Storage bloat**: Large checkpoints cost more and slow recovery
- ❌ **Resume failure**: Missing state causes incorrect behavior
- ❌ **Security risk**: Accidentally storing secrets or PII
- ❌ **Serialization errors**: Functions, circular refs can't be saved

### Why This Matters

A well-designed checkpoint schema enables:
- **Fast recovery**: <1s load time with compact checkpoints
- **Accurate resume**: All context preserved for coherent continuation
- **Cost efficiency**: Minimal storage costs at scale
- **Security compliance**: No secrets or PII in checkpoints

## Core Concept

### Five Core State Components

```
┌─────────────────────────────────────────────────────────────┐
│                    CHECKPOINT STRUCTURE                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. MESSAGES (Conversation History)                         │
│     ├── All user/assistant/system messages                  │
│     ├── Tool call results                                   │
│     └── Size: 1-5KB per 10 messages                         │
│                                                              │
│  2. EXECUTION STATE (Phase & Progress)                      │
│     ├── Current phase: planning|executing|reviewing         │
│     ├── Step number and total steps                         │
│     └── Completed steps set                                 │
│                                                              │
│  3. WORKING MEMORY (Entities & Facts)                       │
│     ├── Extracted entities: {destination: "Japan"}          │
│     ├── Facts: [{subj, pred, obj}, ...]                    │
│     └── References: {"this page" → "page_123"}              │
│                                                              │
│  4. SUBGOALS (Task Breakdown)                               │
│     ├── Goal hierarchy with dependencies                    │
│     ├── Status: pending|in_progress|completed|failed        │
│     └── Results for completed subgoals                      │
│                                                              │
│  5. METADATA (Context & Config)                             │
│     ├── userId, sessionId, threadId                         │
│     ├── Timestamp and version                               │
│     └── Agent configuration (model, tools)                  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Inclusion Decision Tree

```
Should this data be checkpointed?
    │
    ├── Is it needed to resume execution?
    │   └── NO → Don't save
    │
    ├── Is it a secret or credential?
    │   └── YES → Never save, use env vars
    │
    ├── Is it large binary data (images, files)?
    │   └── YES → Save reference (URL/ID), not content
    │
    ├── Can it be quickly recomputed (<100ms)?
    │   └── YES → Don't save, recompute on resume
    │
    └── Otherwise → Save it
```

### What to Include vs Exclude

| Always Include | Never Include |
|---------------|---------------|
| Conversation messages | API keys / secrets |
| Current phase/step | Large binary data |
| Extracted entities | Computed values |
| Critical metadata | Transient UI state |
| Pending actions | Debug logs |
| Subgoal hierarchy | Full RAG documents |

## Implementation Patterns

### Pattern 1: Complete Checkpoint Schema

**Use Case**: Production agents with full state tracking

```typescript
import { z } from 'zod';

// Message schema
const MessageSchema = z.object({
  role: z.enum(['user', 'assistant', 'system', 'tool']),
  content: z.string(),
  timestamp: z.string().datetime(),
  id: z.string().optional(),
  toolCallId: z.string().optional(),
});

// Execution state schema
const ExecutionStateSchema = z.object({
  phase: z.enum(['planning', 'executing', 'reviewing', 'complete']),
  currentStep: z.number(),
  totalSteps: z.number(),
  completedSteps: z.array(z.string()),
});

// Working memory schema
const WorkingMemorySchema = z.object({
  entities: z.record(z.unknown()),
  facts: z.array(z.object({
    subject: z.string(),
    predicate: z.string(),
    object: z.string(),
  })),
  references: z.record(z.string()),
  lastUpdated: z.string().datetime(),
});

// Subgoal schema
const SubgoalSchema = z.object({
  id: z.string(),
  description: z.string(),
  status: z.enum(['pending', 'in_progress', 'completed', 'failed']),
  dependencies: z.array(z.string()),
  result: z.unknown().optional(),
  startedAt: z.string().datetime().optional(),
  completedAt: z.string().datetime().optional(),
});

// Complete checkpoint schema
const CheckpointSchema = z.object({
  // Identity
  id: z.string(),
  threadId: z.string(),
  userId: z.string(),
  timestamp: z.string().datetime(),
  version: z.string(),

  // State
  messages: z.array(MessageSchema),
  execution: ExecutionStateSchema,
  memory: WorkingMemorySchema,
  subgoals: z.array(SubgoalSchema),

  // Metadata
  metadata: z.object({
    agentVersion: z.string(),
    model: z.string(),
    tools: z.array(z.string()),
    userTimezone: z.string().optional(),
    userLanguage: z.string().optional(),
  }),

  // Tracking
  parentCheckpointId: z.string().optional(),
  compressed: z.boolean().default(false),
});

type Checkpoint = z.infer<typeof CheckpointSchema>;
```

**Pros**:
- ✅ Type-safe with runtime validation
- ✅ Complete state for any resume scenario
- ✅ Schema versioning built-in

**Cons**:
- ❌ Verbose schema definition
- ❌ May be overkill for simple agents

**When to Use**: Production systems requiring comprehensive state tracking

### Pattern 2: Serialization with Custom Types

**Use Case**: Handling Maps, Sets, Dates that JSON.stringify can't serialize

```typescript
// Custom serializer for non-JSON types
function serialize(obj: unknown): string {
  return JSON.stringify(obj, (key, value) => {
    if (value instanceof Map) {
      return { __type: 'Map', entries: Array.from(value.entries()) };
    }
    if (value instanceof Set) {
      return { __type: 'Set', values: Array.from(value) };
    }
    if (value instanceof Date) {
      return { __type: 'Date', iso: value.toISOString() };
    }
    return value;
  });
}

// Custom deserializer
function deserialize<T>(json: string): T {
  return JSON.parse(json, (key, value) => {
    if (value && typeof value === 'object') {
      if (value.__type === 'Map') return new Map(value.entries);
      if (value.__type === 'Set') return new Set(value.values);
      if (value.__type === 'Date') return new Date(value.iso);
    }
    return value;
  });
}

// Usage
const memory = {
  entities: new Map([['destination', 'Japan'], ['budget', '$3000']]),
  visitedPages: new Set(['home', 'about']),
  createdAt: new Date(),
};

const json = serialize(memory);
const restored = deserialize<typeof memory>(json);
// ✅ Maps, Sets, Dates properly restored
```

**Pros**:
- ✅ Handles complex JavaScript types
- ✅ Round-trip preserves data fidelity
- ✅ Human-readable JSON output

**Cons**:
- ❌ Custom protocol (non-standard JSON)
- ❌ Must use matching serialize/deserialize pair

**When to Use**: When state includes Maps, Sets, or Date objects

### Pattern 3: Message Compression

**Use Case**: Long conversations exceeding 20+ messages

```typescript
async function compressMessages(
  messages: Message[],
  maxUncompressed: number = 20
): Promise<Message[]> {
  if (messages.length <= maxUncompressed) return messages;

  // Keep first 3 (system prompt + initial context)
  const head = messages.slice(0, 3);

  // Keep last 5 (recent context)
  const tail = messages.slice(-5);

  // Summarize middle section
  const middle = messages.slice(3, -5);
  const summaryPrompt = `Summarize this conversation in 2-3 sentences:
${middle.map(m => `${m.role}: ${m.content}`).join('\n')}`;

  const summary = await generateSummary(summaryPrompt);

  return [
    ...head,
    {
      role: 'system',
      content: `[Summary of ${middle.length} messages: ${summary}]`,
      timestamp: new Date().toISOString(),
    },
    ...tail,
  ];
}

// Usage: Compress before saving
async function saveCheckpoint(threadId: string, state: CheckpointState) {
  const compressedMessages = await compressMessages(state.messages);

  await db.save({
    threadId,
    messages: compressedMessages,
    compressed: compressedMessages.length < state.messages.length,
    originalMessageCount: state.messages.length,
    // ...rest of state
  });
}
```

**Pros**:
- ✅ 10:1 compression ratio typical
- ✅ Preserves recent context for coherent resume
- ✅ Reduces storage and load time

**Cons**:
- ❌ Loses detail from summarized messages
- ❌ Requires LLM call for summarization

**When to Use**: Conversations exceeding 20+ messages

## Framework Integration

### AI SDK v6 Checkpoint-Aware Tools

```typescript
import { generateText, tool } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

// Tool that updates checkpoint state
const updateWorkingMemory = tool({
  description: 'Store extracted information for later reference',
  parameters: z.object({
    entityType: z.string(),
    entityId: z.string(),
    data: z.record(z.unknown()),
  }),
  execute: async ({ entityType, entityId, data }, { checkpointManager, threadId }) => {
    // Load current checkpoint
    const checkpoint = await checkpointManager.loadLatest(threadId);

    // Update working memory
    const updatedMemory = {
      ...checkpoint.memory,
      entities: {
        ...checkpoint.memory.entities,
        [entityType]: { ...checkpoint.memory.entities[entityType], [entityId]: data },
      },
      lastUpdated: new Date().toISOString(),
    };

    // Save updated checkpoint
    await checkpointManager.save({
      ...checkpoint,
      memory: updatedMemory,
    });

    return { stored: true, entityType, entityId };
  },
});

// Tool that advances execution state
const completeStep = tool({
  description: 'Mark a step as completed',
  parameters: z.object({
    stepName: z.string(),
    result: z.unknown().optional(),
  }),
  execute: async ({ stepName, result }, { checkpointManager, threadId }) => {
    const checkpoint = await checkpointManager.loadLatest(threadId);

    const updatedExecution = {
      ...checkpoint.execution,
      currentStep: checkpoint.execution.currentStep + 1,
      completedSteps: [...checkpoint.execution.completedSteps, stepName],
    };

    await checkpointManager.save({
      ...checkpoint,
      execution: updatedExecution,
    });

    return { completed: stepName, nextStep: updatedExecution.currentStep };
  },
});
```

### Tiered Checkpoint Strategy

```typescript
// Different checkpoint frequencies for different data
class TieredCheckpointManager {
  // High frequency: Every tool call (minimal state)
  async quickCheckpoint(threadId: string, step: number, lastMessage: Message) {
    await this.redis.set(`quick:${threadId}`, JSON.stringify({
      step,
      lastMessage,
      timestamp: Date.now(),
    }), 'EX', 3600); // 1 hour TTL
  }

  // Medium frequency: Every 5 steps (working memory)
  async regularCheckpoint(threadId: string, state: PartialState) {
    await this.db.upsert('regular_checkpoints', {
      threadId,
      messages: state.messages.slice(-10), // Last 10 only
      memory: state.memory,
      execution: state.execution,
      timestamp: new Date(),
    });
  }

  // Low frequency: Phase transitions (complete state)
  async fullCheckpoint(threadId: string, state: CompleteState) {
    await this.db.insert('full_checkpoints', {
      threadId,
      ...state,
      timestamp: new Date(),
    });
  }
}
```

## Research & Benchmarks

### Academic Research (2024-2025)

#### OpenAI Agents SDK Session Memory

**Source**: OpenAI Cookbook (2025)

- **Approach**: Automatic session-based context management
- **Key insight**: Keep last N turns, summarize older context
- **Compression**: 10:1 ratio with minimal accuracy loss

#### Mem0 Memory Architecture

**Source**: Mem0 arXiv paper (2025)

- **Finding**: 90% token savings with selective fact storage
- **Pattern**: Extract facts instead of storing raw conversation
- **Benefit**: Smaller checkpoints with higher signal-to-noise

### Size Benchmarks

**Checkpoint Size by Content**:

| Content | Size | Notes |
|---------|------|-------|
| 10 messages | 2-5 KB | Typical short conversation |
| 50 messages | 10-25 KB | Long conversation |
| 50 messages (compressed) | 3-5 KB | With summarization |
| Working memory (20 entities) | 1-2 KB | Extracted facts |
| Subgoals (10 tasks) | 1-3 KB | Task hierarchy |
| Full checkpoint | 5-30 KB | Target range |

**Storage Cost at Scale**:

| Checkpoints/day | Size | Monthly Storage | Monthly Cost |
|-----------------|------|-----------------|--------------|
| 10,000 | 10 KB avg | 3 GB | $0.10 |
| 100,000 | 10 KB avg | 30 GB | $1.00 |
| 1,000,000 | 10 KB avg | 300 GB | $10.00 |

## When to Use This Pattern

### ✅ Include in Checkpoints:

1. **Conversation messages**
   - All user/assistant exchanges
   - System prompts (if dynamic)
   - Tool call results

2. **Execution state**
   - Current phase and step
   - Completed steps tracking
   - Pending actions

3. **Working memory**
   - Extracted entities
   - User preferences
   - Reference resolutions

4. **Critical metadata**
   - User/session/thread IDs
   - Timestamps
   - Agent configuration

### ❌ Exclude from Checkpoints:

1. **Secrets**
   - API keys
   - Credentials
   - Tokens

2. **Large data**
   - Full documents (save IDs instead)
   - Images/videos (save URLs)
   - Raw API responses

3. **Computable values**
   - Token counts
   - Derived metrics
   - Cached computations

4. **Non-serializable**
   - Functions
   - Circular references
   - Class instances with methods

## Production Best Practices

### 1. Always Include Schema Version

```typescript
const checkpoint = {
  version: '2.1.0', // ✅ Enables migration
  // ...rest of state
};

// Migration on load
function migrate(checkpoint: AnyCheckpoint): CurrentCheckpoint {
  if (checkpoint.version === '1.0') {
    return migrateV1toV2(checkpoint);
  }
  if (checkpoint.version === '2.0') {
    return migrateV2toV2_1(checkpoint);
  }
  return checkpoint;
}
```

### 2. Validate Before Saving

```typescript
async function saveCheckpoint(checkpoint: unknown) {
  // Validate schema
  const validated = CheckpointSchema.parse(checkpoint);

  // Check for secrets
  if (containsSecrets(validated)) {
    throw new Error('Checkpoint contains secrets!');
  }

  // Check size
  const size = JSON.stringify(validated).length;
  if (size > MAX_CHECKPOINT_SIZE) {
    throw new Error(`Checkpoint too large: ${size} bytes`);
  }

  await db.save(validated);
}
```

### 3. Encrypt Sensitive Fields

```typescript
import { createCipheriv, createDecipheriv, randomBytes } from 'crypto';

function encryptField(value: string, key: Buffer): string {
  const iv = randomBytes(16);
  const cipher = createCipheriv('aes-256-gcm', key, iv);
  const encrypted = Buffer.concat([cipher.update(value, 'utf8'), cipher.final()]);
  const authTag = cipher.getAuthTag();
  return Buffer.concat([iv, authTag, encrypted]).toString('base64');
}

// Encrypt PII before saving
const checkpoint = {
  userId: user.id,
  userEmail: encryptField(user.email, encryptionKey), // Encrypted
  preferences: user.preferences, // Not sensitive
};
```

### Common Pitfalls

#### ❌ Pitfall: Saving Functions

**Problem**: Functions can't be serialized

```typescript
// BAD
await checkpoint.save({
  callback: () => console.log('done'), // TypeError
});

// GOOD
await checkpoint.save({
  callbackName: 'onComplete',
  callbackParams: { messageId: '123' },
});
```

#### ❌ Pitfall: Missing Timestamps

**Problem**: Can't determine checkpoint age

```typescript
// BAD
await checkpoint.save({ messages });

// GOOD
await checkpoint.save({
  messages,
  timestamp: new Date().toISOString(),
});
```

#### ❌ Pitfall: Storing Full Documents

**Problem**: Bloated checkpoints, slow recovery

```typescript
// BAD: 10MB checkpoint
await checkpoint.save({
  documents: [/* full document content */],
});

// GOOD: 1KB checkpoint
await checkpoint.save({
  documentIds: ['doc_1', 'doc_2'],
  retrievalParams: { query: '...', topK: 5 },
});
```

## Key Takeaways

1. **Save minimal sufficient state** - Just enough to resume, no more
2. **Compress long conversations** - Summarize messages beyond 20
3. **Store references, not content** - Document IDs instead of full text
4. **Include schema version** - Enables future migrations
5. **Never save secrets** - Use environment variables

**Quick Implementation Checklist**:

- [ ] Define checkpoint schema with Zod validation
- [ ] Implement serialize/deserialize for Maps, Sets, Dates
- [ ] Add message compression for conversations >20 messages
- [ ] Include schema version in every checkpoint
- [ ] Validate before saving (no secrets, size limits)
- [ ] Test serialization roundtrip preserves data
- [ ] Implement migration functions for schema changes

## References

1. **Sparkco AI** (2025). "Mastering LangGraph State Management in 2025". https://sparkco.ai/blog/mastering-langgraph-state-management-in-2025
2. **OpenAI** (2025). "Context Engineering - Short-Term Memory Management with Sessions". https://cookbook.openai.com/examples/agents_sdk/session_memory
3. **Mem0** (2025). "Building Production-Ready AI Agents with Scalable Long-Term Memory". https://arxiv.org/html/2504.19413v1
4. **Koog** (2025). "Agent Persistence Documentation". https://docs.koog.ai/agent-persistence/
5. **Youssef Hosni** (2025). "Building Agents with LangGraph Course #5: Persistence & Streaming". https://youssefh.substack.com/p/building-agents-with-langgraph-course-bd2

**Related Topics**:

- [4.4.1 Why Checkpoint](./4.4.1-why-checkpoint.md)
- [4.4.3 When to Checkpoint](./4.4.3-when-to-checkpoint.md)
- [4.4.4 How to Resume](./4.4.4-how-to-resume.md)
- [4.4.5 Implementation](./4.4.5-implementation.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
