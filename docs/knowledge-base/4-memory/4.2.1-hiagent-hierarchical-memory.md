# 4.2.1 - HiAgent: Hierarchical Working Memory Management

## TL;DR

**HiAgent is a hierarchical working memory framework that achieves 2× success rate improvement and 35% token reduction by organizing agent memory into subgoal-based chunks—completed subgoals are compressed into summaries while only current work remains in full detail.**

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-11
- **Prerequisites**: [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md), [4.0.1 Memory Systems Overview](./4.0.1-memory-systems-overview.md)
- **Grounded In**: HiAgent (ACL 2025), CoALA (2024), MemGPT, Context Engineering Research (2025)

## Table of Contents

- [Overview](#overview)
- [The Problem: Flat Memory Growth](#the-problem-flat-memory-growth)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

## Overview

HiAgent introduces a hierarchical approach to working memory management that mimics human cognitive strategies. Instead of keeping every action-observation pair in context, it organizes memory around **subgoals**—intermediate objectives that break complex tasks into manageable chunks.

The key insight is that humans don't remember every individual action when completing tasks. We remember **what we accomplished** (subgoals), not how we did it. HiAgent applies this principle to AI agents by compressing completed work into summaries while keeping only the current subgoal's actions in full detail.

**Key Research Findings (2024-2025)**:

- **HiAgent (ACL 2025)**: 2× success rate improvement across 5 long-horizon benchmarks
- **Token Reduction**: 35% fewer context tokens with 10:1 compression ratio
- **Step Efficiency**: 3.8 fewer steps to task completion on average
- **Context Engineering**: "Most agent failures are context failures" (LangChain, 2025)

## The Problem: Flat Memory Growth

### The Classic Challenge

Traditional agent implementations use flat action history—every action-observation pair is appended to context:

```
Turn 1:  action_1 → observation_1       (50 tokens)
Turn 10: action_10 → observation_10     (500 tokens total)
Turn 50: action_50 → observation_50     (2,500 tokens total)
Turn 100: action_100 → observation_100  (5,000+ tokens total)
```

**Problems**:

- ❌ **Context Overflow**: Long tasks exceed LLM context windows (8K-128K tokens)
- ❌ **Lost in the Middle**: Model accuracy drops as relevant info gets buried in noise
- ❌ **Cost Spiral**: Linear token growth means linear cost growth
- ❌ **Latency Degradation**: 2-5× slower inference with large contexts

### Why This Matters

Research shows 90% of long-running agent failures stem from memory issues:

| Problem | Impact |
|---------|--------|
| Context overflow | Task cannot complete |
| Context rot | 90% → 60% accuracy when >80% capacity |
| Irrelevant context | Model focuses on wrong information |
| High token count | 5-10s latency, $0.01+ per request |

Every additional action adds cognitive load for the model. Without hierarchical organization, agents lose track of what they've accomplished and repeat work or fail entirely.

## Core Concept

### What is Hierarchical Memory?

Hierarchical memory organizes information in **layers of abstraction**:

1. **Compressed Layer**: Completed subgoals stored as summaries (low detail)
2. **Active Layer**: Current subgoal with full action history (high detail)
3. **Pending Layer**: Future subgoals as placeholders (no detail)

### Visual Representation

```
Task: Change car tire
├── Subgoal 1: Prepare tools ✓ (compressed)
│   └── Summary: "Retrieved jack and wrench from boot"
├── Subgoal 2: Loosen nuts ✓ (compressed)
│   └── Summary: "All 4 wheel nuts loosened"
├── Subgoal 3: Jack up car (current - full detail)
│   ├── Action: position_jack → Jack positioned
│   └── Action: pump_jack → Car lifted 10cm
└── Subgoal 4: Remove tire (pending)
```

**Memory Contents**:
- Compressed subgoals: ~40 tokens (summaries only)
- Current subgoal: ~100 tokens (full actions)
- **Total: 140 tokens** vs 400+ tokens (flat approach)

### Three-Component Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    HIAGENT MEMORY                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           SUBGOAL GENERATOR                          │   │
│  │  Task + Completed → Next logical subgoal             │   │
│  └──────────────────────┬──────────────────────────────┘   │
│                         ↓                                   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           ACTION GENERATOR                           │   │
│  │  Current subgoal + Recent actions → Next action      │   │
│  └──────────────────────┬──────────────────────────────┘   │
│                         ↓                                   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           SUMMARIZER                                 │   │
│  │  Completed subgoal + Actions → One-sentence summary  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### Key Principles

1. **Subgoal-Based Chunking**: Break tasks into 3-7 action segments
2. **Aggressive Compression**: 10:1 ratio (10 actions → 1 summary)
3. **Recency Bias**: Full detail for current work, summaries for completed
4. **Outcome Focus**: Summaries capture what was accomplished, not how

## Implementation Patterns

### Pattern 1: Basic HiAgent Memory Manager

**Use Case**: Single-agent tasks with clear subgoal boundaries

```typescript
interface SubgoalMemory {
  subgoal: string;
  summary: string;
  actionCount: number;
}

interface HiAgentMemory {
  completedSubgoals: SubgoalMemory[];
  currentSubgoal: string;
  recentActions: Array<{ action: string; observation: string }>;
  taskDescription: string;
  goalState: string;
}

class HiAgentMemoryManager {
  private memory: HiAgentMemory;
  private readonly maxRecentActions = 5;

  constructor(taskDescription: string, goalState: string) {
    this.memory = {
      completedSubgoals: [],
      currentSubgoal: '',
      recentActions: [],
      taskDescription,
      goalState,
    };
  }

  async processAction(action: string, observation: string): Promise<void> {
    this.memory.recentActions.push({ action, observation });

    // Sliding window for current subgoal
    if (this.memory.recentActions.length > this.maxRecentActions) {
      this.memory.recentActions.shift();
    }

    // Check if subgoal completed
    if (await this.isSubgoalComplete()) {
      await this.compressAndAdvance();
    }
  }

  getContext(): string {
    const completed = this.memory.completedSubgoals
      .map(sg => `✓ ${sg.subgoal}: ${sg.summary}`)
      .join('\n');

    const current = `Current: ${this.memory.currentSubgoal}`;
    const recent = this.memory.recentActions
      .map(a => `- ${a.action} → ${a.observation}`)
      .join('\n');

    return `Task: ${this.memory.taskDescription}\n\n${completed}\n\n${current}\n${recent}`;
  }
}
```

**Pros**:
- ✅ Simple implementation
- ✅ Bounded memory growth
- ✅ Works with any LLM

**Cons**:
- ❌ Requires LLM calls for subgoal detection
- ❌ Fixed window size may not fit all tasks

**When to Use**: Prototypes, single-domain tasks, clear subgoal boundaries

### Pattern 2: Adaptive Compression Triggers

**Use Case**: Variable task complexity requiring dynamic compression

```typescript
class AdaptiveHiAgent {
  private compressionThreshold = 0.8; // 80% context capacity
  private maxContextTokens = 8000;

  async processAction(action: string, observation: string): Promise<void> {
    // Normal processing
    this.recentActions.push({ action, observation });

    // Force compression if approaching context limit
    const usage = this.estimateTokenUsage() / this.maxContextTokens;

    if (usage > this.compressionThreshold) {
      await this.forceCompression();
    }
  }

  private async forceCompression(): Promise<void> {
    // Compress even if subgoal not complete
    const summary = await this.summarizeActions(this.recentActions);

    this.completedSubgoals.push({
      subgoal: `${this.currentSubgoal} (partial)`,
      summary,
      actionCount: this.recentActions.length,
    });

    this.recentActions = [];
  }
}
```

**Pros**:
- ✅ Handles variable task lengths
- ✅ Prevents context overflow
- ✅ Graceful degradation

**Cons**:
- ❌ May compress mid-subgoal
- ❌ Requires token estimation

**When to Use**: Production systems, unpredictable task lengths

### Pattern 3: Multi-Level Compression

**Use Case**: Very long tasks (50+ subgoals) requiring hierarchical summaries

```
Level 0: Individual actions (full detail)
Level 1: Subgoal summaries (10:1 compression)
Level 2: Phase summaries (50:1 compression)
Level 3: Task overview (100:1 compression)
```

```typescript
class MultiLevelHiAgent {
  private archiveThreshold = 10; // Archive after 10 subgoals

  async compressOldSubgoals(): Promise<void> {
    if (this.completedSubgoals.length >= this.archiveThreshold) {
      const oldSubgoals = this.completedSubgoals.slice(0, 5);
      const archiveSummary = await this.createArchiveSummary(oldSubgoals);

      // Replace 5 subgoals with 1 archive entry
      this.completedSubgoals = [
        {
          subgoal: 'Phase 1 (archived)',
          summary: archiveSummary,
          actionCount: oldSubgoals.reduce((sum, sg) => sum + sg.actionCount, 0),
        },
        ...this.completedSubgoals.slice(5),
      ];
    }
  }
}
```

**Pros**:
- ✅ Handles unlimited task length
- ✅ Preserves high-level context
- ✅ 50:1+ compression ratios

**Cons**:
- ❌ More complex implementation
- ❌ Higher information loss
- ❌ Additional LLM calls

**When to Use**: Research agents, multi-day tasks, audit-required workflows

## Framework Integration

### AI SDK v6 with HiAgent Memory

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { z } from 'zod';

const hiAgentMemory = new HiAgentMemoryManager(
  'Complete the support ticket',
  'Ticket resolved and customer satisfied'
);

// Tool that integrates with HiAgent memory
const executeAction = tool({
  description: 'Execute an action and observe the result',
  inputSchema: z.object({
    action: z.string().describe('The action to execute'),
  }),
  execute: async ({ action }) => {
    const observation = await performAction(action);

    // Update HiAgent memory
    await hiAgentMemory.processAction(action, observation);

    return { action, observation };
  },
});

// Generate next action using compressed context
async function getNextAction(): Promise<string> {
  const result = await generateText({
    model: openai('gpt-4o'),
    prompt: `${hiAgentMemory.getContext()}\n\nWhat is the next action?`,
    tools: { executeAction },
    stopWhen: stepCountIs(1),
  });

  return result.text;
}
```

### Subgoal Detection with generateObject

```typescript
import { generateObject } from 'ai';

async function detectSubgoalCompletion(
  subgoal: string,
  actions: Array<{ action: string; observation: string }>
): Promise<boolean> {
  const result = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: z.object({
      isComplete: z.boolean(),
      confidence: z.number().min(0).max(1),
      reasoning: z.string(),
    }),
    prompt: `
Subgoal: ${subgoal}

Recent actions:
${actions.map(a => `- ${a.action} → ${a.observation}`).join('\n')}

Has the subgoal been completed?
    `,
  });

  return result.object.isComplete && result.object.confidence > 0.8;
}
```

### Summarization Tool

```typescript
async function summarizeSubgoal(
  subgoal: string,
  actions: Array<{ action: string; observation: string }>
): Promise<string> {
  const result = await generateText({
    model: openai('gpt-4o-mini'),
    prompt: `
Subgoal: ${subgoal}

Actions taken:
${actions.map(a => `${a.action} → ${a.observation}`).join('\n')}

Summarize what was ACCOMPLISHED in ONE sentence.
Focus on the outcome, not individual actions.
    `,
    temperature: 0,
  });

  return result.text.trim();
}
```

## Research & Benchmarks

### HiAgent Performance (ACL 2025)

**Paper**: "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model"

| Task | Domain | Baseline | HiAgent | Improvement |
|------|--------|----------|---------|-------------|
| **Blocksworld** | Planning | 18% | 38% | **+111%** |
| **Gripper** | Robotics | 22% | 44% | **+100%** |
| **Tyreworld** | Automotive | 20% | 42% | **+110%** |
| **Barman** | Service | 25% | 46% | **+84%** |
| **Jericho** | Text Adventure | 19% | 40% | **+111%** |
| **Average** | Mixed | **21%** | **42%** | **+100%** |

### Efficiency Metrics

| Metric | Baseline | HiAgent | Improvement |
|--------|----------|---------|-------------|
| **Avg Steps** | 14.2 | 10.4 | **-27%** |
| **Context Tokens** | 5,000+ | 3,250 | **-35%** |
| **Compression Ratio** | 1:1 | 10:1 | **10×** |

### Why Performance Improves

Research findings explain the improvements:

1. **Reduced Cognitive Load**: LLM focuses on current subgoal, not entire history
2. **Better Planning**: Explicit subgoals provide structure and direction
3. **Fewer Errors**: Less context → less confusion → more accurate actions
4. **Relevant Information**: Summaries preserve task-critical info, discard noise

### Comparison with Other Approaches

| Approach | Success Rate | Tokens | Latency | Complexity |
|----------|--------------|--------|---------|------------|
| **Flat Memory** | 21% | 5,000+ | High | Low |
| **HiAgent** | 42% | 3,250 | Medium | Medium |
| **RAG Memory** | ~35% | Variable | High | High |
| **MemGPT (Paging)** | ~38% | Variable | Very High | Very High |

## When to Use This Pattern

### ✅ Use When:

1. **Long-horizon tasks** (10+ actions)
   - Multi-step workflows
   - Complex problem-solving

2. **Bounded context needed**
   - Cost control requirements
   - Smaller models with limited context

3. **Clear subgoal structure**
   - Tasks naturally decompose into phases
   - Intermediate milestones exist

4. **Deterministic outcomes**
   - Each subgoal has clear success criteria
   - Progress is measurable

### ❌ Don't Use When:

1. **Short tasks** (<5 actions)
   - Overhead exceeds benefit
   - Use flat memory instead

2. **Highly interconnected context**
   - Every action depends on all previous
   - Summarization loses critical details

3. **Real-time requirements**
   - Additional LLM calls add latency
   - Use simpler sliding window

4. **Cross-session continuity needed**
   - HiAgent is session-scoped
   - Use persistent memory instead

### Decision Matrix

| Your Situation | Recommended Approach |
|----------------|---------------------|
| Task <10 actions | Flat sliding window |
| Task 10-50 actions | Basic HiAgent |
| Task 50+ actions | Multi-level HiAgent |
| Unpredictable length | Adaptive compression |
| Cross-session | HiAgent + persistent storage |

## Production Best Practices

### 1. Size Subgoals Appropriately

**Target: 3-7 actions per subgoal**

```
Too small (1-2 actions): Excessive overhead, poor summaries
Optimal (3-7 actions): Good compression, meaningful summaries
Too large (10+ actions): Loses benefits, context still grows
```

### 2. Monitor Compression Quality

Track summary quality metrics:

| Metric | Target | Alert |
|--------|--------|-------|
| Summary length | 20-50 tokens | >100 tokens |
| Compression ratio | 8:1 - 12:1 | <5:1 |
| Information retention | >80% | <60% |

### 3. Handle Edge Cases

**Subgoal never completes**:
```typescript
const MAX_ACTIONS_PER_SUBGOAL = 10;

if (recentActions.length >= MAX_ACTIONS_PER_SUBGOAL) {
  // Force compression even if not complete
  await forceCompression();
  // Generate new subgoal
  currentSubgoal = await generateSubgoal();
}
```

**Subgoal completes immediately**:
```typescript
const MIN_ACTIONS_PER_SUBGOAL = 2;

if (recentActions.length < MIN_ACTIONS_PER_SUBGOAL) {
  // Merge with next subgoal instead of compressing
  currentSubgoal = `${currentSubgoal} + ${nextSubgoal}`;
}
```

### 4. Common Pitfalls

#### ❌ Pitfall: Over-aggressive Compression

**Problem**: Compressing too early loses important context for current work.

**Solution**: Ensure minimum action count before compression:
```typescript
// Only compress after meaningful work
if (recentActions.length >= 3 && isSubgoalComplete) {
  await compress();
}
```

#### ❌ Pitfall: Poor Summary Quality

**Problem**: Vague summaries like "Did some work" lose critical information.

**Solution**: Use structured prompts requiring specific outcomes:
```
BAD:  "Summarize what happened"
GOOD: "What was ACCOMPLISHED? Include: entities modified, state changes, measurable outcomes"
```

## Key Takeaways

1. **Hierarchical memory mimics human cognition** - We remember accomplishments, not every action
2. **10:1 compression is achievable** - Subgoal summaries drastically reduce context
3. **2× success rate improvement** - Less context means better model focus
4. **Target 3-7 actions per subgoal** - Optimal granularity for compression
5. **Force compression when needed** - Don't let context overflow waiting for subgoal completion

**Quick Implementation Checklist**:

- [ ] Define subgoal detection criteria
- [ ] Implement sliding window for current actions
- [ ] Create summarization prompts (outcome-focused)
- [ ] Set compression thresholds (80% capacity)
- [ ] Add monitoring for compression ratio
- [ ] Handle edge cases (stuck subgoals, immediate completion)

## References

1. **Hu, M., Chen, T., et al.** (2025). "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model". *ACL 2025*. https://aclanthology.org/2025.acl-long.1575.pdf
2. **HiAgent GitHub Repository** (2024). https://github.com/HiAgent2024/HiAgent
3. **LangChain** (2025). "Context Engineering for Agents". https://blog.langchain.dev/context-engineering-for-agents/
4. **Anthropic** (2025). "Effective Context Engineering for AI Agents". https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents
5. **Packer, C. et al.** (2023). "MemGPT: Towards LLMs as Operating Systems". *arXiv:2310.08560*.
6. **Liu, N. et al.** (2024). "Lost in the Middle: How Language Models Use Long Contexts". *arXiv:2307.03172*.

**Related Topics**:

- [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- [4.2.2 Compression Triggers](./4.2.2-compression-triggers.md)
- [4.2.3 Subgoal Detection](./4.2.3-subgoal-detection.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
