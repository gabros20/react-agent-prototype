# 4.2.1 HiAgent: Hierarchical Working Memory Management

**Status**: ‚úÖ Complete  
**Last Updated**: 2025-11-18  
**Research Sources**: 20+ papers and production systems (2024-2025)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [The Memory Problem in LLM Agents](#the-memory-problem-in-llm-agents)
3. [HiAgent Architecture](#hiagent-architecture)
4. [Performance Results](#performance-results)
5. [How HiAgent Works](#how-hiagent-works)
6. [Implementation in TypeScript](#implementation-in-typescript)
7. [Production Patterns](#production-patterns)
8. [Comparison with Other Approaches](#comparison-with-other-approaches)
9. [References](#references)

---

## Executive Summary

**HiAgent** is a hierarchical working memory management framework introduced in ACL 2025 that achieves **2x success rate improvement** and **35% token reduction** in long-horizon agent tasks by using subgoals as memory chunks.[^1][^2]

### Key Innovation

Instead of keeping all action-observation pairs in context, HiAgent:
1. Prompts agents to generate **subgoals** before actions
2. **Compresses completed subgoals** into summaries
3. Retains only **relevant recent actions** in working memory

### Performance Impact

| Metric | Without HiAgent | With HiAgent | Improvement |
|--------|----------------|--------------|-------------|
| **Success Rate** | 21% | 42% | **+100%** (2x) |
| **Avg Steps** | 14.2 | 10.4 | **-3.8 steps** |
| **Context Tokens** | 5000+ | 3250 | **-35%** |
| **Compression Ratio** | N/A | 10:1 | **10:1** |

*Results across 5 long-horizon tasks: Blocksworld, Gripper, Tyreworld, Barman, Jericho*[^1][^3]

### Why It Matters

**90% of long-running agents fail due to memory issues**[^4]. HiAgent solves this by mimicking human cognitive strategies‚Äîwe don't remember every action, we remember **what we accomplished** (subgoals).

---

## The Memory Problem in LLM Agents

### Traditional Approach: Flat Action History

```typescript
// Problem: Context grows linearly with task length
const context = [
  "Action 1: open_boot ‚Üí Boot opened",
  "Action 2: locate_jack ‚Üí Jack found in boot",
  "Action 3: retrieve_jack ‚Üí Jack retrieved",
  "Action 4: locate_wrench ‚Üí Wrench found in toolbox",
  "Action 5: retrieve_wrench ‚Üí Wrench retrieved",
  // ... 50+ more actions
  "Action 55: tighten_nut4 ‚Üí All nuts tightened"
];

// Context size: 55 actions √ó 50 tokens = 2,750 tokens
// Problem: Exceeds context window, high cost, slow inference
```

**Key Issues**:[^5][^6]
1. **Context Overflow**: Long tasks exceed LLM context windows (8K-128K tokens)
2. **High Costs**: Every action adds 50-100 tokens, exponential growth
3. **Degraded Performance**: LLMs struggle with "lost in the middle" problem[^7]
4. **No Abstraction**: All details retained, no hierarchical understanding

### Research Evidence

- **Context Rot**: Model accuracy drops from 90% to 60% when context exceeds 80% capacity[^8]
- **Memory Failures**: 73% of production failures stem from poor context management[^9]
- **Latency Issues**: Longer contexts ‚Üí 2-5x slower inference[^10]

---

## HiAgent Architecture

### Core Concept: Subgoal-Based Memory Chunks

HiAgent organizes memory **hierarchically** using subgoals as organizational units[^1][^11]:

```
Task: Change car tire
‚îú‚îÄ‚îÄ Subgoal 1: Prepare tools ‚úì (compressed)
‚îÇ   ‚îî‚îÄ‚îÄ Summary: "Retrieved jack and wrench from boot"
‚îú‚îÄ‚îÄ Subgoal 2: Loosen nuts ‚úì (compressed)
‚îÇ   ‚îî‚îÄ‚îÄ Summary: "All 4 wheel nuts loosened"
‚îú‚îÄ‚îÄ Subgoal 3: Jack up car (current)
‚îÇ   ‚îú‚îÄ‚îÄ Action 1: position_jack ‚Üí Jack positioned
‚îÇ   ‚îî‚îÄ‚îÄ Action 2: pump_jack ‚Üí Car lifted 10cm
‚îî‚îÄ‚îÄ Subgoal 4: Remove tire (pending)
```

**Memory Contents**:
- **Compressed**: Subgoals 1-2 (summaries only) = 40 tokens
- **Detailed**: Subgoal 3 (full actions) = 100 tokens
- **Total**: 140 tokens vs 400 tokens (flat) = **65% reduction**

### Three-Component System

#### 1. Subgoal Generator
```typescript
async function generateSubgoal(
  taskDescription: string,
  completedSubgoals: string[],
  currentState: string
): Promise<string> {
  const prompt = `
Task: ${taskDescription}

Completed subgoals:
${completedSubgoals.map(s => `‚úì ${s}`).join('\n')}

Current state: ${currentState}

What should be the NEXT subgoal to work towards completing the task?
Generate a specific, actionable subgoal (one sentence).
  `.trim();

  const result = await generateText({
    model: openai('gpt-4o-mini'),
    prompt
  });

  return result.text.trim();
}
```

#### 2. Action Generator (Operating on Current Subgoal)
```typescript
async function generateAction(
  currentSubgoal: string,
  recentActions: Array<{ action: string; observation: string }>,
  availableActions: string[]
): Promise<string> {
  const prompt = `
Current subgoal: ${currentSubgoal}

Recent actions:
${recentActions.map(a => `${a.action} ‚Üí ${a.observation}`).join('\n')}

Available actions: ${availableActions.join(', ')}

What is the NEXT action to achieve the current subgoal?
Respond with just the action name.
  `.trim();

  const result = await generateText({
    model: openai('gpt-4o-mini'),
    prompt
  });

  return result.text.trim();
}
```

#### 3. Summarizer (Compressing Completed Subgoals)
```typescript
async function summarizeSubgoal(
  subgoal: string,
  actions: Array<{ action: string; observation: string }>
): Promise<string> {
  const prompt = `
Subgoal: ${subgoal}

Actions taken:
${actions.map(a => `${a.action} ‚Üí ${a.observation}`).join('\n')}

Summarize what was ACCOMPLISHED in ONE sentence.
Focus on the outcome, not individual actions.
  `.trim();

  const result = await generateText({
    model: openai('gpt-4o-mini'),
    prompt
  });

  return result.text.trim();
}
```

### Memory Structure

```typescript
interface HiAgentMemory {
  // Compressed memory (long-term within trial)
  completedSubgoals: Array<{
    subgoal: string;
    summary: string;
    actions: number; // Count only
  }>;
  
  // Active working memory
  currentSubgoal: string;
  recentActions: Array<{
    action: string;
    observation: string;
  }>;
  
  // Task context
  taskDescription: string;
  goalState: string;
}

// Example state during execution
const memory: HiAgentMemory = {
  completedSubgoals: [
    {
      subgoal: "Prepare tools",
      summary: "Retrieved jack and wrench from boot",
      actions: 5
    },
    {
      subgoal: "Loosen all nuts",
      summary: "All 4 wheel nuts loosened successfully",
      actions: 4
    }
  ],
  currentSubgoal: "Jack up the car",
  recentActions: [
    { action: "position_jack", observation: "Jack positioned under car" },
    { action: "pump_jack", observation: "Car lifted 10cm off ground" }
  ],
  taskDescription: "Change the car tire",
  goalState: "Spare tire mounted, all nuts tightened, car on ground"
};

// Token count:
// - Completed subgoals: 2 √ó 20 tokens = 40 tokens
// - Current subgoal: 5 tokens
// - Recent actions: 2 √ó 25 tokens = 50 tokens
// - Task context: 30 tokens
// Total: 125 tokens (vs 450 tokens for all 11 actions flat)
```

---

## Performance Results

### Benchmarked Tasks (ACL 2025)[^1]

| Task | Domain | Baseline Success | HiAgent Success | Improvement |
|------|--------|------------------|-----------------|-------------|
| **Blocksworld** | Planning | 18% | 38% | **+111%** |
| **Gripper** | Robotics | 22% | 44% | **+100%** |
| **Tyreworld** | Automotive | 20% | 42% | **+110%** |
| **Barman** | Service | 25% | 46% | **+84%** |
| **Jericho** | Text adventure | 19% | 40% | **+111%** |
| **Average** | Mixed | **21%** | **42%** | **+100%** |

### Efficiency Metrics

**Steps Reduction**:[^2]
- Baseline (flat memory): 14.2 average steps to completion
- HiAgent: 10.4 average steps (**-3.8 steps, 27% faster**)

**Context Length Reduction**:[^1]
- Baseline: 5,000-7,000 tokens per task
- HiAgent: 3,250-4,500 tokens (**-35% average**)

**Compression Ratio**:[^1][^3]
- Average: **10:1** (10 actions ‚Üí 1 summary ~50 tokens)
- Range: 9.6:1 (Jericho) to 13.8:1 (Gripper)

### Why Performance Improves

**Research Findings**:[^12][^13]
1. **Reduced Cognitive Load**: LLM focuses on current subgoal, not entire history
2. **Better Planning**: Explicit subgoals provide structure and direction
3. **Fewer Errors**: Less context ‚Üí less confusion ‚Üí more accurate actions
4. **Relevant Information**: Summaries preserve task-critical info, discard noise

---

## How HiAgent Works

### Step-by-Step Execution

```typescript
class HiAgent {
  private memory: HiAgentMemory;
  
  async executeTask(taskDescription: string, goalState: string): Promise<void> {
    this.memory = {
      completedSubgoals: [],
      currentSubgoal: '',
      recentActions: [],
      taskDescription,
      goalState
    };

    while (!this.isGoalAchieved()) {
      // Step 1: Generate new subgoal if needed
      if (this.shouldGenerateNewSubgoal()) {
        await this.generateNextSubgoal();
      }

      // Step 2: Generate and execute action
      const action = await this.generateAction();
      const observation = await this.environment.execute(action);
      this.memory.recentActions.push({ action, observation });

      // Step 3: Check if subgoal completed
      if (await this.isSubgoalCompleted()) {
        await this.compressCompletedSubgoal();
      }
    }
  }

  private shouldGenerateNewSubgoal(): boolean {
    // Generate new subgoal if:
    // 1. No current subgoal, OR
    // 2. Current subgoal completed (just compressed)
    return this.memory.currentSubgoal === '';
  }

  private async generateNextSubgoal(): Promise<void> {
    const newSubgoal = await generateSubgoal(
      this.memory.taskDescription,
      this.memory.completedSubgoals.map(sg => sg.subgoal),
      this.getCurrentState()
    );
    this.memory.currentSubgoal = newSubgoal;
  }

  private async generateAction(): Promise<string> {
    return await generateAction(
      this.memory.currentSubgoal,
      this.memory.recentActions.slice(-3), // Last 3 actions only
      this.environment.getAvailableActions()
    );
  }

  private async isSubgoalCompleted(): Promise<boolean> {
    // Use LLM to determine if subgoal is achieved
    const prompt = `
Subgoal: ${this.memory.currentSubgoal}

Recent actions:
${this.memory.recentActions.map(a => `${a.action} ‚Üí ${a.observation}`).join('\n')}

Has the subgoal been achieved? Respond with YES or NO.
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt
    });

    return result.text.toLowerCase().includes('yes');
  }

  private async compressCompletedSubgoal(): Promise<void> {
    // Compress current subgoal into summary
    const summary = await summarizeSubgoal(
      this.memory.currentSubgoal,
      this.memory.recentActions
    );

    // Move to completed subgoals
    this.memory.completedSubgoals.push({
      subgoal: this.memory.currentSubgoal,
      summary,
      actions: this.memory.recentActions.length
    });

    // Clear current subgoal and actions
    this.memory.currentSubgoal = '';
    this.memory.recentActions = [];

    console.log(`‚úì Subgoal completed and compressed: ${summary}`);
  }
}
```

### Compression Example

**Before Compression** (9 actions, ~450 tokens):
```
Subgoal: Prepare tools
1. open_boot ‚Üí Boot opened
2. locate_jack ‚Üí Jack found in boot compartment
3. retrieve_jack ‚Üí Jack retrieved and placed on ground
4. locate_wrench ‚Üí Wrench found in toolbox
5. retrieve_wrench ‚Üí Wrench retrieved
6. check_jack ‚Üí Jack is functional
7. check_wrench ‚Üí Wrench size matches nuts
8. close_toolbox ‚Üí Toolbox closed
9. position_tools ‚Üí Tools positioned near wheel
```

**After Compression** (~30 tokens):
```
‚úì Prepare tools: "Retrieved and verified jack and wrench from boot, positioned near wheel"
```

**Compression**: 450 tokens ‚Üí 30 tokens = **15:1 ratio**

---

## Implementation in TypeScript

### Complete Production-Ready Implementation

```typescript
// hi-agent.ts
import { generateText } from 'ai';
import { openai } from '@ai-sdk/openai';

export interface SubgoalMemory {
  subgoal: string;
  summary: string;
  actionCount: number;
}

export interface Action {
  action: string;
  observation: string;
}

export class HiAgentMemoryManager {
  private completedSubgoals: SubgoalMemory[] = [];
  private currentSubgoal: string = '';
  private recentActions: Action[] = [];
  private readonly maxRecentActions = 5; // Keep last 5 for current subgoal

  constructor(
    private taskDescription: string,
    private goalState: string
  ) {}

  async start(): Promise<void> {
    // Generate initial subgoal
    this.currentSubgoal = await this.generateSubgoal();
    console.log(`üéØ Starting subgoal: ${this.currentSubgoal}`);
  }

  async processAction(action: string, observation: string): Promise<void> {
    // Add to recent actions
    this.recentActions.push({ action, observation });

    // Keep only most recent N actions
    if (this.recentActions.length > this.maxRecentActions) {
      this.recentActions.shift();
    }

    // Check if subgoal completed
    if (await this.checkSubgoalCompletion()) {
      await this.compressAndAdvance();
    }
  }

  private async generateSubgoal(): Promise<string> {
    const prompt = `
Task: ${this.taskDescription}
Goal: ${this.goalState}

Completed subgoals:
${this.completedSubgoals.map(sg => `‚úì ${sg.subgoal}`).join('\n') || 'None yet'}

Generate the NEXT logical subgoal to work towards the goal.
Respond with ONLY the subgoal (one sentence).
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt
    });

    return result.text.trim();
  }

  private async checkSubgoalCompletion(): Promise<boolean> {
    // Need at least 2 actions to determine completion
    if (this.recentActions.length < 2) {
      return false;
    }

    const prompt = `
Subgoal: ${this.currentSubgoal}

Recent actions:
${this.recentActions.map(a => `- ${a.action} ‚Üí ${a.observation}`).join('\n')}

Has the subgoal been completed? 
Respond with ONLY: YES or NO
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt,
      temperature: 0 // Deterministic
    });

    return result.text.toLowerCase().trim() === 'yes';
  }

  private async compressAndAdvance(): Promise<void> {
    // Compress completed subgoal
    const summary = await this.summarizeActions();

    this.completedSubgoals.push({
      subgoal: this.currentSubgoal,
      summary,
      actionCount: this.recentActions.length
    });

    console.log(`‚úÖ Completed: ${this.currentSubgoal}`);
    console.log(`   Summary: ${summary}`);

    // Clear working memory
    this.recentActions = [];

    // Generate next subgoal
    this.currentSubgoal = await this.generateSubgoal();
    console.log(`üéØ Next subgoal: ${this.currentSubgoal}`);
  }

  private async summarizeActions(): Promise<string> {
    const prompt = `
Subgoal: ${this.currentSubgoal}

Actions taken:
${this.recentActions.map(a => `${a.action} ‚Üí ${a.observation}`).join('\n')}

Summarize what was ACCOMPLISHED in ONE concise sentence.
Focus on the outcome, not the process.
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt
    });

    return result.text.trim();
  }

  // Get context for LLM (compressed memory + current work)
  getContext(): string {
    const completed = this.completedSubgoals
      .map(sg => `‚úì ${sg.subgoal}: ${sg.summary}`)
      .join('\n');

    const current = `Current subgoal: ${this.currentSubgoal}`;

    const recent = this.recentActions.length > 0
      ? `Recent actions:\n${this.recentActions.map(a => `- ${a.action} ‚Üí ${a.observation}`).join('\n')}`
      : '';

    return `
Task: ${this.taskDescription}
Goal: ${this.goalState}

${completed}

${current}
${recent}
    `.trim();
  }

  // Get statistics
  getStats(): {
    completedSubgoals: number;
    totalActions: number;
    currentActions: number;
    estimatedTokensSaved: number;
  } {
    const totalActions = this.completedSubgoals.reduce((sum, sg) => sum + sg.actionCount, 0)
      + this.recentActions.length;

    // Estimate: Each action-observation pair ‚âà 50 tokens
    // Each summary ‚âà 30 tokens
    // Savings = (actions √ó 50) - (summaries √ó 30)
    const withoutCompression = totalActions * 50;
    const withCompression = this.completedSubgoals.length * 30
      + this.recentActions.length * 50;
    const saved = withoutCompression - withCompression;

    return {
      completedSubgoals: this.completedSubgoals.length,
      totalActions,
      currentActions: this.recentActions.length,
      estimatedTokensSaved: saved
    };
  }
}
```

### Usage Example

```typescript
// example-usage.ts
import { HiAgentMemoryManager } from './hi-agent';

async function changeCarTire() {
  const agent = new HiAgentMemoryManager(
    'Change the car tire',
    'Spare tire mounted, all nuts tightened, car on ground'
  );

  await agent.start();

  // Simulate task execution
  const actions = [
    // Subgoal 1: Prepare tools
    { action: 'open_boot', observation: 'Boot opened' },
    { action: 'get_jack', observation: 'Jack retrieved' },
    { action: 'get_wrench', observation: 'Wrench retrieved' },
    
    // Subgoal 2: Loosen nuts
    { action: 'loosen_nut1', observation: 'Nut 1 loosened' },
    { action: 'loosen_nut2', observation: 'Nut 2 loosened' },
    { action: 'loosen_nut3', observation: 'Nut 3 loosened' },
    { action: 'loosen_nut4', observation: 'Nut 4 loosened' },
    
    // Subgoal 3: Jack up car
    { action: 'position_jack', observation: 'Jack positioned' },
    { action: 'pump_jack', observation: 'Car lifted off ground' },
    
    // ... more actions
  ];

  for (const { action, observation } of actions) {
    await agent.processAction(action, observation);
    
    // Get current context for next action
    const context = agent.getContext();
    console.log('\n--- Current Context ---');
    console.log(context);
  }

  // Print statistics
  const stats = agent.getStats();
  console.log('\n--- Final Statistics ---');
  console.log(`Completed subgoals: ${stats.completedSubgoals}`);
  console.log(`Total actions: ${stats.totalActions}`);
  console.log(`Tokens saved: ${stats.estimatedTokensSaved}`);
}

changeCarTire();
```

---

## Production Patterns

### Pattern 1: Adaptive Compression Triggers

```typescript
class AdaptiveHiAgent extends HiAgentMemoryManager {
  private compressionThreshold = 0.8; // Compress at 80% context capacity

  async processAction(action: string, observation: string): Promise<void> {
    await super.processAction(action, observation);

    // Force compression if approaching context limit
    const contextUsage = this.estimateContextUsage();
    if (contextUsage > this.compressionThreshold) {
      console.warn(`‚ö†Ô∏è Context usage at ${contextUsage * 100}%, forcing compression`);
      await this.forceCompression();
    }
  }

  private estimateContextUsage(): number {
    const currentTokens = this.estimateCurrentTokens();
    const maxTokens = 8000; // Model context window
    return currentTokens / maxTokens;
  }

  private async forceCompression(): Promise<void> {
    if (this.recentActions.length > 0) {
      // Compress current subgoal even if not complete
      const summary = await this.summarizeActions();
      this.completedSubgoals.push({
        subgoal: this.currentSubgoal + ' (partial)',
        summary,
        actionCount: this.recentActions.length
      });
      this.recentActions = [];
    }
  }
}
```

### Pattern 2: Multi-Level Compression

```typescript
class MultiLevelHiAgent extends HiAgentMemoryManager {
  private archiveThreshold = 10; // Archive after 10 completed subgoals

  async compressOldSubgoals(): Promise<void> {
    if (this.completedSubgoals.length >= this.archiveThreshold) {
      // Compress old subgoals into higher-level summary
      const oldSubgoals = this.completedSubgoals.slice(0, 5);
      const archiveSummary = await this.createArchiveSummary(oldSubgoals);
      
      // Replace with archived summary
      this.completedSubgoals = [
        {
          subgoal: 'Archive (first 5 subgoals)',
          summary: archiveSummary,
          actionCount: oldSubgoals.reduce((sum, sg) => sum + sg.actionCount, 0)
        },
        ...this.completedSubgoals.slice(5)
      ];

      console.log(`üì¶ Archived 5 subgoals: ${archiveSummary}`);
    }
  }

  private async createArchiveSummary(subgoals: SubgoalMemory[]): Promise<string> {
    const prompt = `
Summarize these completed subgoals into ONE sentence:
${subgoals.map(sg => `${sg.subgoal}: ${sg.summary}`).join('\n')}

Provide a high-level summary of what was accomplished overall.
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt
    });

    return result.text.trim();
  }
}
```

### Pattern 3: Error Recovery with Memory

```typescript
class RobustHiAgent extends HiAgentMemoryManager {
  async handleActionFailure(
    action: string,
    error: string
  ): Promise<string> {
    // Use memory to inform retry strategy
    const context = this.getContext();
    
    const prompt = `
${context}

FAILED ACTION: ${action}
Error: ${error}

Given the context and failure, what should be the NEXT action?
Consider what has already been accomplished.
    `.trim();

    const result = await generateText({
      model: openai('gpt-4o-mini'),
      prompt
    });

    return result.text.trim();
  }
}
```

---

## Comparison with Other Approaches

### vs. Standard (Flat) Memory[^1]

| Metric | Standard | HiAgent | Winner |
|--------|----------|---------|--------|
| Success Rate | 21% | 42% | **HiAgent (+100%)** |
| Context Tokens | 5000+ | 3250 | **HiAgent (-35%)** |
| Steps to Complete | 14.2 | 10.4 | **HiAgent (-27%)** |
| Memory Scalability | Poor (linear growth) | Good (bounded) | **HiAgent** |

### vs. RAG-Based Memory[^14][^15]

| Aspect | RAG Memory | HiAgent | Difference |
|--------|------------|---------|------------|
| **Storage** | Vector DB (external) | In-context (compressed) | HiAgent = simpler |
| **Retrieval** | Semantic search | Hierarchical structure | HiAgent = faster |
| **Cost** | DB + embeddings | LLM only | HiAgent = cheaper |
| **Latency** | 50-200ms per query | 0ms (already in context) | HiAgent = instant |
| **Best For** | Cross-session memory | Within-session tasks | Different use cases |

### vs. Optimus-1 (Hybrid Memory)[^16]

**Optimus-1** combines knowledge graphs with abstracted experience pools:
- **Strengths**: Better for complex multi-modal tasks (Minecraft)
- **Complexity**: Requires graph construction + experience abstraction
- **HiAgent Advantage**: Simpler, works with any LLM, no external storage

### vs. MemGPT (Paging)[^17]

**MemGPT** uses OS-like paging (swap to external storage):
- **Strengths**: Handles indefinite memory
- **Latency**: Swapping adds 100-500ms per page fault
- **HiAgent Advantage**: No external I/O, faster for medium-length tasks

---

## References

### Research Papers

[^1]: Hu, M., Chen, T., et al. (2025). "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model." *ACL 2025*. https://aclanthology.org/2025.acl-long.1575.pdf

[^2]: HiAgent GitHub Repository (2024). https://github.com/HiAgent2024/HiAgent

[^3]: Hu, M. et al. (2024). "HiAgent: Hierarchical Working Memory Management for LLMs." *arXiv:2408.09559*. https://arxiv.org/abs/2408.09559

[^4]: "The Technical Reality of Production AI Agents." *AgentDock* (2024). https://agentdock.ai/docs/ai-agents-book/chapter-02-technical-reality

[^5]: "Context Engineering for Agents." *LangChain Blog* (2025). https://blog.langchain.com/context-engineering-for-agents/

[^6]: "Deep Dive into Context Engineering for Agents." *Galileo AI* (2025). https://galileo.ai/blog/context-engineering-for-agents

[^7]: Liu, N. et al. (2024). "Lost in the Middle: How Language Models Use Long Contexts." *arXiv:2307.03172*.

[^8]: "Effective Context Engineering for AI Agents." *Anthropic Engineering* (2025). https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents

[^9]: Ghosh, B. (2025). "Optimizing AI Agent Framework with Context Engineering." *Medium*. https://medium.com/@bijit211987/optimizing-any-ai-agent-framework-with-context-engineering

[^10]: Nawrot, P. et al. (2024). "Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference." *ICML 2024*. https://arxiv.org/abs/2403.09636

[^11]: "Memory Mechanisms in LLM Agents." *EmergentMind* (2025). https://www.emergentmind.com/topics/memory-mechanisms-in-llm-based-agents

[^12]: Wang, K. et al. (2025). "Cognitive-inspired xLSTM for multi-agent information retrieval." *Nature Scientific Reports*. https://www.nature.com/articles/s41598-025-19628-w

[^13]: Hou, Y., Tamoto, H., & Miyashita, H. (2024). "My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents." *CHI 2024*. https://arxiv.org/abs/2404.00573

[^14]: Balarabe, T. (2025). "DeepSeek OCR AI Memory Compression Breakthrough." *Medium*. https://medium.com/@tahirbalarabe2/deepseek-ocr-ai-memory-compression-breakthrough

[^15]: Rodriguez, J. (2025). "The Future of Memory Is Visual: Inside DeepSeek-OCR." *The Sequence*. https://thesequence.substack.com/p/the-sequence-ai-of-the-week-745-the

[^16]: Hu, J. et al. (2024). "Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks." *arXiv:2408.03615*. https://arxiv.org/abs/2408.03615

[^17]: Packer, C. et al. (2023). "MemGPT: Towards LLMs as Operating Systems." *arXiv:2310.08560*.

### Additional Resources

- "Building Smarter AI Agents: AgentCore Long-term Memory." *AWS Machine Learning Blog* (2025). https://aws.amazon.com/blogs/machine-learning/building-smarter-ai-agents-agentcore

- "Advanced Memory Compression Techniques for AI in 2025." *Sparkco AI* (2025). https://sparkco.ai/blog/advanced-memory-compression-techniques-for-ai-in-2025

- "Why Multi-Agent Systems Need Memory Engineering." *MongoDB Blog* (2025). https://www.mongodb.com/company/blog/technical/why-multi-agent-systems-need-memory-engineering

- "HiPlan: Hierarchical Planning for LLM-Based Agents." *arXiv:2508.19076* (2025). https://arxiv.org/abs/2508.19076

- "RoboMemory: A Brain-inspired Multi-memory Agentic Framework." *arXiv:2508.01415* (2024). https://arxiv.org/html/2508.01415v2

---

**Next Topic**: [4.2.2 Compression Triggers](./4.2.2-compression-triggers.md)

**Related Topics**:
- [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- [4.2.3 Subgoal Detection](./4.2.3-subgoal-detection.md)
- [6.1 Plan-and-Execute Pattern](../6-planning/6.1.1-separation.md)
