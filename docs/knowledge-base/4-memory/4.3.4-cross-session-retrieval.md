# 4.3.4 - Cross-Session Retrieval

## TL;DR

**Cross-session retrieval enables AI agents to recall and utilize information from previous conversations, transforming stateless systems into persistent, context-aware agents.** This achieves 30% accuracy improvement for returning users and 91% latency reduction compared to passing full conversation history.

- **Status**: ‚úÖ Complete
- **Last Updated**: 2025-12-12
- **Prerequisites**: [4.3.1 Vector Databases](./4.3.1-vector-databases.md), [4.3.3 Fact Extraction](./4.3.3-fact-extraction.md)
- **Grounded In**: Mem0 (2025), LongMemEval, A-MEM, Zep research (2024-2025)

## Table of Contents

- [Overview](#overview)
- [The Problem: Stateless AI](#the-problem-stateless-ai)
- [Core Concept](#core-concept)
- [Implementation Patterns](#implementation-patterns)
- [Framework Integration](#framework-integration)
- [Research & Benchmarks](#research--benchmarks)
- [When to Use This Pattern](#when-to-use-this-pattern)
- [Production Best Practices](#production-best-practices)
- [Key Takeaways](#key-takeaways)
- [References](#references)

---

## Overview

Cross-session retrieval allows agents to remember and apply information from previous interactions across multiple conversation sessions. This transforms AI from a "goldfish memory" experience to a persistent, personalized assistant that knows users over time.

**Key Difference**:
- **Single-Session**: Remembers only current conversation (context window)
- **Cross-Session**: Remembers across all past conversations (persistent storage)

**Key Research Findings (2024-2025)**:

- **LongMemEval**: 30% accuracy drop for AI assistants without cross-session memory
- **A-MEM**: 18.5% accuracy improvement with proper memory management
- **Mem0**: 91% latency reduction vs full conversation history
- **Zep**: Temporal knowledge graphs for memory organization

---

## The Problem: Stateless AI

### The Classic Challenge

Without cross-session memory, every session starts fresh:

```
Session 1 (Monday):
User: "I prefer dark mode and I'm allergic to peanuts."
Agent: "Got it! I'll remember that."

Session 50 (Two weeks later):
User: "Recommend a lunch spot."
Agent: "What kind of food do you like? Any allergies?"
User: "I ALREADY TOLD YOU!" üò§
```

**Problems**:

- ‚ùå **Context amnesia**: User must re-explain preferences every session
- ‚ùå **No personalization**: Can't build on previous interactions
- ‚ùå **Broken trust**: Users expect AI to remember important information
- ‚ùå **Inefficiency**: Wasted tokens re-establishing context

### Why This Matters

Cross-session memory enables:
- Remember user preferences from weeks/months ago
- Continue tasks across sessions without re-explanation
- Build long-term relationships with users
- Provide personalized responses based on history

---

## Core Concept

### Three-Tier Memory Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TIER 1: WORKING MEMORY (Current Session)                   ‚îÇ
‚îÇ  - Duration: 30 min - 24 hours                              ‚îÇ
‚îÇ  - Storage: In-memory (Redis, local state)                  ‚îÇ
‚îÇ  - Content: Conversation history, temporary entities        ‚îÇ
‚îÇ  - TTL: Session timeout                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì (Extract & Compress)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TIER 2: EPISODIC MEMORY (Recent Sessions)                  ‚îÇ
‚îÇ  - Duration: 7-30 days                                      ‚îÇ
‚îÇ  - Storage: Vector DB + Key-Value                           ‚îÇ
‚îÇ  - Content: Recent facts, events, interactions              ‚îÇ
‚îÇ  - TTL: 30-90 days (configurable)                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì (Consolidate & Index)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TIER 3: SEMANTIC MEMORY (Long-Term)                        ‚îÇ
‚îÇ  - Duration: Months to years                                ‚îÇ
‚îÇ  - Storage: Vector DB + Graph DB                            ‚îÇ
‚îÇ  - Content: Core preferences, relationships, facts          ‚îÇ
‚îÇ  - TTL: Indefinite or manual deletion                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Session Isolation with Namespaces

```typescript
interface SessionIdentifier {
  user_id: string;
  session_id: string;
  timestamp: string;
}

// Store memory with session metadata
await memory.add(fact, {
  user_id: 'user_123',
  session_id: 'sess_2025-12-12_001',
  timestamp: '2025-12-12T10:00:00Z',
});

// Retrieve across ALL sessions for user
const memories = await memory.search(query, {
  user_id: 'user_123', // Filter by user only
  // session_id omitted ‚Üí search all sessions
});
```

---

## Implementation Patterns

### Pattern 1: Session-Scoped Storage

**Use Case**: Basic cross-session memory with clear boundaries

```typescript
import { OpenAI } from 'openai';
import lancedb from 'lancedb';
import Redis from 'ioredis';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const vectorDB = await lancedb.connect('./lancedb');
const redis = new Redis();

interface Memory {
  id: string;
  user_id: string;
  session_id: string;
  content: string;
  timestamp: string;
  category: string;
  vector: number[];
}

class CrossSessionMemory {
  // Store memory from current session
  async add(userId: string, sessionId: string, content: string, category: string) {
    const embedding = await this.embed(content);

    const memory: Memory = {
      id: crypto.randomUUID(),
      user_id: userId,
      session_id: sessionId,
      content,
      timestamp: new Date().toISOString(),
      category,
      vector: embedding,
    };

    // Store in vector DB (long-term)
    const table = await vectorDB.openTable('memories');
    await table.add([memory]);

    // Cache recent in Redis (short-term)
    await redis.lpush(`user:${userId}:recent`, JSON.stringify(memory));
    await redis.ltrim(`user:${userId}:recent`, 0, 19);
    await redis.expire(`user:${userId}:recent`, 3600);
  }

  // Search across all sessions
  async search(query: string, userId: string, options: {
    sessionId?: string;
    category?: string;
    topK?: number;
  } = {}) {
    const { sessionId, category, topK = 5 } = options;

    // Check recent cache first
    const cached = await redis.lrange(`user:${userId}:recent`, 0, -1);
    const recentMemories = cached.map(m => JSON.parse(m));

    // Vector search across all sessions
    const queryVector = await this.embed(query);
    const table = await vectorDB.openTable('memories');

    let filters = `user_id = '${userId}'`;
    if (sessionId) filters += ` AND session_id = '${sessionId}'`;
    if (category) filters += ` AND category = '${category}'`;

    const results = await table
      .search(queryVector)
      .where(filters)
      .limit(topK * 2)
      .execute();

    // Merge and deduplicate
    const allResults = [...recentMemories, ...results];
    const unique = Array.from(new Map(allResults.map(m => [m.id, m])).values());

    // Re-rank by recency + similarity
    return this.rerank(unique, topK);
  }

  private rerank(memories: Memory[], topK: number) {
    const now = Date.now();
    return memories
      .map(m => {
        const ageInDays = (now - new Date(m.timestamp).getTime()) / (1000 * 60 * 60 * 24);
        const recencyScore = 1 / (1 + ageInDays);
        const similarity = m._distance ? 1 - m._distance : 0.5;
        const score = similarity * 0.7 + recencyScore * 0.3;
        return { ...m, score };
      })
      .sort((a, b) => b.score - a.score)
      .slice(0, topK);
  }

  private async embed(text: string): Promise<number[]> {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: text,
    });
    return response.data[0].embedding;
  }
}
```

---

### Pattern 2: Recency-Weighted Retrieval

**Use Case**: Prioritize recent memories while including historical context

```typescript
async function recencyWeightedSearch(query: string, userId: string, topK = 10) {
  const results = await vectorDB.search(query, {
    filter: { user_id: userId },
    limit: topK * 2,
  });

  const now = Date.now();
  const rankedResults = results.map(r => {
    const ageInDays = (now - new Date(r.timestamp).getTime()) / (1000 * 60 * 60 * 24);
    const recencyScore = Math.exp(-ageInDays / 30); // Decay over 30 days
    const hybridScore = r.similarity * 0.7 + recencyScore * 0.3;

    return { ...r, hybridScore };
  });

  rankedResults.sort((a, b) => b.hybridScore - a.hybridScore);
  return rankedResults.slice(0, topK);
}

// Example: Recent preference overrides old
// Day 1: "I prefer light mode"
// Day 30: "I prefer dark mode"
// Query: "What theme do I use?"
// Result: "dark mode" ranks higher (more recent)
```

---

### Pattern 3: Context-Aware Retrieval

**Use Case**: Retrieve memories relevant to current context

```typescript
async function contextAwareRetrieval(
  query: string,
  userId: string,
  context: {
    current_task?: string;
    location?: string;
    time_of_day?: string;
  }
) {
  // Build context-enhanced query
  const enhancedQuery = `
    ${query}
    Context: ${context.current_task || 'general'}
    Location: ${context.location || 'unknown'}
    Time: ${context.time_of_day || 'unknown'}
  `;

  // Metadata filters
  const filters = {
    user_id: userId,
    ...(context.current_task && { category: context.current_task }),
  };

  return await vectorDB.search(enhancedQuery, { filter: filters, limit: 5 });
}

// Example
const memories = await contextAwareRetrieval('What should I eat?', 'user_123', {
  current_task: 'meal_planning',
  time_of_day: 'lunch',
  location: 'San Francisco',
});
// Retrieves: lunch preferences, dietary restrictions, nearby favorites
```

---

### Pattern 4: Session Lifecycle Management

**Use Case**: Proper session handling with memory consolidation

```typescript
import { v4 as uuidv4 } from 'uuid';

interface Session {
  id: string;
  user_id: string;
  started_at: string;
  ended_at?: string;
  message_count: number;
  status: 'active' | 'inactive' | 'archived';
}

class SessionManager {
  async createSession(userId: string): Promise<Session> {
    const session: Session = {
      id: uuidv4(),
      user_id: userId,
      started_at: new Date().toISOString(),
      message_count: 0,
      status: 'active',
    };

    await db.sessions.insert(session);
    return session;
  }

  async endSession(sessionId: string) {
    await db.sessions.update(sessionId, {
      ended_at: new Date().toISOString(),
      status: 'inactive',
    });

    // Trigger memory consolidation
    await this.consolidateSession(sessionId);
  }

  async consolidateSession(sessionId: string) {
    // Extract facts from session
    const messages = await db.messages.find({ session_id: sessionId });
    const facts = await extractFacts(messages);

    // Store important facts in long-term memory
    await memory.addBatch(facts);

    // Archive session
    await db.sessions.update(sessionId, { status: 'archived' });
  }
}

// Usage
const sessionMgr = new SessionManager();
const session = await sessionMgr.createSession('user_123');

// ... conversation happens ...

// End session (30 min timeout or explicit close)
await sessionMgr.endSession(session.id);
```

---

## Framework Integration

### AI SDK v6 with Cross-Session Memory

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

const crossSessionMemory = new CrossSessionMemory();

// Memory retrieval tool
const retrievePastMemories = tool({
  description: 'Search memories from past sessions for relevant information',
  inputSchema: z.object({
    query: z.string().describe('What to search for'),
    userId: z.string().describe('User ID'),
    includeAllSessions: z.boolean().default(true),
    category: z.string().optional().describe('Filter by category'),
  }),
  execute: async ({ query, userId, includeAllSessions, category }) => {
    const memories = await crossSessionMemory.search(query, userId, {
      sessionId: includeAllSessions ? undefined : currentSessionId,
      category,
      topK: 5,
    });

    return {
      memories: memories.map(m => ({
        content: m.content,
        session: m.session_id,
        date: m.timestamp,
        relevance: m.score,
      })),
      count: memories.length,
    };
  },
});

// Memory storage tool
const storeMemory = tool({
  description: 'Store important information for future sessions',
  inputSchema: z.object({
    userId: z.string(),
    content: z.string().describe('Information to remember'),
    category: z.enum(['preference', 'fact', 'event', 'medical']),
    sessionId: z.string(),
  }),
  execute: async ({ userId, content, category, sessionId }) => {
    await crossSessionMemory.add(userId, sessionId, content, category);
    return { success: true, stored: content };
  },
});

// Agent with cross-session memory
const { text, steps } = await generateText({
  model: openai('gpt-4o'),
  tools: { retrievePastMemories, storeMemory },
  stopWhen: stepCountIs(10),
  system: `You are a personal assistant with cross-session memory.
When users share preferences or important information, store them for future sessions.
When users ask questions, check past sessions for relevant context first.`,
  prompt: 'What food preferences have I mentioned before?',
});
```

---

## Research & Benchmarks

### LongMemEval Benchmark (2025)

| System | Without Memory | With Memory | Improvement |
|--------|----------------|-------------|-------------|
| **Claude** | 60% | 82% | +22% |
| **GPT-4** | 58% | 80% | +22% |
| **With A-MEM** | 61% | 79.5% | +18.5% |
| **With Zep** | 60% | 81% | +21% |

### Performance Comparison

| Strategy | Latency (p95) | Cost/Query | Accuracy |
|----------|---------------|------------|----------|
| **No Memory** | 10ms | $0.001 | 60% |
| **Redis Cache Only** | 20ms | $0.001 | 75% |
| **Vector DB Only** | 80ms | $0.02 | 85% |
| **Hybrid (Cache + Vector)** | 30ms | $0.01 | 92% |

### Memory System Performance (Mem0)

| Metric | Full Context | Cross-Session | Improvement |
|--------|--------------|---------------|-------------|
| **Latency (p95)** | 550ms | 50ms | **-91%** |
| **Tokens/Query** | 26K | 1.8K | **-93%** |
| **Accuracy** | 69% | 87% | **+26%** |

---

## When to Use This Pattern

### ‚úÖ Use Cross-Session Retrieval When:

1. **Returning users expected**
   - SaaS applications with login
   - Personal assistants, productivity tools

2. **Personalization required**
   - User preferences affect responses
   - Building long-term relationships

3. **Multi-session tasks**
   - Projects spanning multiple days
   - Ongoing support tickets

4. **Compliance/audit needs**
   - Track conversation history
   - Document user consent

### ‚ùå Consider Alternatives When:

1. **One-time interactions**
   - Anonymous users, public chatbots
   - No return expected

2. **High-volume, low-value**
   - Millions of short interactions
   - Cost prohibitive

3. **Privacy-first requirements**
   - Users don't want data stored
   - Regulatory restrictions

### Decision Matrix

| Scenario | Cross-Session | Working Only |
|----------|---------------|--------------|
| **Customer support (repeat)** | ‚úÖ | ‚ùå |
| **Anonymous FAQ bot** | ‚ùå | ‚úÖ |
| **Personal AI assistant** | ‚úÖ | ‚ùå |
| **One-time survey bot** | ‚ùå | ‚úÖ |
| **Healthcare (patient history)** | ‚úÖ | ‚ùå |

---

## Production Best Practices

### 1. Lazy Memory Loading

```typescript
async function lazyMemoryRetrieval(query: string, userId: string) {
  // Fast check: any memories exist?
  const hasMemories = await redis.exists(`user:${userId}:has_memories`);
  if (!hasMemories) return [];

  // Quick semantic search (top 3)
  const initialResults = await memory.search(query, userId, { topK: 3 });

  // Only expand if needed
  if (initialResults.length === 0 || initialResults[0].score < 0.7) {
    return await memory.search(query, userId, { topK: 10 });
  }

  return initialResults;
}
```

### 2. Memory Decay

```typescript
async function decayOldMemories(userId: string) {
  const SIX_MONTHS_AGO = new Date();
  SIX_MONTHS_AGO.setMonth(SIX_MONTHS_AGO.getMonth() - 6);

  // Get old, low-access memories
  const oldMemories = await vectorDB
    .query(`user_id = '${userId}' AND timestamp < '${SIX_MONTHS_AGO.toISOString()}'`)
    .select(['id', 'access_count']);

  // Delete rarely accessed
  const toDelete = oldMemories.filter(m => m.access_count < 2);
  for (const m of toDelete) {
    await vectorDB.delete(m.id);
  }

  console.log(`Deleted ${toDelete.length} unused memories`);
}

// Run daily
setInterval(() => decayOldMemories('user_123'), 24 * 60 * 60 * 1000);
```

### 3. Session Boundary Handling

```typescript
// ‚úÖ Good: Explicitly reference past sessions
Agent: "In our conversation on December 5, you mentioned..."

// ‚ùå Bad: Assume continuous conversation
Agent: "As we discussed earlier..." // User: "We never discussed that!"
```

### 4. Cache Frequent Queries

```typescript
async function searchWithCache(query: string, userId: string) {
  const cacheKey = `query:${userId}:${query}`;
  const cached = await redis.get(cacheKey);

  if (cached) return JSON.parse(cached);

  const results = await memory.search(query, userId);
  await redis.set(cacheKey, JSON.stringify(results), 'EX', 3600);

  return results;
}
```

### Common Pitfalls

#### ‚ùå Pitfall: No Memory Cleanup

```typescript
// ‚ùå Bad: Never delete old memories
// Year 1: 1000 memories ‚Üí $10/month
// Year 5: 50,000 memories ‚Üí $500/month

// ‚úÖ Good: Periodic cleanup
await decayOldMemories(userId);
```

#### ‚ùå Pitfall: Over-Reliance on Memory

```typescript
// ‚ùå Bad: Always search memory
User: "What's 2+2?"
Agent: *searches memory* // Overkill!

// ‚úÖ Good: Only when relevant
if (requiresPersonalization(query)) {
  const memories = await memory.search(query, userId);
}
```

#### ‚ùå Pitfall: Mixing Session Boundaries

```typescript
// ‚ùå Bad: Treating sessions as continuous
// Session 1: "I'm buying a car"
// Session 2: "I'm buying a house"
// Agent confuses which purchase is current

// ‚úÖ Good: Track session context
const memories = await memory.search(query, userId, {
  sessionId: currentSessionId, // Current session only
});
```

---

## Key Takeaways

1. **Cross-session memory transforms AI into persistent assistants** - Users expect remembrance
2. **Use three-tier architecture** - Working ‚Üí Episodic ‚Üí Semantic
3. **Prioritize recent memories** - Recency-weighted retrieval for relevance
4. **Cache frequent queries** - 91% latency reduction possible
5. **Plan for memory decay** - Clean up old, unused memories

**Quick Implementation Checklist**:

- [ ] Set up session management (create, end, archive)
- [ ] Implement three-tier storage (Redis + Vector DB)
- [ ] Add user/session isolation (namespaces or filters)
- [ ] Implement recency-weighted ranking
- [ ] Add memory caching for frequent queries
- [ ] Plan memory decay strategy (TTL, access count)
- [ ] Handle session boundaries explicitly
- [ ] Monitor storage costs and query latency

---

## References

1. **Mem0 Team** (2025). "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory". arXiv. https://arxiv.org/abs/2504.19413
2. **LongMemEval** (2024). "Benchmarking Chat Assistants on Long-Term Interactive Memory". arXiv. https://arxiv.org/abs/2410.10813
3. **A-MEM** (2025). "Agentic Memory for LLM Agents". arXiv. https://arxiv.org/abs/2502.12110
4. **Zep** (2025). "A Temporal Knowledge Graph Architecture for Agent Memory". arXiv. https://arxiv.org/abs/2501.13956
5. **Ajith Prabhakar** (2025). "AI-Native Memory and the Rise of Context-Aware AI Agents". https://ajithp.com/2025/06/30/ai-native-memory-persistent-agents-second-me/
6. **Tribe.ai** (2025). "Context-Aware Memory Systems". https://www.tribe.ai/applied-ai/beyond-the-bubble

**Related Topics**:

- [4.3.1 Vector Databases](./4.3.1-vector-databases.md)
- [4.3.2 Semantic Search](./4.3.2-semantic-search.md)
- [4.3.3 Fact Extraction](./4.3.3-fact-extraction.md)
- [4.3.5 When to Use Long-Term Memory](./4.3.5-when-to-use.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
