# 4.1.4 - Reference Resolution

## TL;DR

**Reference resolution links natural language references ("this page", "that entry", "it") to entities in working memory, enabling conversational interaction without explicit IDs.** This transforms rigid ID-based commands into natural dialogue while maintaining precision through working memory lookup.

- **Status**: ✅ Complete
- **Last Updated**: 2025-12-11
- **Prerequisites**: [4.1.2 Entity Extraction](./4.1.2-entity-extraction.md)
- **Grounded In**: Coreference resolution research (2024-2025), LLM-based resolution, Stanford NLP

## Overview

When users interact with AI agents, they naturally use pronouns and demonstratives: "update this page," "delete that entry," "what about it?" Without reference resolution, agents require explicit IDs for every operation, creating unnatural, mechanical interactions.

Reference resolution bridges this gap by linking referring expressions to their antecedents (the entities they refer to) using working memory. The field draws from decades of coreference resolution research in NLP, now enhanced by LLM capabilities.

**Key Research Findings (2024-2025)**:

- **LLM-based systems**: 83.3 F1-score on CoNLL-2012 (English)
- **LQCA framework**: +3.61% improvement over GPT-4 baseline
- **Simple heuristics**: 70-80% accuracy in domain-specific tasks
- **Hybrid approaches**: 95%+ accuracy with recency heuristics + LLM fallback

## The Problem: Ambiguous References

### The Classic Challenge

Without reference resolution, conversations become mechanical:

```
Turn 1: User: "Show me page 42"
Agent: "Here's page 42: Home Page"

Turn 2: User: "Update this page's title to 'Welcome'"
Agent: "ERROR: pageId parameter is required"  ← Broken!
```

**Problems**:

- ❌ Requires explicit IDs for every operation
- ❌ Unnatural conversation flow
- ❌ Users must remember and repeat IDs
- ❌ Breaks multi-step workflows

### Common Reference Types

| User Says | Refers To | Challenge |
|-----------|-----------|-----------|
| "this page" | Most recent page | Which page? |
| "that entry" | Previously mentioned entry | How far back? |
| "update it" | Last entity operated on | What type? |
| "the first one" | First item in list | Which list? |
| "those pages" | Multiple pages | Which subset? |

## Core Concept

### What is Reference Resolution?

Reference resolution is the process of linking **referring expressions** (pronouns, demonstratives) to their **antecedents** (the entities they refer to):

```
Linguistic Terms:
"Show me page 42. Update this page's title."
          ↓              ↓
     ANTECEDENT      ANAPHOR
    (entity)     (referring expression)

Resolution: "this page" → page 42
```

### Resolution Flow

```
┌─────────────────────────────────────────────────────────────┐
│                  REFERENCE RESOLUTION                        │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  User: "Update this page's title"                           │
│              ↓                                               │
│  ┌───────────────────────┐                                  │
│  │  Detect Reference     │  "this page" detected            │
│  └───────────┬───────────┘                                  │
│              ↓                                               │
│  ┌───────────────────────┐                                  │
│  │  Extract Type         │  type = "page"                   │
│  └───────────┬───────────┘                                  │
│              ↓                                               │
│  ┌───────────────────────┐                                  │
│  │  Query Working Memory │  Find recent pages               │
│  └───────────┬───────────┘                                  │
│              ↓                                               │
│  ┌───────────────────────┐                                  │
│  │  Select Best Match    │  page:42 (most recent)           │
│  └───────────┬───────────┘                                  │
│              ↓                                               │
│  Resolved: { type: 'page', id: 42 }                         │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### Types of References

| Type | Examples | Resolution Strategy |
|------|----------|---------------------|
| **Demonstrative** | "this page", "that entry" | Type + recency |
| **Personal Pronoun** | "it", "they", "them" | Most recent entity |
| **Ordinal** | "the first one", "the last" | Position in list |
| **Definite Description** | "the page", "the user" | Type match |
| **Zero Anaphora** | (implicit subject) | Context inference |

## Implementation Patterns

### Pattern 1: Recency Heuristic (Simplest)

**Use Case**: Short conversations, single entity type focus

Always resolve to the most recent entity of matching type:

```
Reference: "this page"
Working Memory: [page:42, entry:7, page:15, user:1]
                                   ↑
                           Most recent page
Resolution: page:15
```

**Pros**:
- ✅ Fast (O(n) scan)
- ✅ Simple to implement
- ✅ Works for 80% of cases

**Cons**:
- ❌ Ignores "this" vs "that" distinction
- ❌ May pick wrong entity in complex dialogs
- ❌ No context awareness

**When to Use**: Simple assistants, short conversations, single-entity workflows

### Pattern 2: Type + Distance

**Use Case**: Conversations with multiple entity types

Use "this" vs "that" to determine recency:

```
"this" → most recent (near)
"that" → second most recent (far)

Reference: "that page"
Working Memory: [page:42, page:15]
                        ↑
                 Second most recent
Resolution: page:42
```

**Pros**:
- ✅ Handles "this" vs "that" distinction
- ✅ More accurate for multi-entity conversations
- ✅ Still fast

**Cons**:
- ❌ Only two distance levels
- ❌ May not match user intent

**When to Use**: Multi-step workflows, entity comparisons

### Pattern 3: LLM-Based (Most Accurate)

**Use Case**: Complex conversations, ambiguous references

Use LLM to analyze full context and resolve references:

```
Prompt: "Given conversation and working memory,
         what does 'this page' refer to?"

LLM analyzes:
- Recent conversation turns
- Entity mentions
- Contextual clues
- User intent

Resolution: page:42 (confidence: 0.95)
```

**Pros**:
- ✅ Handles complex context
- ✅ High accuracy (83%+ F1)
- ✅ Can handle ambiguous cases

**Cons**:
- ❌ Slow (50-200ms)
- ❌ Costs tokens
- ❌ May hallucinate

**When to Use**: Complex conversations, high-stakes operations, ambiguous references

### Pattern 4: Hybrid (Production Best Practice)

**Use Case**: Production systems

Try fast heuristics first, fall back to LLM for ambiguous cases:

```
┌─────────────────────────────────────────────────────────────┐
│                    HYBRID RESOLUTION                         │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Reference: "this page"                                      │
│       ↓                                                      │
│  ┌─────────────────┐                                        │
│  │   Heuristics    │ ← Fast path (0.2ms, free)              │
│  │  (type+recency) │                                        │
│  └────────┬────────┘                                        │
│           │                                                  │
│       Confident?                                             │
│      ↙        ↘                                             │
│    Yes         No                                            │
│     ↓           ↓                                            │
│  Return   ┌─────────────────┐                               │
│  result   │   LLM-Based     │ ← Slow path (100ms, $0.001)   │
│           │   Resolution    │                               │
│           └────────┬────────┘                               │
│                    ↓                                         │
│                 Result                                       │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

**Pros**:
- ✅ Fast path for common cases (95%)
- ✅ Handles edge cases with LLM (5%)
- ✅ Cost-efficient

**Cons**:
- ❌ More complex implementation
- ❌ Two code paths to maintain

**When to Use**: Any production system

## Framework Integration

### AI SDK v6 with Reference Resolution

```typescript
import { generateText, tool, stepCountIs } from 'ai';
import { openai } from '@ai-sdk/openai';
import { z } from 'zod';

interface Entity {
  type: string;
  id: number | string;
  label?: string;
  timestamp: number;
}

class ReferenceResolver {
  private entities: Entity[];

  constructor(entities: Entity[]) {
    this.entities = entities;
  }

  resolve(reference: string): Entity | null {
    const type = this.extractType(reference);
    const isNear = reference.toLowerCase().includes('this');

    const candidates = this.entities
      .filter(e => !type || e.type === type)
      .sort((a, b) => b.timestamp - a.timestamp);

    if (candidates.length === 0) return null;

    // "this" → most recent, "that" → second most recent
    if (!isNear && candidates.length >= 2) {
      return candidates[1];
    }
    return candidates[0];
  }

  private extractType(reference: string): string | null {
    const ref = reference.toLowerCase();
    if (ref.includes('page')) return 'page';
    if (ref.includes('entry')) return 'entry';
    if (ref.includes('user')) return 'user';
    return null;
  }
}

// Tool with automatic reference resolution
const updatePage = tool({
  description: 'Update page by ID or reference (e.g., "this page")',
  inputSchema: z.object({
    pageRef: z.union([z.number(), z.string()]),
    title: z.string().optional(),
    status: z.string().optional(),
  }),
  execute: async ({ pageRef, title, status }, { experimental_context }) => {
    const ctx = experimental_context as AgentContext;
    let pageId: number;

    // Resolve reference if not a number
    if (typeof pageRef === 'string' && !/^\d+$/.test(pageRef)) {
      const resolver = new ReferenceResolver(ctx.memory.getAll());
      const entity = resolver.resolve(pageRef);

      if (!entity || entity.type !== 'page') {
        return { error: `Could not resolve "${pageRef}" to a page` };
      }
      pageId = entity.id as number;
    } else {
      pageId = typeof pageRef === 'number' ? pageRef : parseInt(pageRef);
    }

    // Update page
    const page = await ctx.db.updatePage(pageId, { title, status });
    return { success: true, page };
  },
});

const result = await generateText({
  model: openai('gpt-4o'),
  tools: { updatePage },
  stopWhen: stepCountIs(10),
  experimental_context: { memory: workingMemory, db: database },
  prompt: 'Update this page title to Welcome',
});
```

### LLM-Based Resolution with Structured Output

```typescript
import { generateObject } from 'ai';
import { z } from 'zod';

const ResolutionSchema = z.object({
  type: z.string(),
  id: z.number(),
  confidence: z.number().min(0).max(1),
  reasoning: z.string().optional(),
});

async function resolveWithLLM(
  reference: string,
  conversation: Message[],
  entities: Entity[]
): Promise<z.infer<typeof ResolutionSchema> | null> {
  const { object } = await generateObject({
    model: openai('gpt-4o-mini'),
    schema: ResolutionSchema,
    prompt: `
Resolve the reference "${reference}" to an entity.

Recent conversation:
${conversation.slice(-5).map(m => `${m.role}: ${m.content}`).join('\n')}

Available entities:
${entities.map(e => `- ${e.type} ${e.id}: ${e.label}`).join('\n')}

Rules:
- "this" prefers most recent entity
- "that" prefers second most recent
- Match entity type from reference phrase
- Confidence < 0.5 if ambiguous
    `,
  });

  return object.confidence >= 0.5 ? object : null;
}
```

## Research & Benchmarks

### Coreference Resolution Performance (2025)

| System | F1-Score | Dataset | Notes |
|--------|----------|---------|-------|
| **State-of-the-art Supervised** | 87.1 | CoNLL-2012 | Traditional ML |
| **LLM-based (GPT-4)** | 83.3 | CoNLL-2012 | Zero-shot |
| **LQCA Framework** | 86.9 | CoNLL-2012 | GPT-4 + framework |
| **Constrained Decoding** | 95.1 | CoNLL-2012 | 8B params |

### Resolution Strategy Comparison

| Strategy | Accuracy | Latency | Cost |
|----------|----------|---------|------|
| **Recency Heuristic** | 70-80% | 0.2ms | Free |
| **Type + Distance** | 80-85% | 0.5ms | Free |
| **LLM-based** | 83-95% | 100ms | $0.001 |
| **Hybrid** | 90-95% | 5ms avg | ~$0.0001 |

### When Heuristics Fail

| Scenario | Why Heuristics Fail | Solution |
|----------|---------------------|----------|
| Multiple recent entities | Ambiguous recency | LLM resolution |
| Complex conversation | Context required | LLM resolution |
| Implicit references | No explicit type | LLM resolution |
| Plural references | "those pages" | Specialized handling |

## When to Use This Pattern

### ✅ Use Reference Resolution When:

1. **Multi-turn conversations**
   - Users reference previous entities
   - Natural dialogue expected

2. **Entity-heavy workflows**
   - CMS operations
   - Database interactions

3. **UX priority**
   - Conversational interface
   - Reducing verbosity

### ❌ Don't Use When:

1. **Single-turn queries**
   - No context to reference
   - Explicit IDs acceptable

2. **Audit requirements**
   - Need explicit ID logging
   - Compliance constraints

3. **High-stakes operations**
   - Deletion, financial transactions
   - Require explicit confirmation

### Resolution Strategy Selection

| Conversation Type | Recommended Strategy |
|-------------------|---------------------|
| Simple Q&A | Recency heuristic |
| CMS editing | Type + distance |
| Customer support | Hybrid |
| Complex workflows | LLM-based |

## Production Best Practices

### 1. Always Validate Resolved Entities

```typescript
const entity = resolver.resolve(reference);

// Validate resolution
if (!entity) {
  return { error: `Could not resolve "${reference}". Please specify the ID.` };
}

// Validate entity type
if (entity.type !== expectedType) {
  return { error: `"${reference}" resolved to ${entity.type}, not ${expectedType}.` };
}
```

### 2. Support Both References and Explicit IDs

```typescript
inputSchema: z.object({
  pageRef: z.union([
    z.number(),                // Direct ID: 42
    z.string().regex(/^\d+$/), // String ID: "42"
    z.string(),                // Reference: "this page"
  ]),
}),
```

### 3. Log Resolution Decisions

```typescript
function resolve(reference: string): Entity | null {
  const entity = doResolve(reference);

  console.log({
    reference,
    resolved: entity ? `${entity.type}:${entity.id}` : null,
    strategy: 'recency',
    candidates: candidates.length,
    confidence: entity ? 0.9 : 0,
  });

  return entity;
}
```

### 4. Handle Disambiguation

When multiple entities match:

```typescript
const candidates = getCandidates(reference);

if (candidates.length > 1) {
  // Option 1: Return most recent (implicit)
  return candidates[0];

  // Option 2: Ask for clarification (explicit)
  return {
    ambiguous: true,
    candidates: candidates.map(c => `${c.type} ${c.id}: ${c.label}`),
    message: 'Which one did you mean?',
  };
}
```

### Common Pitfalls

#### ❌ Pitfall: Resolving Without Validation

**Problem**: Resolved entity may be wrong type or deleted.

**Solution**: Always validate after resolution:
```typescript
const entity = resolver.resolve(reference);
if (!entity) throw new Error('Resolution failed');
if (entity.type !== 'page') throw new Error('Wrong type');
const exists = await db.exists(entity.id);
if (!exists) throw new Error('Entity deleted');
```

#### ❌ Pitfall: LLM-Only Resolution

**Problem**: Slow and expensive for every reference.

**Solution**: Use hybrid with heuristic fast path:
```typescript
// 95% of references resolved in 0.2ms
// 5% fall back to LLM (100ms)
// Average: ~5ms
```

## Key Takeaways

1. **Reference resolution enables natural conversation** - Users say "this page" instead of "page 42"
2. **Recency heuristic works for 80% of cases** - Simple and fast
3. **Hybrid approach is production best practice** - Fast path + LLM fallback
4. **Always validate resolved entities** - Type check and existence verification
5. **Support both references and explicit IDs** - Graceful fallback

**Quick Implementation Checklist**:

- [ ] Define extractable entity types (page, entry, user, etc.)
- [ ] Implement recency-based resolution
- [ ] Add type extraction from reference phrases
- [ ] Support "this" vs "that" distance distinction
- [ ] Add LLM fallback for ambiguous cases
- [ ] Validate resolved entities before use
- [ ] Log resolution decisions for debugging

## References

1. **ACL** (2025). "Improving LLMs' Learning for Coreference Resolution". https://aclanthology.org/2025.sigdial-1.25.pdf
2. **EMNLP** (2025). "Low-Hallucination and Efficient Coreference Resolution". https://aclanthology.org/2025.findings-emnlp.934.pdf
3. **ICLR** (2025). "Bridging Context Gaps: Leveraging Coreference". LQCA Framework.
4. **Stanford NLP** (2024). "Coreference Resolution and Entity Linking". Jurafsky & Martin. https://web.stanford.edu/~jurafsky/slp3/23.pdf
5. **CoNLL** (2025). "Fourth Shared Task on Multilingual Coreference Resolution". https://arxiv.org/html/2509.17796
6. **Vercel AI SDK** (2025). "AI SDK v6 Documentation". https://v6.ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling

**Related Topics**:

- [4.1.1 Working Memory Concept](./4.1.1-working-memory-concept.md)
- [4.1.2 Entity Extraction](./4.1.2-entity-extraction.md)
- [4.1.3 Sliding Window Management](./4.1.3-sliding-window.md)
- [4.1.5 Universal Working Memory](./4.1.5-universal-working-memory.md)

**Layer Index**: [Layer 4: Memory & State](../AI_KNOWLEDGE_BASE_TOC.md#layer-4-memory--state)
