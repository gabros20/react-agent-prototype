# 1.1.5 Self-Consistency: Improving Reliability Through Voting

## Overview

Self-consistency is a prompting technique that dramatically improves answer reliability by generating multiple reasoning paths for the same question, then selecting the most common answer through majority voting. Think of it as "asking a panel of experts" where the model generates diverse solutions and picks the consensus.

**Key Paper**: "Self-Consistency Improves Chain of Thought Reasoning in Language Models" (Wang et al., 2022)

**Impact**: +18% accuracy on GSM8K, +11% on SVAMP, +12% on AQuA (math benchmarks)

**Trade-off**: Higher cost/latency (3-40x) for significantly better reliability.

## The Core Idea

### Single Path (Standard CoT)

```
Q: There are 15 trees in the grove. Grove workers will plant trees today. 
   After they're done, there will be 21 trees. How many did they plant?

Generate once:
A: There were 15 trees originally. Now there are 21 trees. 
   So 21 - 15 = 6 trees were planted.

Answer: 6 trees
```

**Problem**: What if this single path has an error?

### Multiple Paths (Self-Consistency)

```
Generate 5 times with different reasoning:

Path 1: 15 original + planted = 21 total. So planted = 21 - 15 = 6 ✓
Path 2: Started 15. Ended 21. Difference is 21 - 15 = 6 ✓
Path 3: Let x = planted. 15 + x = 21. x = 6 ✓
Path 4: 21 trees minus 15 trees equals 6 new trees ✓
Path 5: From 15 to 21 is increase of 6 ✓

Vote: 6 appears 5/5 times
Final Answer: 6 trees (high confidence)
```

**Benefit**: Errors in one path are outvoted by correct paths.

## Why It Works

### Theory: Marginalizing Over Reasoning Paths

**Mathematical Intuition**:
- Traditional: P(answer | question, single_path)
- Self-Consistency: P(answer | question) = Σ P(answer | path_i) × P(path_i | question)

**Plain English**:
- Each reasoning path might have errors
- Correct reasoning is more consistent across paths
- Errors are random and don't align
- Majority vote filters out noise

### Analogy: The Wisdom of Crowds

If you ask 5 experts to estimate a value:
- Expert 1: 100
- Expert 2: 103
- Expert 3: 101
- Expert 4: 250 (outlier error)
- Expert 5: 102

**Consensus**: ~101-102 (ignore the outlier)

Self-consistency does this automatically with the model as all "experts."

## Implementation

### Basic Pattern

```typescript
async function selfConsistency(
  question: string,
  paths: number = 5
): Promise<{ answer: string; confidence: number; reasoning: string[] }> {
  
  // Step 1: Generate multiple reasoning paths
  const results = await Promise.all(
    Array(paths).fill(null).map(() =>
      generateText({
        model: openai("gpt-4o-mini"),
        prompt: `${question}\n\nLet's think step by step.`,
        temperature: 0.7  // Sampling for diversity
      })
    )
  );
  
  // Step 2: Extract final answers from each path
  const answers = results.map(r => extractAnswer(r.text));
  
  // Step 3: Count votes
  const votes = countVotes(answers);
  
  // Step 4: Select majority answer
  const majorityAnswer = votes[0];
  const confidence = majorityAnswer.count / paths;
  
  return {
    answer: majorityAnswer.value,
    confidence,
    reasoning: results.map(r => r.text)
  };
}

function extractAnswer(reasoning: string): string {
  // Extract final numeric answer, or last sentence, etc.
  const match = reasoning.match(/(?:answer is|equals?|=)\s*(\d+)/i);
  return match ? match[1] : reasoning.split('\n').pop()?.trim() || '';
}

function countVotes(answers: string[]): Array<{value: string; count: number}> {
  const counts = new Map<string, number>();
  answers.forEach(a => counts.set(a, (counts.get(a) || 0) + 1));
  
  return Array.from(counts.entries())
    .map(([value, count]) => ({ value, count }))
    .sort((a, b) => b.count - a.count);
}
```

### Output Example

```typescript
const result = await selfConsistency(
  "If 3 apples cost $6, how much do 5 apples cost?",
  5
);

console.log(result);
// {
//   answer: "$10",
//   confidence: 1.0,  // 5/5 paths agreed
//   reasoning: [
//     "3 apples = $6, so $6/3 = $2 per apple. 5 apples = 5 × $2 = $10",
//     "$6 for 3 apples means $2 each. 5 apples cost $10",
//     "Unit price: $6 ÷ 3 = $2. Total: $2 × 5 = $10",
//     "Each apple is $2 ($6/3). Five apples: $2 + $2 + $2 + $2 + $2 = $10",
//     "Price per apple = $6/3 = $2. Cost of 5 = $10"
//   ]
// }
```

## When to Use Self-Consistency

### ✅ Best For

**1. High-Stakes Decisions**
```
Medical diagnosis assistance
Legal document analysis
Financial calculations
Safety-critical systems

Cost of error > cost of multiple generations
```

**2. Ambiguous or Complex Problems**
```
Q: "John said he'd arrive 'around noon'. Meeting starts at 1 PM. 
    Should we wait for him?"

Single path might give definitive yes/no.
Multiple paths capture uncertainty:
- Path 1: "Yes, around noon could mean 12:30" (Yes)
- Path 2: "No, noon is 12, meeting is 1" (No)
- Path 3: "Maybe, depends on context" (Maybe)
- Path 4: "Yes, give 15 min grace period" (Yes)
- Path 5: "No, be punctual" (No)

Vote: 2 Yes, 2 No, 1 Maybe → Flag as uncertain!
```

**3. Tasks with Verifiable Answers**
```
Math problems
Code generation (run multiple versions, vote on output)
Structured data extraction
Classification tasks
```

**4. Reducing Hallucinations**
```
Q: "What year did Einstein win the Nobel Prize?"

5 paths might give:
- 1921 (correct)
- 1921 (correct)
- 1905 (confusing with relativity paper)
- 1921 (correct)
- 1922 (incorrect)

Vote: 1921 (3/5) → More reliable than single guess
```

### ❌ Skip For

**1. Simple, Deterministic Tasks**
```
Q: "What is 2 + 2?"

Single path is sufficient. Self-consistency adds no value.
```

**2. Creative/Subjective Tasks**
```
"Write a poem about sunset"

Multiple generations might all be good but different.
Voting doesn't make sense for creative output.
```

**3. Budget-Constrained Applications**
```
If 5-10x cost increase is unacceptable:
- High-volume, low-margin queries
- Real-time, low-latency requirements
- Acceptable error rate already met
```

**4. When Speed is Critical**
```
Self-consistency: 5 sequential generations = 5x latency
or 5 parallel generations = same latency but 5x cost

Not suitable for sub-second response requirements
unless parallelized with large budget.
```

## Advanced Techniques

### 1. Weighted Voting

Not all reasoning paths are equal. Weight by quality.

```typescript
async function weightedSelfConsistency(question: string, paths: number = 5) {
  const results = await Promise.all(
    Array(paths).fill(null).map(() =>
      generateText({
        model: openai("gpt-4o-mini"),
        prompt: `${question}\n\nLet's think step by step.`,
        temperature: 0.7
      })
    )
  );
  
  // Score each reasoning path
  const scored = results.map(r => ({
    answer: extractAnswer(r.text),
    reasoning: r.text,
    score: scoreReasoning(r.text)  // Quality metric
  }));
  
  // Weighted vote
  const votes = new Map<string, number>();
  scored.forEach(s => {
    votes.set(s.answer, (votes.get(s.answer) || 0) + s.score);
  });
  
  // Return answer with highest weighted score
  const best = Array.from(votes.entries())
    .sort((a, b) => b[1] - a[1])[0];
    
  return {
    answer: best[0],
    totalScore: best[1],
    reasoning: scored
  };
}

function scoreReasoning(text: string): number {
  // Example metrics:
  let score = 1.0;
  
  // Bonus for showing calculations
  if (/\d+\s*[+\-×÷]\s*\d+\s*=\s*\d+/.test(text)) score += 0.5;
  
  // Bonus for verification step
  if (/verify|check|confirm/i.test(text)) score += 0.3;
  
  // Penalty for very short reasoning (likely skipped steps)
  if (text.length < 100) score -= 0.3;
  
  // Bonus for structured format
  if (/Step \d+:|First,|Then,|Finally,/.test(text)) score += 0.2;
  
  return Math.max(0.1, score);  // Min score 0.1
}
```

### 2. Universal Self-Consistency (USC)

Let the model pick the best answer from its own generations.

```typescript
async function universalSelfConsistency(question: string, paths: number = 5) {
  // Step 1: Generate multiple reasoning paths
  const results = await Promise.all(
    Array(paths).fill(null).map(() =>
      generateText({
        model: openai("gpt-4o-mini"),
        prompt: `${question}\n\nLet's think step by step.`,
        temperature: 0.7
      })
    )
  );
  
  // Step 2: Ask model to select best answer
  const candidates = results.map((r, i) => `
Option ${i + 1}:
Reasoning: ${r.text}
Answer: ${extractAnswer(r.text)}
`).join('\n\n');
  
  const selection = await generateText({
    model: openai("gpt-4o-mini"),
    prompt: `Given these ${paths} different solutions to the same problem, 
select the most accurate answer and explain why.

${candidates}

Which option is most correct and why?`
  });
  
  return {
    selected: selection.text,
    allPaths: results.map(r => r.text)
  };
}
```

**Benefit**: Works for free-form answers where voting is ambiguous.

### 3. Ranked Voting (Beyond Majority)

Use sophisticated voting methods.

**Instant-Runoff Voting**:
```typescript
// Each path ranks top 3 answers
// Eliminate least popular iteratively
// More robust to ties and close races
```

**Borda Count**:
```typescript
// Assign points: 1st choice = 3 pts, 2nd = 2 pts, 3rd = 1 pt
// Sum points across all paths
// Winner = highest total score
```

**Mean Reciprocal Rank**:
```typescript
// Score = 1/rank (1st = 1.0, 2nd = 0.5, 3rd = 0.33)
// Average scores across paths
// Good for ranked lists
```

### 4. Self-Consistency with Different Models

**Ensemble across models**, not just paths:

```typescript
async function multiModelConsistency(question: string) {
  const prompt = `${question}\n\nLet's think step by step.`;
  
  // Generate with multiple models
  const results = await Promise.all([
    generateText({ model: openai("gpt-4o-mini"), prompt }),
    generateText({ model: openai("gpt-4o-mini"), prompt }),  // Twice for sampling
    generateText({ model: anthropic("claude-3-5-haiku"), prompt }),
    generateText({ model: anthropic("claude-3-5-haiku"), prompt }),
    generateText({ model: google("gemini-1.5-flash"), prompt }),
  ]);
  
  const answers = results.map(r => extractAnswer(r.text));
  return majorityVote(answers);
}
```

**Benefit**: Different models have different biases; consensus is more robust.

**Cost**: Very expensive (using premium models multiple times).

### 5. Temperature Sampling Strategy

**Optimal temperature for diversity**:

```typescript
async function optimizedSelfConsistency(question: string) {
  const prompt = `${question}\n\nLet's think step by step.`;
  
  // Vary temperature for controlled diversity
  const temperatures = [0.5, 0.7, 0.9, 0.7, 0.5];
  
  const results = await Promise.all(
    temperatures.map(temp =>
      generateText({
        model: openai("gpt-4o-mini"),
        prompt,
        temperature: temp
      })
    )
  );
  
  return majorityVote(results.map(r => extractAnswer(r.text)));
}
```

**Research finding**: temperature 0.7 gives best diversity/quality balance.

## Combining with Other Techniques

### Self-Consistency + Few-Shot

```
Example 1: [problem] → [reasoning] → [answer]
Example 2: [problem] → [reasoning] → [answer]

Q: [new problem]
A: Let's think step by step.
```

Generate 5 paths with these examples, then vote.

**Benefit**: Few-shot guides reasoning style, self-consistency filters errors.

### Self-Consistency + Structured Outputs

```typescript
const schema = z.object({
  reasoning: z.string(),
  answer: z.number(),
  confidence: z.number().min(0).max(1)
});

// Generate 5 structured outputs
const results = await Promise.all(
  Array(5).fill(null).map(() =>
    generateObject({
      model: openai("gpt-4o-mini", { structuredOutputs: true }),
      schema,
      prompt: `${question}\n\nLet's think step by step.`,
      temperature: 0.7
    })
  )
);

// Vote on answer field
const answers = results.map(r => r.object.answer);
const majority = majorityVote(answers);
```

### Self-Consistency in Your Agent

**Current** (single-path ReAct):
```
User: "Should I delete the hero section?"
→ Agent generates one reasoning path
→ Executes based on that path
```

**Enhanced** (self-consistent ReAct):
```typescript
async function consistentAgentDecision(userQuery: string) {
  // Generate 3 plans
  const plans = await Promise.all(
    Array(3).fill(null).map(() =>
      agent.generatePlan(userQuery, { temperature: 0.7 })
    )
  );
  
  // Vote on next action
  const actions = plans.map(p => p.nextAction);
  const consensus = majorityVote(actions);
  
  // Execute majority action
  return await agent.executeTool(consensus);
}
```

**When to use**: Critical decisions (deletions, payments, irreversible actions)

## Cost-Benefit Analysis

### Token Cost Comparison

**Scenario**: Math word problem

**Single Path**:
- Input: 50 tokens
- Output: 150 tokens (reasoning + answer)
- Total: 200 tokens
- Cost: $0.000120 (GPT-4o-mini: $0.15/$0.60 per 1M)

**Self-Consistency (5 paths)**:
- Input: 50 tokens × 1 (shared)
- Output: 150 tokens × 5 = 750 tokens
- Total: 800 tokens
- Cost: $0.000480

**Cost increase**: 4x (if parallelized) or same wall-clock time

### Accuracy Improvement

| Task | Single Path | Self-Consistency (5) | Gain |
|------|-------------|---------------------|------|
| **GSM8K** (Math) | 57% | 75% | +18% |
| **SVAMP** (Math) | 69% | 80% | +11% |
| **AQuA** (Math) | 38% | 50% | +12% |
| **StrategyQA** (Logic) | 67% | 74% | +7% |

### ROI Calculation

**Example**: Medical diagnosis assistance (1000 queries/month)

**Without Self-Consistency**:
- Cost: 1000 × $0.000120 = $0.12/month
- Accuracy: 85%
- Correct: 850
- Errors: 150 (could lead to misdiagnosis)

**With Self-Consistency**:
- Cost: 1000 × $0.000480 = $0.48/month
- Accuracy: 95%
- Correct: 950
- Errors: 50

**Analysis**:
- Additional cost: $0.36/month
- Errors prevented: 100
- Cost per error prevented: $0.0036
- **Verdict**: Absolutely worth it for high-stakes medical applications

## Limitations & Considerations

### 1. Not a Panacea

Self-consistency helps when:
- ✅ Model CAN solve the problem (just inconsistently)
- ✅ Errors are random across paths
- ✅ Correct reasoning is consistent

Doesn't help when:
- ❌ Model fundamentally doesn't understand the problem
- ❌ All paths make the same systematic error
- ❌ Problem is outside model's capabilities

### 2. Diminishing Returns

| Paths | Accuracy | Cost | Improvement per path |
|-------|----------|------|---------------------|
| 1 | 57% | 1x | baseline |
| 3 | 70% | 3x | +13% (+6.5% each) |
| 5 | 75% | 5x | +5% (+2.5% each) |
| 10 | 77% | 10x | +2% (+0.4% each) |
| 20 | 78% | 20x | +1% (+0.1% each) |

**Sweet spot**: 5-7 paths for most applications.

### 3. Latency Considerations

**Sequential** (cheaper but slower):
```
Path 1: 2s
Path 2: 2s
Path 3: 2s
Path 4: 2s
Path 5: 2s
Total: 10s
```

**Parallel** (faster but same cost):
```
All paths: 2s (parallelized)
Total: 2s
```

Choose based on requirements and budget.

### 4. Answer Extraction Challenges

**Problem**: Voting requires extracting comparable answers.

**Easy** (numbers):
```
Path 1: "... therefore the answer is 42"
Path 2: "... we get 42 as the result"
Path 3: "... equals 42"

Extract "42" from all → easy to vote
```

**Hard** (free-form):
```
Path 1: "The best approach is to use caching"
Path 2: "I recommend implementing a cache layer"
Path 3: "Cache the results for better performance"

All mean the same but different wording → harder to vote
```

**Solution**: Use Universal Self-Consistency (USC) or semantic similarity.

## Key Takeaways

**What is Self-Consistency**:
- Generate multiple reasoning paths (3-10)
- Extract final answers from each
- Vote on most common answer (majority or weighted)
- Significantly improves reliability

**Why It Works**:
- Correct reasoning is consistent across diverse paths
- Errors are random and don't align
- Majority vote filters noise
- Mimics "wisdom of crowds" effect

**When to Use**:
- ✅ High-stakes decisions (medical, legal, financial)
- ✅ Ambiguous/complex problems
- ✅ Tasks with verifiable answers
- ✅ Reducing hallucinations
- ❌ Simple deterministic tasks
- ❌ Creative/subjective outputs
- ❌ Strict budget/latency constraints

**Cost-Benefit**:
- 3-10x cost increase
- 7-18% accuracy improvement
- Sweet spot: 5-7 paths
- Worth it when error cost > compute cost

**Advanced Variants**:
- **Weighted voting**: Score reasoning quality
- **USC**: Let model pick best answer
- **Ranked voting**: Borda count, instant-runoff
- **Multi-model**: Ensemble across different models
- **Temperature tuning**: 0.7 optimal for diversity

**Your Agent**:
- Use for critical decisions (deletions, payments)
- Implement as wrapper around tool execution
- Generate 3-5 plans, vote on next action
- Add confidence threshold (e.g., only execute if 80%+ agreement)

**Implementation**:
```typescript
// Quick integration
const result = await selfConsistency(question, 5);
if (result.confidence >= 0.6) {  // 3/5 agreement minimum
  return result.answer;
} else {
  return "Uncertain - manual review needed";
}
```

## Practical Exercise

Implement self-consistency for these scenarios:

**Exercise 1**: Math Problem
```typescript
// Question: "If a store sells pencils at $2 each or 3 for $5, 
// how much do 7 pencils cost?"

// Implement self-consistency with 5 paths
// Return answer and confidence score
```

**Exercise 2**: Classification
```typescript
// Question: "Classify sentiment: 'The product is okay but 
// customer service was terrible'"

// Use self-consistency to handle ambiguity
// Return sentiment + confidence
```

**Exercise 3**: Your Agent
```typescript
// User: "Delete all unused sections from About page"

// Implement self-consistent decision:
// - Generate 3 plans for which sections to delete
// - Vote on each section (keep/delete)
// - Only delete if 2/3 plans agree
```

## Navigation

- [← Previous: 1.1.4 Zero-Shot CoT](./1.1.4-zero-shot-cot.md)
- [↑ Back to Knowledge Base TOC](../../AI_KNOWLEDGE_BASE_TOC.md)
- [→ Next: 1.2.1 System Prompts - Role Definition](./1.2.1-role-definition.md)

---

*Part of Layer 1: Prompt Engineering - Reliability through consensus*
